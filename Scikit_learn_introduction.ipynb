{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn.datasets in sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn.datasets\n",
      "\n",
      "DESCRIPTION\n",
      "    The :mod:`sklearn.datasets` module includes utilities to load datasets,\n",
      "    including methods to load and fetch popular reference datasets. It also\n",
      "    features some artificial data generators.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _base\n",
      "    _california_housing\n",
      "    _covtype\n",
      "    _kddcup99\n",
      "    _lfw\n",
      "    _olivetti_faces\n",
      "    _openml\n",
      "    _rcv1\n",
      "    _samples_generator\n",
      "    _species_distributions\n",
      "    _svmlight_format\n",
      "    _svmlight_format_fast\n",
      "    _twenty_newsgroups\n",
      "    base\n",
      "    california_housing\n",
      "    covtype\n",
      "    kddcup99\n",
      "    lfw\n",
      "    olivetti_faces\n",
      "    openml\n",
      "    rcv1\n",
      "    samples_generator\n",
      "    setup\n",
      "    species_distributions\n",
      "    svmlight_format\n",
      "    tests (package)\n",
      "    twenty_newsgroups\n",
      "\n",
      "FUNCTIONS\n",
      "    clear_data_home(data_home=None)\n",
      "        Delete all the content of the data home cache.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str | None\n",
      "            The path to scikit-learn data dir.\n",
      "    \n",
      "    dump_svmlight_file(X, y, f, zero_based=True, comment=None, query_id=None, multilabel=False)\n",
      "        Dump the dataset in svmlight / libsvm file format.\n",
      "        \n",
      "        This format is a text-based format, with one sample per line. It does\n",
      "        not store zero valued features hence is suitable for sparse dataset.\n",
      "        \n",
      "        The first element of each line can be used to store a target variable\n",
      "        to predict.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            Training vectors, where n_samples is the number of samples and\n",
      "            n_features is the number of features.\n",
      "        \n",
      "        y : {array-like, sparse matrix}, shape = [n_samples (, n_labels)]\n",
      "            Target values. Class labels must be an\n",
      "            integer or float, or array-like objects of integer or float for\n",
      "            multilabel classifications.\n",
      "        \n",
      "        f : string or file-like in binary mode\n",
      "            If string, specifies the path that will contain the data.\n",
      "            If file-like, data will be written to f. f should be opened in binary\n",
      "            mode.\n",
      "        \n",
      "        zero_based : boolean, optional\n",
      "            Whether column indices should be written zero-based (True) or one-based\n",
      "            (False).\n",
      "        \n",
      "        comment : string, optional\n",
      "            Comment to insert at the top of the file. This should be either a\n",
      "            Unicode string, which will be encoded as UTF-8, or an ASCII byte\n",
      "            string.\n",
      "            If a comment is given, then it will be preceded by one that identifies\n",
      "            the file as having been dumped by scikit-learn. Note that not all\n",
      "            tools grok comments in SVMlight files.\n",
      "        \n",
      "        query_id : array-like of shape (n_samples,)\n",
      "            Array containing pairwise preference constraints (qid in svmlight\n",
      "            format).\n",
      "        \n",
      "        multilabel : boolean, optional\n",
      "            Samples may have several labels each (see\n",
      "            https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html)\n",
      "        \n",
      "            .. versionadded:: 0.17\n",
      "               parameter *multilabel* to support multilabel datasets.\n",
      "    \n",
      "    fetch_20newsgroups(data_home=None, subset='train', categories=None, shuffle=True, random_state=42, remove=(), download_if_missing=True, return_X_y=False)\n",
      "        Load the filenames and data from the 20 newsgroups dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   ==========\n",
      "        Classes                     20\n",
      "        Samples total            18846\n",
      "        Dimensionality               1\n",
      "        Features                  text\n",
      "        =================   ==========\n",
      "        \n",
      "        Read more in the :ref:`User Guide <20newsgroups_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : optional, default: None\n",
      "            Specify a download and cache folder for the datasets. If None,\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        subset : 'train' or 'test', 'all', optional\n",
      "            Select the dataset to load: 'train' for the training set, 'test'\n",
      "            for the test set, 'all' for both, with shuffled ordering.\n",
      "        \n",
      "        categories : None or collection of string or unicode\n",
      "            If None (default), load all the categories.\n",
      "            If not None, list of category names to load (other categories\n",
      "            ignored).\n",
      "        \n",
      "        shuffle : bool, optional\n",
      "            Whether or not to shuffle the data: might be important for models that\n",
      "            make the assumption that the samples are independent and identically\n",
      "            distributed (i.i.d.), such as stochastic gradient descent.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        remove : tuple\n",
      "            May contain any subset of ('headers', 'footers', 'quotes'). Each of\n",
      "            these are kinds of text that will be detected and removed from the\n",
      "            newsgroup posts, preventing classifiers from overfitting on\n",
      "            metadata.\n",
      "        \n",
      "            'headers' removes newsgroup headers, 'footers' removes blocks at the\n",
      "            ends of posts that look like signatures, and 'quotes' removes lines\n",
      "            that appear to be quoting another post.\n",
      "        \n",
      "            'headers' follows an exact standard; the other filters are not always\n",
      "            correct.\n",
      "        \n",
      "        download_if_missing : optional, True by default\n",
      "            If False, raise an IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : bool, default=False.\n",
      "            If True, returns `(data.data, data.target)` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        bunch : Bunch object with the following attribute:\n",
      "            - data: list, length [n_samples]\n",
      "            - target: array, shape [n_samples]\n",
      "            - filenames: list, length [n_samples]\n",
      "            - DESCR: a description of the dataset.\n",
      "            - target_names: a list of categories of the returned data,\n",
      "              length [n_classes]. This depends on the `categories` parameter.\n",
      "        \n",
      "        (data, target) : tuple if `return_X_y=True`\n",
      "            .. versionadded:: 0.22\n",
      "    \n",
      "    fetch_20newsgroups_vectorized(subset='train', remove=(), data_home=None, download_if_missing=True, return_X_y=False, normalize=True)\n",
      "        Load the 20 newsgroups dataset and vectorize it into token counts (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        This is a convenience function; the transformation is done using the\n",
      "        default settings for\n",
      "        :class:`sklearn.feature_extraction.text.CountVectorizer`. For more\n",
      "        advanced usage (stopword filtering, n-gram extraction, etc.), combine\n",
      "        fetch_20newsgroups with a custom\n",
      "        :class:`sklearn.feature_extraction.text.CountVectorizer`,\n",
      "        :class:`sklearn.feature_extraction.text.HashingVectorizer`,\n",
      "        :class:`sklearn.feature_extraction.text.TfidfTransformer` or\n",
      "        :class:`sklearn.feature_extraction.text.TfidfVectorizer`.\n",
      "        \n",
      "        The resulting counts are normalized using\n",
      "        :func:`sklearn.preprocessing.normalize` unless normalize is set to False.\n",
      "        \n",
      "        =================   ==========\n",
      "        Classes                     20\n",
      "        Samples total            18846\n",
      "        Dimensionality          130107\n",
      "        Features                  real\n",
      "        =================   ==========\n",
      "        \n",
      "        Read more in the :ref:`User Guide <20newsgroups_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        subset : 'train' or 'test', 'all', optional\n",
      "            Select the dataset to load: 'train' for the training set, 'test'\n",
      "            for the test set, 'all' for both, with shuffled ordering.\n",
      "        \n",
      "        remove : tuple\n",
      "            May contain any subset of ('headers', 'footers', 'quotes'). Each of\n",
      "            these are kinds of text that will be detected and removed from the\n",
      "            newsgroup posts, preventing classifiers from overfitting on\n",
      "            metadata.\n",
      "        \n",
      "            'headers' removes newsgroup headers, 'footers' removes blocks at the\n",
      "            ends of posts that look like signatures, and 'quotes' removes lines\n",
      "            that appear to be quoting another post.\n",
      "        \n",
      "        data_home : optional, default: None\n",
      "            Specify an download and cache folder for the datasets. If None,\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : optional, True by default\n",
      "            If False, raise an IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        normalize : bool, default=True\n",
      "            If True, normalizes each document's feature vector to unit norm using\n",
      "            :func:`sklearn.preprocessing.normalize`.\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        bunch : Bunch object with the following attribute:\n",
      "            - bunch.data: sparse matrix, shape [n_samples, n_features]\n",
      "            - bunch.target: array, shape [n_samples]\n",
      "            - bunch.target_names: a list of categories of the returned data,\n",
      "              length [n_classes].\n",
      "            - bunch.DESCR: a description of the dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_california_housing(data_home=None, download_if_missing=True, return_X_y=False)\n",
      "        Load the California housing dataset (regression).\n",
      "        \n",
      "        ==============   ==============\n",
      "        Samples total             20640\n",
      "        Dimensionality                8\n",
      "        Features                   real\n",
      "        Target           real 0.15 - 5.\n",
      "        ==============   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <california_housing_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : optional, default: None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : optional, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : dict-like object with the following attributes:\n",
      "        \n",
      "        dataset.data : ndarray, shape [20640, 8]\n",
      "            Each row corresponding to the 8 feature values in order.\n",
      "        \n",
      "        dataset.target : numpy array of shape (20640,)\n",
      "            Each value corresponds to the average house value in units of 100,000.\n",
      "        \n",
      "        dataset.feature_names : array of length 8\n",
      "            Array of ordered feature names used in the dataset.\n",
      "        \n",
      "        dataset.DESCR : string\n",
      "            Description of the California housing dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        This dataset consists of 20,640 samples and 9 features.\n",
      "    \n",
      "    fetch_covtype(data_home=None, download_if_missing=True, random_state=None, shuffle=False, return_X_y=False)\n",
      "        Load the covertype dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   ============\n",
      "        Classes                        7\n",
      "        Samples total             581012\n",
      "        Dimensionality                54\n",
      "        Features                     int\n",
      "        =================   ============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <covtype_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : string, optional\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : boolean, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle dataset.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : dict-like object with the following attributes:\n",
      "        \n",
      "        dataset.data : numpy array of shape (581012, 54)\n",
      "            Each row corresponds to the 54 features in the dataset.\n",
      "        \n",
      "        dataset.target : numpy array of shape (581012,)\n",
      "            Each value corresponds to one of the 7 forest covertypes with values\n",
      "            ranging between 1 to 7.\n",
      "        \n",
      "        dataset.DESCR : string\n",
      "            Description of the forest covertype dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_kddcup99(subset=None, data_home=None, shuffle=False, random_state=None, percent10=True, download_if_missing=True, return_X_y=False)\n",
      "        Load the kddcup99 dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   ====================================\n",
      "        Classes                                               23\n",
      "        Samples total                                    4898431\n",
      "        Dimensionality                                        41\n",
      "        Features            discrete (int) or continuous (float)\n",
      "        =================   ====================================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <kddcup99_dataset>`.\n",
      "        \n",
      "        .. versionadded:: 0.18\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        subset : None, 'SA', 'SF', 'http', 'smtp'\n",
      "            To return the corresponding classical subsets of kddcup 99.\n",
      "            If None, return the entire kddcup 99 dataset.\n",
      "        \n",
      "        data_home : string, optional\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "            .. versionadded:: 0.19\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle dataset.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset shuffling and for\n",
      "            selection of abnormal samples if `subset='SA'`. Pass an int for\n",
      "            reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        percent10 : bool, default=True\n",
      "            Whether to load only 10 percent of the data.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "            below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are:\n",
      "             - 'data', the data to learn.\n",
      "             - 'target', the regression target for each sample.\n",
      "             - 'DESCR', a description of the dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_lfw_pairs(subset='train', data_home=None, funneled=True, resize=0.5, color=False, slice_=(slice(70, 195, None), slice(78, 172, None)), download_if_missing=True)\n",
      "        Load the Labeled Faces in the Wild (LFW) pairs dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   =======================\n",
      "        Classes                                5749\n",
      "        Samples total                         13233\n",
      "        Dimensionality                         5828\n",
      "        Features            real, between 0 and 255\n",
      "        =================   =======================\n",
      "        \n",
      "        In the official `README.txt`_ this task is described as the\n",
      "        \"Restricted\" task.  As I am not sure as to implement the\n",
      "        \"Unrestricted\" variant correctly, I left it as unsupported for now.\n",
      "        \n",
      "          .. _`README.txt`: http://vis-www.cs.umass.edu/lfw/README.txt\n",
      "        \n",
      "        The original images are 250 x 250 pixels, but the default slice and resize\n",
      "        arguments reduce them to 62 x 47.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <labeled_faces_in_the_wild_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        subset : optional, default: 'train'\n",
      "            Select the dataset to load: 'train' for the development training\n",
      "            set, 'test' for the development test set, and '10_folds' for the\n",
      "            official evaluation set that is meant to be used with a 10-folds\n",
      "            cross validation.\n",
      "        \n",
      "        data_home : optional, default: None\n",
      "            Specify another download and cache folder for the datasets. By\n",
      "            default all scikit-learn data is stored in '~/scikit_learn_data'\n",
      "            subfolders.\n",
      "        \n",
      "        funneled : boolean, optional, default: True\n",
      "            Download and use the funneled variant of the dataset.\n",
      "        \n",
      "        resize : float, optional, default 0.5\n",
      "            Ratio used to resize the each face picture.\n",
      "        \n",
      "        color : boolean, optional, default False\n",
      "            Keep the 3 RGB channels instead of averaging them to a single\n",
      "            gray level channel. If color is True the shape of the data has\n",
      "            one more dimension than the shape with color = False.\n",
      "        \n",
      "        slice_ : optional\n",
      "            Provide a custom 2D slice (height, width) to extract the\n",
      "            'interesting' part of the jpeg files and avoid use statistical\n",
      "            correlation from the background\n",
      "        \n",
      "        download_if_missing : optional, True by default\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        The data is returned as a Bunch object with the following attributes:\n",
      "        \n",
      "        data : numpy array of shape (2200, 5828). Shape depends on ``subset``.\n",
      "            Each row corresponds to 2 ravel'd face images of original size 62 x 47\n",
      "            pixels. Changing the ``slice_``, ``resize`` or ``subset`` parameters\n",
      "            will change the shape of the output.\n",
      "        \n",
      "        pairs : numpy array of shape (2200, 2, 62, 47). Shape depends on ``subset``\n",
      "            Each row has 2 face images corresponding to same or different person\n",
      "            from the dataset containing 5749 people. Changing the ``slice_``,\n",
      "            ``resize`` or ``subset`` parameters will change the shape of the\n",
      "            output.\n",
      "        \n",
      "        target : numpy array of shape (2200,). Shape depends on ``subset``.\n",
      "            Labels associated to each pair of images. The two label values being\n",
      "            different persons or the same person.\n",
      "        \n",
      "        DESCR : string\n",
      "            Description of the Labeled Faces in the Wild (LFW) dataset.\n",
      "    \n",
      "    fetch_lfw_people(data_home=None, funneled=True, resize=0.5, min_faces_per_person=0, color=False, slice_=(slice(70, 195, None), slice(78, 172, None)), download_if_missing=True, return_X_y=False)\n",
      "        Load the Labeled Faces in the Wild (LFW) people dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   =======================\n",
      "        Classes                                5749\n",
      "        Samples total                         13233\n",
      "        Dimensionality                         5828\n",
      "        Features            real, between 0 and 255\n",
      "        =================   =======================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <labeled_faces_in_the_wild_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : optional, default: None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        funneled : boolean, optional, default: True\n",
      "            Download and use the funneled variant of the dataset.\n",
      "        \n",
      "        resize : float, optional, default 0.5\n",
      "            Ratio used to resize the each face picture.\n",
      "        \n",
      "        min_faces_per_person : int, optional, default None\n",
      "            The extracted dataset will only retain pictures of people that have at\n",
      "            least `min_faces_per_person` different pictures.\n",
      "        \n",
      "        color : boolean, optional, default False\n",
      "            Keep the 3 RGB channels instead of averaging them to a single\n",
      "            gray level channel. If color is True the shape of the data has\n",
      "            one more dimension than the shape with color = False.\n",
      "        \n",
      "        slice_ : optional\n",
      "            Provide a custom 2D slice (height, width) to extract the\n",
      "            'interesting' part of the jpeg files and avoid use statistical\n",
      "            correlation from the background\n",
      "        \n",
      "        download_if_missing : optional, True by default\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(dataset.data, dataset.target)`` instead of a Bunch\n",
      "            object. See below for more information about the `dataset.data` and\n",
      "            `dataset.target` object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : dict-like object with the following attributes:\n",
      "        \n",
      "        dataset.data : numpy array of shape (13233, 2914)\n",
      "            Each row corresponds to a ravelled face image of original size 62 x 47\n",
      "            pixels. Changing the ``slice_`` or resize parameters will change the\n",
      "            shape of the output.\n",
      "        \n",
      "        dataset.images : numpy array of shape (13233, 62, 47)\n",
      "            Each row is a face image corresponding to one of the 5749 people in\n",
      "            the dataset. Changing the ``slice_`` or resize parameters will change\n",
      "            the shape of the output.\n",
      "        \n",
      "        dataset.target : numpy array of shape (13233,)\n",
      "            Labels associated to each face image. Those labels range from 0-5748\n",
      "            and correspond to the person IDs.\n",
      "        \n",
      "        dataset.DESCR : string\n",
      "            Description of the Labeled Faces in the Wild (LFW) dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_olivetti_faces(data_home=None, shuffle=False, random_state=0, download_if_missing=True, return_X_y=False)\n",
      "        Load the Olivetti faces data-set from AT&T (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   =====================\n",
      "        Classes                                40\n",
      "        Samples total                         400\n",
      "        Dimensionality                       4096\n",
      "        Features            real, between 0 and 1\n",
      "        =================   =====================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <olivetti_faces_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : optional, default: None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        shuffle : boolean, optional\n",
      "            If True the order of the dataset is shuffled to avoid having\n",
      "            images of the same person grouped.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default=0)\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        download_if_missing : optional, True by default\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns `(data, target)` instead of a `Bunch` object. See\n",
      "            below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        bunch : Bunch object with the following attributes:\n",
      "            - data: ndarray, shape (400, 4096). Each row corresponds to a ravelled\n",
      "              face image of original size 64 x 64 pixels.\n",
      "            - images : ndarray, shape (400, 64, 64). Each row is a face image\n",
      "              corresponding to one of the 40 subjects of the dataset.\n",
      "            - target : ndarray, shape (400,). Labels associated to each face image.\n",
      "              Those labels are ranging from 0-39 and correspond to the\n",
      "              Subject IDs.\n",
      "            - DESCR : string. Description of the modified Olivetti Faces Dataset.\n",
      "        \n",
      "        (data, target) : tuple if `return_X_y=True`\n",
      "            .. versionadded:: 0.22\n",
      "    \n",
      "    fetch_openml(name=None, version='active', data_id=None, data_home=None, target_column='default-target', cache=True, return_X_y=False, as_frame=False)\n",
      "        Fetch dataset from openml by name or dataset id.\n",
      "        \n",
      "        Datasets are uniquely identified by either an integer ID or by a\n",
      "        combination of name and version (i.e. there might be multiple\n",
      "        versions of the 'iris' dataset). Please give either name or data_id\n",
      "        (not both). In case a name is given, a version can also be\n",
      "        provided.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <openml>`.\n",
      "        \n",
      "        .. note:: EXPERIMENTAL\n",
      "        \n",
      "            The API is experimental (particularly the return value structure),\n",
      "            and might have small backward-incompatible changes in future releases.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        name : str or None\n",
      "            String identifier of the dataset. Note that OpenML can have multiple\n",
      "            datasets with the same name.\n",
      "        \n",
      "        version : integer or 'active', default='active'\n",
      "            Version of the dataset. Can only be provided if also ``name`` is given.\n",
      "            If 'active' the oldest version that's still active is used. Since\n",
      "            there may be more than one active version of a dataset, and those\n",
      "            versions may fundamentally be different from one another, setting an\n",
      "            exact version is highly recommended.\n",
      "        \n",
      "        data_id : int or None\n",
      "            OpenML ID of the dataset. The most specific way of retrieving a\n",
      "            dataset. If data_id is not given, name (and potential version) are\n",
      "            used to obtain a dataset.\n",
      "        \n",
      "        data_home : string or None, default None\n",
      "            Specify another download and cache folder for the data sets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        target_column : string, list or None, default 'default-target'\n",
      "            Specify the column name in the data to use as target. If\n",
      "            'default-target', the standard target column a stored on the server\n",
      "            is used. If ``None``, all columns are returned as data and the\n",
      "            target is ``None``. If list (of strings), all columns with these names\n",
      "            are returned as multi-target (Note: not all scikit-learn classifiers\n",
      "            can handle all types of multi-output combinations)\n",
      "        \n",
      "        cache : boolean, default=True\n",
      "            Whether to cache downloaded datasets using joblib.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "            below for more information about the `data` and `target` objects.\n",
      "        \n",
      "        as_frame : boolean, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric, string or categorical). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target_columns.\n",
      "            The Bunch will contain a ``frame`` attribute with the target and the\n",
      "            data. If ``return_X_y`` is True, then ``(data, target)`` will be pandas\n",
      "            DataFrames or Series as describe above.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        \n",
      "        data : Bunch\n",
      "            Dictionary-like object, with attributes:\n",
      "        \n",
      "            data : np.array, scipy.sparse.csr_matrix of floats, or pandas DataFrame\n",
      "                The feature matrix. Categorical features are encoded as ordinals.\n",
      "            target : np.array, pandas Series or DataFrame\n",
      "                The regression target or classification labels, if applicable.\n",
      "                Dtype is float if numeric, and object if categorical. If\n",
      "                ``as_frame`` is True, ``target`` is a pandas object.\n",
      "            DESCR : str\n",
      "                The full description of the dataset\n",
      "            feature_names : list\n",
      "                The names of the dataset columns\n",
      "            target_names: list\n",
      "                The names of the target columns\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "        \n",
      "            categories : dict or None\n",
      "                Maps each categorical feature name to a list of values, such\n",
      "                that the value encoded as i is ith in the list. If ``as_frame``\n",
      "                is True, this is None.\n",
      "            details : dict\n",
      "                More metadata from OpenML\n",
      "            frame : pandas DataFrame\n",
      "                Only present when `as_frame=True`. DataFrame with ``data`` and\n",
      "                ``target``.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. note:: EXPERIMENTAL\n",
      "        \n",
      "                This interface is **experimental** and subsequent releases may\n",
      "                change attributes without notice (although there should only be\n",
      "                minor changes to ``data`` and ``target``).\n",
      "        \n",
      "            Missing values in the 'data' are represented as NaN's. Missing values\n",
      "            in 'target' are represented as NaN's (numerical target) or None\n",
      "            (categorical target)\n",
      "    \n",
      "    fetch_rcv1(data_home=None, subset='all', download_if_missing=True, random_state=None, shuffle=False, return_X_y=False)\n",
      "        Load the RCV1 multilabel dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        Version: RCV1-v2, vectors, full sets, topics multilabels.\n",
      "        \n",
      "        =================   =====================\n",
      "        Classes                               103\n",
      "        Samples total                      804414\n",
      "        Dimensionality                      47236\n",
      "        Features            real, between 0 and 1\n",
      "        =================   =====================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <rcv1_dataset>`.\n",
      "        \n",
      "        .. versionadded:: 0.17\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : string, optional\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        subset : string, 'train', 'test', or 'all', default='all'\n",
      "            Select the dataset to load: 'train' for the training set\n",
      "            (23149 samples), 'test' for the test set (781265 samples),\n",
      "            'all' for both, with the training samples first if shuffle is False.\n",
      "            This follows the official LYRL2004 chronological split.\n",
      "        \n",
      "        download_if_missing : boolean, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle dataset.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(dataset.data, dataset.target)`` instead of a Bunch\n",
      "            object. See below for more information about the `dataset.data` and\n",
      "            `dataset.target` object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : dict-like object with the following attributes:\n",
      "        \n",
      "        dataset.data : scipy csr array, dtype np.float64, shape (804414, 47236)\n",
      "            The array has 0.16% of non zero values.\n",
      "        \n",
      "        dataset.target : scipy csr array, dtype np.uint8, shape (804414, 103)\n",
      "            Each sample has a value of 1 in its categories, and 0 in others.\n",
      "            The array has 3.15% of non zero values.\n",
      "        \n",
      "        dataset.sample_id : numpy array, dtype np.uint32, shape (804414,)\n",
      "            Identification number of each sample, as ordered in dataset.data.\n",
      "        \n",
      "        dataset.target_names : numpy array, dtype object, length (103)\n",
      "            Names of each target (RCV1 topics), as ordered in dataset.target.\n",
      "        \n",
      "        dataset.DESCR : string\n",
      "            Description of the RCV1 dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_species_distributions(data_home=None, download_if_missing=True)\n",
      "        Loader for species distribution dataset from Phillips et. al. (2006)\n",
      "        \n",
      "        Read more in the :ref:`User Guide <datasets>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : optional, default: None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : optional, True by default\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        The data is returned as a Bunch object with the following attributes:\n",
      "        \n",
      "        coverages : array, shape = [14, 1592, 1212]\n",
      "            These represent the 14 features measured at each point of the map grid.\n",
      "            The latitude/longitude values for the grid are discussed below.\n",
      "            Missing data is represented by the value -9999.\n",
      "        \n",
      "        train : record array, shape = (1624,)\n",
      "            The training points for the data.  Each point has three fields:\n",
      "        \n",
      "            - train['species'] is the species name\n",
      "            - train['dd long'] is the longitude, in degrees\n",
      "            - train['dd lat'] is the latitude, in degrees\n",
      "        \n",
      "        test : record array, shape = (620,)\n",
      "            The test points for the data.  Same format as the training data.\n",
      "        \n",
      "        Nx, Ny : integers\n",
      "            The number of longitudes (x) and latitudes (y) in the grid\n",
      "        \n",
      "        x_left_lower_corner, y_left_lower_corner : floats\n",
      "            The (x,y) position of the lower-left corner, in degrees\n",
      "        \n",
      "        grid_size : float\n",
      "            The spacing between points of the grid, in degrees\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        * `\"Maximum entropy modeling of species geographic distributions\"\n",
      "          <http://rob.schapire.net/papers/ecolmod.pdf>`_\n",
      "          S. J. Phillips, R. P. Anderson, R. E. Schapire - Ecological Modelling,\n",
      "          190:231-259, 2006.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        This dataset represents the geographic distribution of species.\n",
      "        The dataset is provided by Phillips et. al. (2006).\n",
      "        \n",
      "        The two species are:\n",
      "        \n",
      "        - `\"Bradypus variegatus\"\n",
      "          <http://www.iucnredlist.org/details/3038/0>`_ ,\n",
      "          the Brown-throated Sloth.\n",
      "        \n",
      "        - `\"Microryzomys minutus\"\n",
      "          <http://www.iucnredlist.org/details/13408/0>`_ ,\n",
      "          also known as the Forest Small Rice Rat, a rodent that lives in Peru,\n",
      "          Colombia, Ecuador, Peru, and Venezuela.\n",
      "        \n",
      "        - For an example of using this dataset with scikit-learn, see\n",
      "          :ref:`examples/applications/plot_species_distribution_modeling.py\n",
      "          <sphx_glr_auto_examples_applications_plot_species_distribution_modeling.py>`.\n",
      "    \n",
      "    get_data_home(data_home=None)\n",
      "        Return the path of the scikit-learn data dir.\n",
      "        \n",
      "        This folder is used by some large dataset loaders to avoid downloading the\n",
      "        data several times.\n",
      "        \n",
      "        By default the data dir is set to a folder named 'scikit_learn_data' in the\n",
      "        user home folder.\n",
      "        \n",
      "        Alternatively, it can be set by the 'SCIKIT_LEARN_DATA' environment\n",
      "        variable or programmatically by giving an explicit folder path. The '~'\n",
      "        symbol is expanded to the user home folder.\n",
      "        \n",
      "        If the folder does not already exist, it is automatically created.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str | None\n",
      "            The path to scikit-learn data dir.\n",
      "    \n",
      "    load_boston(return_X_y=False)\n",
      "        Load and return the boston house-prices dataset (regression).\n",
      "        \n",
      "        ==============   ==============\n",
      "        Samples total               506\n",
      "        Dimensionality               13\n",
      "        Features         real, positive\n",
      "        Targets           real 5. - 50.\n",
      "        ==============   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <boston_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are:\n",
      "            'data', the data to learn, 'target', the regression targets,\n",
      "            'DESCR', the full description of the dataset,\n",
      "            and 'filename', the physical location of boston\n",
      "            csv dataset (added in version `0.20`).\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "            .. versionchanged:: 0.20\n",
      "                Fixed a wrong data point at [445, 0].\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.datasets import load_boston\n",
      "        >>> X, y = load_boston(return_X_y=True)\n",
      "        >>> print(X.shape)\n",
      "        (506, 13)\n",
      "    \n",
      "    load_breast_cancer(return_X_y=False)\n",
      "        Load and return the breast cancer wisconsin dataset (classification).\n",
      "        \n",
      "        The breast cancer dataset is a classic and very easy binary classification\n",
      "        dataset.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                          2\n",
      "        Samples per class    212(M),357(B)\n",
      "        Samples total                  569\n",
      "        Dimensionality                  30\n",
      "        Features            real, positive\n",
      "        =================   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <breast_cancer_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : boolean, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are:\n",
      "            'data', the data to learn, 'target', the classification labels,\n",
      "            'target_names', the meaning of the labels, 'feature_names', the\n",
      "            meaning of the features, and 'DESCR', the full description of\n",
      "            the dataset, 'filename', the physical location of\n",
      "            breast cancer csv dataset (added in version `0.20`).\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        The copy of UCI ML Breast Cancer Wisconsin (Diagnostic) dataset is\n",
      "        downloaded from:\n",
      "        https://goo.gl/U2Uwz2\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Let's say you are interested in the samples 10, 50, and 85, and want to\n",
      "        know their class name.\n",
      "        \n",
      "        >>> from sklearn.datasets import load_breast_cancer\n",
      "        >>> data = load_breast_cancer()\n",
      "        >>> data.target[[10, 50, 85]]\n",
      "        array([0, 1, 0])\n",
      "        >>> list(data.target_names)\n",
      "        ['malignant', 'benign']\n",
      "    \n",
      "    load_diabetes(return_X_y=False)\n",
      "        Load and return the diabetes dataset (regression).\n",
      "        \n",
      "        ==============   ==================\n",
      "        Samples total    442\n",
      "        Dimensionality   10\n",
      "        Features         real, -.2 < x < .2\n",
      "        Targets          integer 25 - 346\n",
      "        ==============   ==================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <diabetes_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are:\n",
      "            'data', the data to learn, 'target', the regression target for each\n",
      "            sample, 'data_filename', the physical location\n",
      "            of diabetes data csv dataset, and 'target_filename', the physical\n",
      "            location of diabetes targets csv datataset (added in version `0.20`).\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "    \n",
      "    load_digits(n_class=10, return_X_y=False)\n",
      "        Load and return the digits dataset (classification).\n",
      "        \n",
      "        Each datapoint is a 8x8 image of a digit.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                         10\n",
      "        Samples per class             ~180\n",
      "        Samples total                 1797\n",
      "        Dimensionality                  64\n",
      "        Features             integers 0-16\n",
      "        =================   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <digits_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_class : integer, between 0 and 10, optional (default=10)\n",
      "            The number of classes to return.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are:\n",
      "            'data', the data to learn, 'images', the images corresponding\n",
      "            to each sample, 'target', the classification labels for each\n",
      "            sample, 'target_names', the meaning of the labels, and 'DESCR',\n",
      "            the full description of the dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "        https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        To load the data and visualize the images::\n",
      "        \n",
      "            >>> from sklearn.datasets import load_digits\n",
      "            >>> digits = load_digits()\n",
      "            >>> print(digits.data.shape)\n",
      "            (1797, 64)\n",
      "            >>> import matplotlib.pyplot as plt #doctest: +SKIP\n",
      "            >>> plt.gray() #doctest: +SKIP\n",
      "            >>> plt.matshow(digits.images[0]) #doctest: +SKIP\n",
      "            >>> plt.show() #doctest: +SKIP\n",
      "    \n",
      "    load_files(container_path, description=None, categories=None, load_content=True, shuffle=True, encoding=None, decode_error='strict', random_state=0)\n",
      "        Load text files with categories as subfolder names.\n",
      "        \n",
      "        Individual samples are assumed to be files stored a two levels folder\n",
      "        structure such as the following:\n",
      "        \n",
      "            container_folder/\n",
      "                category_1_folder/\n",
      "                    file_1.txt\n",
      "                    file_2.txt\n",
      "                    ...\n",
      "                    file_42.txt\n",
      "                category_2_folder/\n",
      "                    file_43.txt\n",
      "                    file_44.txt\n",
      "                    ...\n",
      "        \n",
      "        The folder names are used as supervised signal label names. The individual\n",
      "        file names are not important.\n",
      "        \n",
      "        This function does not try to extract features into a numpy array or scipy\n",
      "        sparse matrix. In addition, if load_content is false it does not try to\n",
      "        load the files in memory.\n",
      "        \n",
      "        To use text files in a scikit-learn classification or clustering algorithm,\n",
      "        you will need to use the :mod`~sklearn.feature_extraction.text` module to\n",
      "        build a feature extraction transformer that suits your problem.\n",
      "        \n",
      "        If you set load_content=True, you should also specify the encoding of the\n",
      "        text using the 'encoding' parameter. For many modern text files, 'utf-8'\n",
      "        will be the correct encoding. If you leave encoding equal to None, then the\n",
      "        content will be made of bytes instead of Unicode, and you will not be able\n",
      "        to use most functions in :mod:`~sklearn.feature_extraction.text`.\n",
      "        \n",
      "        Similar feature extractors should be built for other kind of unstructured\n",
      "        data input such as images, audio, video, ...\n",
      "        \n",
      "        Read more in the :ref:`User Guide <datasets>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        container_path : string or unicode\n",
      "            Path to the main folder holding one subfolder per category\n",
      "        \n",
      "        description : string or unicode, optional (default=None)\n",
      "            A paragraph describing the characteristic of the dataset: its source,\n",
      "            reference, etc.\n",
      "        \n",
      "        categories : A collection of strings or None, optional (default=None)\n",
      "            If None (default), load all the categories. If not None, list of\n",
      "            category names to load (other categories ignored).\n",
      "        \n",
      "        load_content : boolean, optional (default=True)\n",
      "            Whether to load or not the content of the different files. If true a\n",
      "            'data' attribute containing the text information is present in the data\n",
      "            structure returned. If not, a filenames attribute gives the path to the\n",
      "            files.\n",
      "        \n",
      "        shuffle : bool, optional (default=True)\n",
      "            Whether or not to shuffle the data: might be important for models that\n",
      "            make the assumption that the samples are independent and identically\n",
      "            distributed (i.i.d.), such as stochastic gradient descent.\n",
      "        \n",
      "        encoding : string or None (default is None)\n",
      "            If None, do not try to decode the content of the files (e.g. for images\n",
      "            or other non-text content). If not None, encoding to use to decode text\n",
      "            files to Unicode if load_content is True.\n",
      "        \n",
      "        decode_error : {'strict', 'ignore', 'replace'}, optional\n",
      "            Instruction on what to do if a byte sequence is given to analyze that\n",
      "            contains characters not of the given `encoding`. Passed as keyword\n",
      "            argument 'errors' to bytes.decode.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default=0)\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are: either\n",
      "            data, the raw text data to learn, or 'filenames', the files\n",
      "            holding it, 'target', the classification labels (integer index),\n",
      "            'target_names', the meaning of the labels, and 'DESCR', the full\n",
      "            description of the dataset.\n",
      "    \n",
      "    load_iris(return_X_y=False)\n",
      "        Load and return the iris dataset (classification).\n",
      "        \n",
      "        The iris dataset is a classic and very easy multi-class classification\n",
      "        dataset.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                          3\n",
      "        Samples per class               50\n",
      "        Samples total                  150\n",
      "        Dimensionality                   4\n",
      "        Features            real, positive\n",
      "        =================   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <iris_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "            below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are:\n",
      "            'data', the data to learn, 'target', the classification labels,\n",
      "            'target_names', the meaning of the labels, 'feature_names', the\n",
      "            meaning of the features, 'DESCR', the full description of\n",
      "            the dataset, 'filename', the physical location of\n",
      "            iris csv dataset (added in version `0.20`).\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "            .. versionchanged:: 0.20\n",
      "                Fixed two wrong data points according to Fisher's paper.\n",
      "                The new version is the same as in R, but not as in the UCI\n",
      "                Machine Learning Repository.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Let's say you are interested in the samples 10, 25, and 50, and want to\n",
      "        know their class name.\n",
      "        \n",
      "        >>> from sklearn.datasets import load_iris\n",
      "        >>> data = load_iris()\n",
      "        >>> data.target[[10, 25, 50]]\n",
      "        array([0, 0, 1])\n",
      "        >>> list(data.target_names)\n",
      "        ['setosa', 'versicolor', 'virginica']\n",
      "    \n",
      "    load_linnerud(return_X_y=False)\n",
      "        Load and return the linnerud dataset (multivariate regression).\n",
      "        \n",
      "        ==============   ============================\n",
      "        Samples total    20\n",
      "        Dimensionality   3 (for both data and target)\n",
      "        Features         integer\n",
      "        Targets          integer\n",
      "        ==============   ============================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <linnerrud_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are: 'data' and\n",
      "            'target', the two multivariate datasets, with 'data' corresponding to\n",
      "            the exercise and 'target' corresponding to the physiological\n",
      "            measurements, as well as 'feature_names' and 'target_names'.\n",
      "            In addition, you will also have access to 'data_filename',\n",
      "            the physical location of linnerud data csv dataset, and\n",
      "            'target_filename', the physical location of\n",
      "            linnerud targets csv datataset (added in version `0.20`).\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "    \n",
      "    load_sample_image(image_name)\n",
      "        Load the numpy array of a single sample image\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_images>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        image_name : {`china.jpg`, `flower.jpg`}\n",
      "            The name of the sample image loaded\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        img : 3D array\n",
      "            The image as a numpy array: height x width x color\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        >>> from sklearn.datasets import load_sample_image\n",
      "        >>> china = load_sample_image('china.jpg')   # doctest: +SKIP\n",
      "        >>> china.dtype                              # doctest: +SKIP\n",
      "        dtype('uint8')\n",
      "        >>> china.shape                              # doctest: +SKIP\n",
      "        (427, 640, 3)\n",
      "        >>> flower = load_sample_image('flower.jpg') # doctest: +SKIP\n",
      "        >>> flower.dtype                             # doctest: +SKIP\n",
      "        dtype('uint8')\n",
      "        >>> flower.shape                             # doctest: +SKIP\n",
      "        (427, 640, 3)\n",
      "    \n",
      "    load_sample_images()\n",
      "        Load sample images for image manipulation.\n",
      "        \n",
      "        Loads both, ``china`` and ``flower``.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_images>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object with the following attributes : 'images', the\n",
      "            two sample images, 'filenames', the file names for the images, and\n",
      "            'DESCR' the full description of the dataset.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        To load the data and visualize the images:\n",
      "        \n",
      "        >>> from sklearn.datasets import load_sample_images\n",
      "        >>> dataset = load_sample_images()     #doctest: +SKIP\n",
      "        >>> len(dataset.images)                #doctest: +SKIP\n",
      "        2\n",
      "        >>> first_img_data = dataset.images[0] #doctest: +SKIP\n",
      "        >>> first_img_data.shape               #doctest: +SKIP\n",
      "        (427, 640, 3)\n",
      "        >>> first_img_data.dtype               #doctest: +SKIP\n",
      "        dtype('uint8')\n",
      "    \n",
      "    load_svmlight_file(f, n_features=None, dtype=<class 'numpy.float64'>, multilabel=False, zero_based='auto', query_id=False, offset=0, length=-1)\n",
      "        Load datasets in the svmlight / libsvm format into sparse CSR matrix\n",
      "        \n",
      "        This format is a text-based format, with one sample per line. It does\n",
      "        not store zero valued features hence is suitable for sparse dataset.\n",
      "        \n",
      "        The first element of each line can be used to store a target variable\n",
      "        to predict.\n",
      "        \n",
      "        This format is used as the default format for both svmlight and the\n",
      "        libsvm command line programs.\n",
      "        \n",
      "        Parsing a text based source can be expensive. When working on\n",
      "        repeatedly on the same dataset, it is recommended to wrap this\n",
      "        loader with joblib.Memory.cache to store a memmapped backup of the\n",
      "        CSR results of the first call and benefit from the near instantaneous\n",
      "        loading of memmapped structures for the subsequent calls.\n",
      "        \n",
      "        In case the file contains a pairwise preference constraint (known\n",
      "        as \"qid\" in the svmlight format) these are ignored unless the\n",
      "        query_id parameter is set to True. These pairwise preference\n",
      "        constraints can be used to constraint the combination of samples\n",
      "        when using pairwise loss functions (as is the case in some\n",
      "        learning to rank problems) so that only pairs with the same\n",
      "        query_id value are considered.\n",
      "        \n",
      "        This implementation is written in Cython and is reasonably fast.\n",
      "        However, a faster API-compatible loader is also available at:\n",
      "        \n",
      "          https://github.com/mblondel/svmlight-loader\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        f : {str, file-like, int}\n",
      "            (Path to) a file to load. If a path ends in \".gz\" or \".bz2\", it will\n",
      "            be uncompressed on the fly. If an integer is passed, it is assumed to\n",
      "            be a file descriptor. A file-like or file descriptor will not be closed\n",
      "            by this function. A file-like object must be opened in binary mode.\n",
      "        \n",
      "        n_features : int or None\n",
      "            The number of features to use. If None, it will be inferred. This\n",
      "            argument is useful to load several files that are subsets of a\n",
      "            bigger sliced dataset: each subset might not have examples of\n",
      "            every feature, hence the inferred shape might vary from one\n",
      "            slice to another.\n",
      "            n_features is only required if ``offset`` or ``length`` are passed a\n",
      "            non-default value.\n",
      "        \n",
      "        dtype : numpy data type, default np.float64\n",
      "            Data type of dataset to be loaded. This will be the data type of the\n",
      "            output numpy arrays ``X`` and ``y``.\n",
      "        \n",
      "        multilabel : boolean, optional, default False\n",
      "            Samples may have several labels each (see\n",
      "            https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html)\n",
      "        \n",
      "        zero_based : boolean or \"auto\", optional, default \"auto\"\n",
      "            Whether column indices in f are zero-based (True) or one-based\n",
      "            (False). If column indices are one-based, they are transformed to\n",
      "            zero-based to match Python/NumPy conventions.\n",
      "            If set to \"auto\", a heuristic check is applied to determine this from\n",
      "            the file contents. Both kinds of files occur \"in the wild\", but they\n",
      "            are unfortunately not self-identifying. Using \"auto\" or True should\n",
      "            always be safe when no ``offset`` or ``length`` is passed.\n",
      "            If ``offset`` or ``length`` are passed, the \"auto\" mode falls back\n",
      "            to ``zero_based=True`` to avoid having the heuristic check yield\n",
      "            inconsistent results on different segments of the file.\n",
      "        \n",
      "        query_id : boolean, default False\n",
      "            If True, will return the query_id array for each file.\n",
      "        \n",
      "        offset : integer, optional, default 0\n",
      "            Ignore the offset first bytes by seeking forward, then\n",
      "            discarding the following bytes up until the next new line\n",
      "            character.\n",
      "        \n",
      "        length : integer, optional, default -1\n",
      "            If strictly positive, stop reading any new line of data once the\n",
      "            position in the file has reached the (offset + length) bytes threshold.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : scipy.sparse matrix of shape (n_samples, n_features)\n",
      "        \n",
      "        y : ndarray of shape (n_samples,), or, in the multilabel a list of\n",
      "            tuples of length n_samples.\n",
      "        \n",
      "        query_id : array of shape (n_samples,)\n",
      "           query_id for each sample. Only returned when query_id is set to\n",
      "           True.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        load_svmlight_files: similar function for loading multiple files in this\n",
      "                             format, enforcing the same number of features/columns\n",
      "                             on all of them.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        To use joblib.Memory to cache the svmlight file::\n",
      "        \n",
      "            from joblib import Memory\n",
      "            from .datasets import load_svmlight_file\n",
      "            mem = Memory(\"./mycache\")\n",
      "        \n",
      "            @mem.cache\n",
      "            def get_data():\n",
      "                data = load_svmlight_file(\"mysvmlightfile\")\n",
      "                return data[0], data[1]\n",
      "        \n",
      "            X, y = get_data()\n",
      "    \n",
      "    load_svmlight_files(files, n_features=None, dtype=<class 'numpy.float64'>, multilabel=False, zero_based='auto', query_id=False, offset=0, length=-1)\n",
      "        Load dataset from multiple files in SVMlight format\n",
      "        \n",
      "        This function is equivalent to mapping load_svmlight_file over a list of\n",
      "        files, except that the results are concatenated into a single, flat list\n",
      "        and the samples vectors are constrained to all have the same number of\n",
      "        features.\n",
      "        \n",
      "        In case the file contains a pairwise preference constraint (known\n",
      "        as \"qid\" in the svmlight format) these are ignored unless the\n",
      "        query_id parameter is set to True. These pairwise preference\n",
      "        constraints can be used to constraint the combination of samples\n",
      "        when using pairwise loss functions (as is the case in some\n",
      "        learning to rank problems) so that only pairs with the same\n",
      "        query_id value are considered.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        files : iterable over {str, file-like, int}\n",
      "            (Paths of) files to load. If a path ends in \".gz\" or \".bz2\", it will\n",
      "            be uncompressed on the fly. If an integer is passed, it is assumed to\n",
      "            be a file descriptor. File-likes and file descriptors will not be\n",
      "            closed by this function. File-like objects must be opened in binary\n",
      "            mode.\n",
      "        \n",
      "        n_features : int or None\n",
      "            The number of features to use. If None, it will be inferred from the\n",
      "            maximum column index occurring in any of the files.\n",
      "        \n",
      "            This can be set to a higher value than the actual number of features\n",
      "            in any of the input files, but setting it to a lower value will cause\n",
      "            an exception to be raised.\n",
      "        \n",
      "        dtype : numpy data type, default np.float64\n",
      "            Data type of dataset to be loaded. This will be the data type of the\n",
      "            output numpy arrays ``X`` and ``y``.\n",
      "        \n",
      "        multilabel : boolean, optional\n",
      "            Samples may have several labels each (see\n",
      "            https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html)\n",
      "        \n",
      "        zero_based : boolean or \"auto\", optional\n",
      "            Whether column indices in f are zero-based (True) or one-based\n",
      "            (False). If column indices are one-based, they are transformed to\n",
      "            zero-based to match Python/NumPy conventions.\n",
      "            If set to \"auto\", a heuristic check is applied to determine this from\n",
      "            the file contents. Both kinds of files occur \"in the wild\", but they\n",
      "            are unfortunately not self-identifying. Using \"auto\" or True should\n",
      "            always be safe when no offset or length is passed.\n",
      "            If offset or length are passed, the \"auto\" mode falls back\n",
      "            to zero_based=True to avoid having the heuristic check yield\n",
      "            inconsistent results on different segments of the file.\n",
      "        \n",
      "        query_id : boolean, defaults to False\n",
      "            If True, will return the query_id array for each file.\n",
      "        \n",
      "        offset : integer, optional, default 0\n",
      "            Ignore the offset first bytes by seeking forward, then\n",
      "            discarding the following bytes up until the next new line\n",
      "            character.\n",
      "        \n",
      "        length : integer, optional, default -1\n",
      "            If strictly positive, stop reading any new line of data once the\n",
      "            position in the file has reached the (offset + length) bytes threshold.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        [X1, y1, ..., Xn, yn]\n",
      "        where each (Xi, yi) pair is the result from load_svmlight_file(files[i]).\n",
      "        \n",
      "        If query_id is set to True, this will return instead [X1, y1, q1,\n",
      "        ..., Xn, yn, qn] where (Xi, yi, qi) is the result from\n",
      "        load_svmlight_file(files[i])\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When fitting a model to a matrix X_train and evaluating it against a\n",
      "        matrix X_test, it is essential that X_train and X_test have the same\n",
      "        number of features (X_train.shape[1] == X_test.shape[1]). This may not\n",
      "        be the case if you load the files individually with load_svmlight_file.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        load_svmlight_file\n",
      "    \n",
      "    load_wine(return_X_y=False)\n",
      "        Load and return the wine dataset (classification).\n",
      "        \n",
      "        .. versionadded:: 0.18\n",
      "        \n",
      "        The wine dataset is a classic and very easy multi-class classification\n",
      "        dataset.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                          3\n",
      "        Samples per class        [59,71,48]\n",
      "        Samples total                  178\n",
      "        Dimensionality                  13\n",
      "        Features            real, positive\n",
      "        =================   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <wine_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are: 'data', the\n",
      "            data to learn, 'target', the classification labels, 'target_names', the\n",
      "            meaning of the labels, 'feature_names', the meaning of the features,\n",
      "            and 'DESCR', the full description of the dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "        The copy of UCI ML Wine Data Set dataset is downloaded and modified to fit\n",
      "        standard format from:\n",
      "        https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Let's say you are interested in the samples 10, 80, and 140, and want to\n",
      "        know their class name.\n",
      "        \n",
      "        >>> from sklearn.datasets import load_wine\n",
      "        >>> data = load_wine()\n",
      "        >>> data.target[[10, 80, 140]]\n",
      "        array([0, 1, 2])\n",
      "        >>> list(data.target_names)\n",
      "        ['class_0', 'class_1', 'class_2']\n",
      "    \n",
      "    make_biclusters(shape, n_clusters, noise=0.0, minval=10, maxval=100, shuffle=True, random_state=None)\n",
      "        Generate an array with constant block diagonal structure for\n",
      "        biclustering.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        shape : iterable (n_rows, n_cols)\n",
      "            The shape of the result.\n",
      "        \n",
      "        n_clusters : integer\n",
      "            The number of biclusters.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        minval : int, optional (default=10)\n",
      "            Minimum value of a bicluster.\n",
      "        \n",
      "        maxval : int, optional (default=100)\n",
      "            Maximum value of a bicluster.\n",
      "        \n",
      "        shuffle : boolean, optional (default=True)\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape `shape`\n",
      "            The generated array.\n",
      "        \n",
      "        rows : array of shape (n_clusters, X.shape[0],)\n",
      "            The indicators for cluster membership of each row.\n",
      "        \n",
      "        cols : array of shape (n_clusters, X.shape[1],)\n",
      "            The indicators for cluster membership of each column.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] Dhillon, I. S. (2001, August). Co-clustering documents and\n",
      "            words using bipartite spectral graph partitioning. In Proceedings\n",
      "            of the seventh ACM SIGKDD international conference on Knowledge\n",
      "            discovery and data mining (pp. 269-274). ACM.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_checkerboard\n",
      "    \n",
      "    make_blobs(n_samples=100, n_features=2, centers=None, cluster_std=1.0, center_box=(-10.0, 10.0), shuffle=True, random_state=None)\n",
      "        Generate isotropic Gaussian blobs for clustering.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int or array-like, optional (default=100)\n",
      "            If int, it is the total number of points equally divided among\n",
      "            clusters.\n",
      "            If array-like, each element of the sequence indicates\n",
      "            the number of samples per cluster.\n",
      "        \n",
      "        n_features : int, optional (default=2)\n",
      "            The number of features for each sample.\n",
      "        \n",
      "        centers : int or array of shape [n_centers, n_features], optional\n",
      "            (default=None)\n",
      "            The number of centers to generate, or the fixed center locations.\n",
      "            If n_samples is an int and centers is None, 3 centers are generated.\n",
      "            If n_samples is array-like, centers must be\n",
      "            either None or an array of length equal to the length of n_samples.\n",
      "        \n",
      "        cluster_std : float or sequence of floats, optional (default=1.0)\n",
      "            The standard deviation of the clusters.\n",
      "        \n",
      "        center_box : pair of floats (min, max), optional (default=(-10.0, 10.0))\n",
      "            The bounding box for each cluster center when centers are\n",
      "            generated at random.\n",
      "        \n",
      "        shuffle : boolean, optional (default=True)\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The generated samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The integer labels for cluster membership of each sample.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.datasets import make_blobs\n",
      "        >>> X, y = make_blobs(n_samples=10, centers=3, n_features=2,\n",
      "        ...                   random_state=0)\n",
      "        >>> print(X.shape)\n",
      "        (10, 2)\n",
      "        >>> y\n",
      "        array([0, 0, 1, 0, 2, 2, 2, 1, 1, 0])\n",
      "        >>> X, y = make_blobs(n_samples=[3, 3, 4], centers=None, n_features=2,\n",
      "        ...                   random_state=0)\n",
      "        >>> print(X.shape)\n",
      "        (10, 2)\n",
      "        >>> y\n",
      "        array([0, 1, 2, 0, 2, 2, 2, 1, 1, 0])\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_classification: a more intricate variant\n",
      "    \n",
      "    make_checkerboard(shape, n_clusters, noise=0.0, minval=10, maxval=100, shuffle=True, random_state=None)\n",
      "        Generate an array with block checkerboard structure for\n",
      "        biclustering.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        shape : iterable (n_rows, n_cols)\n",
      "            The shape of the result.\n",
      "        \n",
      "        n_clusters : integer or iterable (n_row_clusters, n_column_clusters)\n",
      "            The number of row and column clusters.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        minval : int, optional (default=10)\n",
      "            Minimum value of a bicluster.\n",
      "        \n",
      "        maxval : int, optional (default=100)\n",
      "            Maximum value of a bicluster.\n",
      "        \n",
      "        shuffle : boolean, optional (default=True)\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape `shape`\n",
      "            The generated array.\n",
      "        \n",
      "        rows : array of shape (n_clusters, X.shape[0],)\n",
      "            The indicators for cluster membership of each row.\n",
      "        \n",
      "        cols : array of shape (n_clusters, X.shape[1],)\n",
      "            The indicators for cluster membership of each column.\n",
      "        \n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] Kluger, Y., Basri, R., Chang, J. T., & Gerstein, M. (2003).\n",
      "            Spectral biclustering of microarray data: coclustering genes\n",
      "            and conditions. Genome research, 13(4), 703-716.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_biclusters\n",
      "    \n",
      "    make_circles(n_samples=100, shuffle=True, noise=None, random_state=None, factor=0.8)\n",
      "        Make a large circle containing a smaller circle in 2d.\n",
      "        \n",
      "        A simple toy dataset to visualize clustering and classification\n",
      "        algorithms.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The total number of points generated. If odd, the inner circle will\n",
      "            have one point more than the outer circle.\n",
      "        \n",
      "        shuffle : bool, optional (default=True)\n",
      "            Whether to shuffle the samples.\n",
      "        \n",
      "        noise : double or None (default=None)\n",
      "            Standard deviation of Gaussian noise added to the data.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset shuffling and noise.\n",
      "            Pass an int for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        factor : 0 < double < 1 (default=.8)\n",
      "            Scale factor between inner and outer circle.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 2]\n",
      "            The generated samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The integer labels (0 or 1) for class membership of each sample.\n",
      "    \n",
      "    make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
      "        Generate a random n-class classification problem.\n",
      "        \n",
      "        This initially creates clusters of points normally distributed (std=1)\n",
      "        about vertices of an ``n_informative``-dimensional hypercube with sides of\n",
      "        length ``2*class_sep`` and assigns an equal number of clusters to each\n",
      "        class. It introduces interdependence between these features and adds\n",
      "        various types of further noise to the data.\n",
      "        \n",
      "        Without shuffling, ``X`` horizontally stacks features in the following\n",
      "        order: the primary ``n_informative`` features, followed by ``n_redundant``\n",
      "        linear combinations of the informative features, followed by ``n_repeated``\n",
      "        duplicates, drawn randomly with replacement from the informative and\n",
      "        redundant features. The remaining features are filled with random noise.\n",
      "        Thus, without shuffling, all useful features are contained in the columns\n",
      "        ``X[:, :n_informative + n_redundant + n_repeated]``.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, optional (default=20)\n",
      "            The total number of features. These comprise ``n_informative``\n",
      "            informative features, ``n_redundant`` redundant features,\n",
      "            ``n_repeated`` duplicated features and\n",
      "            ``n_features-n_informative-n_redundant-n_repeated`` useless features\n",
      "            drawn at random.\n",
      "        \n",
      "        n_informative : int, optional (default=2)\n",
      "            The number of informative features. Each class is composed of a number\n",
      "            of gaussian clusters each located around the vertices of a hypercube\n",
      "            in a subspace of dimension ``n_informative``. For each cluster,\n",
      "            informative features are drawn independently from  N(0, 1) and then\n",
      "            randomly linearly combined within each cluster in order to add\n",
      "            covariance. The clusters are then placed on the vertices of the\n",
      "            hypercube.\n",
      "        \n",
      "        n_redundant : int, optional (default=2)\n",
      "            The number of redundant features. These features are generated as\n",
      "            random linear combinations of the informative features.\n",
      "        \n",
      "        n_repeated : int, optional (default=0)\n",
      "            The number of duplicated features, drawn randomly from the informative\n",
      "            and the redundant features.\n",
      "        \n",
      "        n_classes : int, optional (default=2)\n",
      "            The number of classes (or labels) of the classification problem.\n",
      "        \n",
      "        n_clusters_per_class : int, optional (default=2)\n",
      "            The number of clusters per class.\n",
      "        \n",
      "        weights : array-like of shape (n_classes,) or (n_classes - 1,),              (default=None)\n",
      "            The proportions of samples assigned to each class. If None, then\n",
      "            classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n",
      "            then the last class weight is automatically inferred.\n",
      "            More than ``n_samples`` samples may be returned if the sum of\n",
      "            ``weights`` exceeds 1.\n",
      "        \n",
      "        flip_y : float, optional (default=0.01)\n",
      "            The fraction of samples whose class is assigned randomly. Larger\n",
      "            values introduce noise in the labels and make the classification\n",
      "            task harder.\n",
      "        \n",
      "        class_sep : float, optional (default=1.0)\n",
      "            The factor multiplying the hypercube size.  Larger values spread\n",
      "            out the clusters/classes and make the classification task easier.\n",
      "        \n",
      "        hypercube : boolean, optional (default=True)\n",
      "            If True, the clusters are put on the vertices of a hypercube. If\n",
      "            False, the clusters are put on the vertices of a random polytope.\n",
      "        \n",
      "        shift : float, array of shape [n_features] or None, optional (default=0.0)\n",
      "            Shift features by the specified value. If None, then features\n",
      "            are shifted by a random value drawn in [-class_sep, class_sep].\n",
      "        \n",
      "        scale : float, array of shape [n_features] or None, optional (default=1.0)\n",
      "            Multiply features by the specified value. If None, then features\n",
      "            are scaled by a random value drawn in [1, 100]. Note that scaling\n",
      "            happens after shifting.\n",
      "        \n",
      "        shuffle : boolean, optional (default=True)\n",
      "            Shuffle the samples and the features.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The generated samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The integer labels for class membership of each sample.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The algorithm is adapted from Guyon [1] and was designed to generate\n",
      "        the \"Madelon\" dataset.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
      "               selection benchmark\", 2003.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_blobs: simplified variant\n",
      "        make_multilabel_classification: unrelated generator for multilabel tasks\n",
      "    \n",
      "    make_friedman1(n_samples=100, n_features=10, noise=0.0, random_state=None)\n",
      "        Generate the \"Friedman #1\" regression problem\n",
      "        \n",
      "        This dataset is described in Friedman [1] and Breiman [2].\n",
      "        \n",
      "        Inputs `X` are independent features uniformly distributed on the interval\n",
      "        [0, 1]. The output `y` is created according to the formula::\n",
      "        \n",
      "            y(X) = 10 * sin(pi * X[:, 0] * X[:, 1]) + 20 * (X[:, 2] - 0.5) ** 2 + 10 * X[:, 3] + 5 * X[:, 4] + noise * N(0, 1).\n",
      "        \n",
      "        Out of the `n_features` features, only 5 are actually used to compute\n",
      "        `y`. The remaining features are independent of `y`.\n",
      "        \n",
      "        The number of features has to be >= 5.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, optional (default=10)\n",
      "            The number of features. Should be at least 5.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset noise. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The input samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Friedman, \"Multivariate adaptive regression splines\", The Annals\n",
      "               of Statistics 19 (1), pages 1-67, 1991.\n",
      "        \n",
      "        .. [2] L. Breiman, \"Bagging predictors\", Machine Learning 24,\n",
      "               pages 123-140, 1996.\n",
      "    \n",
      "    make_friedman2(n_samples=100, noise=0.0, random_state=None)\n",
      "        Generate the \"Friedman #2\" regression problem\n",
      "        \n",
      "        This dataset is described in Friedman [1] and Breiman [2].\n",
      "        \n",
      "        Inputs `X` are 4 independent features uniformly distributed on the\n",
      "        intervals::\n",
      "        \n",
      "            0 <= X[:, 0] <= 100,\n",
      "            40 * pi <= X[:, 1] <= 560 * pi,\n",
      "            0 <= X[:, 2] <= 1,\n",
      "            1 <= X[:, 3] <= 11.\n",
      "        \n",
      "        The output `y` is created according to the formula::\n",
      "        \n",
      "            y(X) = (X[:, 0] ** 2 + (X[:, 1] * X[:, 2]  - 1 / (X[:, 1] * X[:, 3])) ** 2) ** 0.5 + noise * N(0, 1).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset noise. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 4]\n",
      "            The input samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Friedman, \"Multivariate adaptive regression splines\", The Annals\n",
      "               of Statistics 19 (1), pages 1-67, 1991.\n",
      "        \n",
      "        .. [2] L. Breiman, \"Bagging predictors\", Machine Learning 24,\n",
      "               pages 123-140, 1996.\n",
      "    \n",
      "    make_friedman3(n_samples=100, noise=0.0, random_state=None)\n",
      "        Generate the \"Friedman #3\" regression problem\n",
      "        \n",
      "        This dataset is described in Friedman [1] and Breiman [2].\n",
      "        \n",
      "        Inputs `X` are 4 independent features uniformly distributed on the\n",
      "        intervals::\n",
      "        \n",
      "            0 <= X[:, 0] <= 100,\n",
      "            40 * pi <= X[:, 1] <= 560 * pi,\n",
      "            0 <= X[:, 2] <= 1,\n",
      "            1 <= X[:, 3] <= 11.\n",
      "        \n",
      "        The output `y` is created according to the formula::\n",
      "        \n",
      "            y(X) = arctan((X[:, 1] * X[:, 2] - 1 / (X[:, 1] * X[:, 3])) / X[:, 0]) + noise * N(0, 1).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset noise. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 4]\n",
      "            The input samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Friedman, \"Multivariate adaptive regression splines\", The Annals\n",
      "               of Statistics 19 (1), pages 1-67, 1991.\n",
      "        \n",
      "        .. [2] L. Breiman, \"Bagging predictors\", Machine Learning 24,\n",
      "               pages 123-140, 1996.\n",
      "    \n",
      "    make_gaussian_quantiles(mean=None, cov=1.0, n_samples=100, n_features=2, n_classes=3, shuffle=True, random_state=None)\n",
      "        Generate isotropic Gaussian and label samples by quantile\n",
      "        \n",
      "        This classification dataset is constructed by taking a multi-dimensional\n",
      "        standard normal distribution and defining classes separated by nested\n",
      "        concentric multi-dimensional spheres such that roughly equal numbers of\n",
      "        samples are in each class (quantiles of the :math:`\\chi^2` distribution).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        mean : array of shape [n_features], optional (default=None)\n",
      "            The mean of the multi-dimensional normal distribution.\n",
      "            If None then use the origin (0, 0, ...).\n",
      "        \n",
      "        cov : float, optional (default=1.)\n",
      "            The covariance matrix will be this value times the unit matrix. This\n",
      "            dataset only produces symmetric normal distributions.\n",
      "        \n",
      "        n_samples : int, optional (default=100)\n",
      "            The total number of points equally divided among classes.\n",
      "        \n",
      "        n_features : int, optional (default=2)\n",
      "            The number of features for each sample.\n",
      "        \n",
      "        n_classes : int, optional (default=3)\n",
      "            The number of classes\n",
      "        \n",
      "        shuffle : boolean, optional (default=True)\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The generated samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The integer labels for quantile membership of each sample.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The dataset is from Zhu et al [1].\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Zhu, H. Zou, S. Rosset, T. Hastie, \"Multi-class AdaBoost\", 2009.\n",
      "    \n",
      "    make_hastie_10_2(n_samples=12000, random_state=None)\n",
      "        Generates data for binary classification used in\n",
      "        Hastie et al. 2009, Example 10.2.\n",
      "        \n",
      "        The ten features are standard independent Gaussian and\n",
      "        the target ``y`` is defined by::\n",
      "        \n",
      "          y[i] = 1 if np.sum(X[i] ** 2) > 9.34 else -1\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=12000)\n",
      "            The number of samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 10]\n",
      "            The input samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] T. Hastie, R. Tibshirani and J. Friedman, \"Elements of Statistical\n",
      "               Learning Ed. 2\", Springer, 2009.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_gaussian_quantiles: a generalization of this dataset approach\n",
      "    \n",
      "    make_low_rank_matrix(n_samples=100, n_features=100, effective_rank=10, tail_strength=0.5, random_state=None)\n",
      "        Generate a mostly low rank matrix with bell-shaped singular values\n",
      "        \n",
      "        Most of the variance can be explained by a bell-shaped curve of width\n",
      "        effective_rank: the low rank part of the singular values profile is::\n",
      "        \n",
      "            (1 - tail_strength) * exp(-1.0 * (i / effective_rank) ** 2)\n",
      "        \n",
      "        The remaining singular values' tail is fat, decreasing as::\n",
      "        \n",
      "            tail_strength * exp(-0.1 * i / effective_rank).\n",
      "        \n",
      "        The low rank part of the profile can be considered the structured\n",
      "        signal part of the data while the tail can be considered the noisy\n",
      "        part of the data that cannot be summarized by a low number of linear\n",
      "        components (singular vectors).\n",
      "        \n",
      "        This kind of singular profiles is often seen in practice, for instance:\n",
      "         - gray level pictures of faces\n",
      "         - TF-IDF vectors of text documents crawled from the web\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, optional (default=100)\n",
      "            The number of features.\n",
      "        \n",
      "        effective_rank : int, optional (default=10)\n",
      "            The approximate number of singular vectors required to explain most of\n",
      "            the data by linear combinations.\n",
      "        \n",
      "        tail_strength : float between 0.0 and 1.0, optional (default=0.5)\n",
      "            The relative importance of the fat noisy tail of the singular values\n",
      "            profile.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The matrix.\n",
      "    \n",
      "    make_moons(n_samples=100, shuffle=True, noise=None, random_state=None)\n",
      "        Make two interleaving half circles\n",
      "        \n",
      "        A simple toy dataset to visualize clustering and classification\n",
      "        algorithms. Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The total number of points generated.\n",
      "        \n",
      "        shuffle : bool, optional (default=True)\n",
      "            Whether to shuffle the samples.\n",
      "        \n",
      "        noise : double or None (default=None)\n",
      "            Standard deviation of Gaussian noise added to the data.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset shuffling and noise.\n",
      "            Pass an int for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 2]\n",
      "            The generated samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The integer labels (0 or 1) for class membership of each sample.\n",
      "    \n",
      "    make_multilabel_classification(n_samples=100, n_features=20, n_classes=5, n_labels=2, length=50, allow_unlabeled=True, sparse=False, return_indicator='dense', return_distributions=False, random_state=None)\n",
      "        Generate a random multilabel classification problem.\n",
      "        \n",
      "        For each sample, the generative process is:\n",
      "            - pick the number of labels: n ~ Poisson(n_labels)\n",
      "            - n times, choose a class c: c ~ Multinomial(theta)\n",
      "            - pick the document length: k ~ Poisson(length)\n",
      "            - k times, choose a word: w ~ Multinomial(theta_c)\n",
      "        \n",
      "        In the above process, rejection sampling is used to make sure that\n",
      "        n is never zero or more than `n_classes`, and that the document length\n",
      "        is never zero. Likewise, we reject classes which have already been chosen.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, optional (default=20)\n",
      "            The total number of features.\n",
      "        \n",
      "        n_classes : int, optional (default=5)\n",
      "            The number of classes of the classification problem.\n",
      "        \n",
      "        n_labels : int, optional (default=2)\n",
      "            The average number of labels per instance. More precisely, the number\n",
      "            of labels per sample is drawn from a Poisson distribution with\n",
      "            ``n_labels`` as its expected value, but samples are bounded (using\n",
      "            rejection sampling) by ``n_classes``, and must be nonzero if\n",
      "            ``allow_unlabeled`` is False.\n",
      "        \n",
      "        length : int, optional (default=50)\n",
      "            The sum of the features (number of words if documents) is drawn from\n",
      "            a Poisson distribution with this expected value.\n",
      "        \n",
      "        allow_unlabeled : bool, optional (default=True)\n",
      "            If ``True``, some instances might not belong to any class.\n",
      "        \n",
      "        sparse : bool, optional (default=False)\n",
      "            If ``True``, return a sparse feature matrix\n",
      "        \n",
      "            .. versionadded:: 0.17\n",
      "               parameter to allow *sparse* output.\n",
      "        \n",
      "        return_indicator : 'dense' (default) | 'sparse' | False\n",
      "            If ``dense`` return ``Y`` in the dense binary indicator format. If\n",
      "            ``'sparse'`` return ``Y`` in the sparse binary indicator format.\n",
      "            ``False`` returns a list of lists of labels.\n",
      "        \n",
      "        return_distributions : bool, optional (default=False)\n",
      "            If ``True``, return the prior class probability and conditional\n",
      "            probabilities of features given classes, from which the data was\n",
      "            drawn.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The generated samples.\n",
      "        \n",
      "        Y : array or sparse CSR matrix of shape [n_samples, n_classes]\n",
      "            The label sets.\n",
      "        \n",
      "        p_c : array, shape [n_classes]\n",
      "            The probability of each class being drawn. Only returned if\n",
      "            ``return_distributions=True``.\n",
      "        \n",
      "        p_w_c : array, shape [n_features, n_classes]\n",
      "            The probability of each feature being drawn given each class.\n",
      "            Only returned if ``return_distributions=True``.\n",
      "    \n",
      "    make_regression(n_samples=100, n_features=100, n_informative=10, n_targets=1, bias=0.0, effective_rank=None, tail_strength=0.5, noise=0.0, shuffle=True, coef=False, random_state=None)\n",
      "        Generate a random regression problem.\n",
      "        \n",
      "        The input set can either be well conditioned (by default) or have a low\n",
      "        rank-fat tail singular profile. See :func:`make_low_rank_matrix` for\n",
      "        more details.\n",
      "        \n",
      "        The output is generated by applying a (potentially biased) random linear\n",
      "        regression model with `n_informative` nonzero regressors to the previously\n",
      "        generated input and some gaussian centered noise with some adjustable\n",
      "        scale.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, optional (default=100)\n",
      "            The number of features.\n",
      "        \n",
      "        n_informative : int, optional (default=10)\n",
      "            The number of informative features, i.e., the number of features used\n",
      "            to build the linear model used to generate the output.\n",
      "        \n",
      "        n_targets : int, optional (default=1)\n",
      "            The number of regression targets, i.e., the dimension of the y output\n",
      "            vector associated with a sample. By default, the output is a scalar.\n",
      "        \n",
      "        bias : float, optional (default=0.0)\n",
      "            The bias term in the underlying linear model.\n",
      "        \n",
      "        effective_rank : int or None, optional (default=None)\n",
      "            if not None:\n",
      "                The approximate number of singular vectors required to explain most\n",
      "                of the input data by linear combinations. Using this kind of\n",
      "                singular spectrum in the input allows the generator to reproduce\n",
      "                the correlations often observed in practice.\n",
      "            if None:\n",
      "                The input set is well conditioned, centered and gaussian with\n",
      "                unit variance.\n",
      "        \n",
      "        tail_strength : float between 0.0 and 1.0, optional (default=0.5)\n",
      "            The relative importance of the fat noisy tail of the singular values\n",
      "            profile if `effective_rank` is not None.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        shuffle : boolean, optional (default=True)\n",
      "            Shuffle the samples and the features.\n",
      "        \n",
      "        coef : boolean, optional (default=False)\n",
      "            If True, the coefficients of the underlying linear model are returned.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The input samples.\n",
      "        \n",
      "        y : array of shape [n_samples] or [n_samples, n_targets]\n",
      "            The output values.\n",
      "        \n",
      "        coef : array of shape [n_features] or [n_features, n_targets], optional\n",
      "            The coefficient of the underlying linear model. It is returned only if\n",
      "            coef is True.\n",
      "    \n",
      "    make_s_curve(n_samples=100, noise=0.0, random_state=None)\n",
      "        Generate an S curve dataset.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of sample points on the S curve.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 3]\n",
      "            The points.\n",
      "        \n",
      "        t : array of shape [n_samples]\n",
      "            The univariate position of the sample according to the main dimension\n",
      "            of the points in the manifold.\n",
      "    \n",
      "    make_sparse_coded_signal(n_samples, n_components, n_features, n_nonzero_coefs, random_state=None)\n",
      "        Generate a signal as a sparse combination of dictionary elements.\n",
      "        \n",
      "        Returns a matrix Y = DX, such as D is (n_features, n_components),\n",
      "        X is (n_components, n_samples) and each column of X has exactly\n",
      "        n_nonzero_coefs non-zero elements.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int\n",
      "            number of samples to generate\n",
      "        \n",
      "        n_components :  int,\n",
      "            number of components in the dictionary\n",
      "        \n",
      "        n_features : int\n",
      "            number of features of the dataset to generate\n",
      "        \n",
      "        n_nonzero_coefs : int\n",
      "            number of active (non-zero) coefficients in each sample\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : array of shape [n_features, n_samples]\n",
      "            The encoded signal (Y).\n",
      "        \n",
      "        dictionary : array of shape [n_features, n_components]\n",
      "            The dictionary with normalized components (D).\n",
      "        \n",
      "        code : array of shape [n_components, n_samples]\n",
      "            The sparse code such that each column of this matrix has exactly\n",
      "            n_nonzero_coefs non-zero items (X).\n",
      "    \n",
      "    make_sparse_spd_matrix(dim=1, alpha=0.95, norm_diag=False, smallest_coef=0.1, largest_coef=0.9, random_state=None)\n",
      "        Generate a sparse symmetric definite positive matrix.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dim : integer, optional (default=1)\n",
      "            The size of the random matrix to generate.\n",
      "        \n",
      "        alpha : float between 0 and 1, optional (default=0.95)\n",
      "            The probability that a coefficient is zero (see notes). Larger values\n",
      "            enforce more sparsity.\n",
      "        \n",
      "        norm_diag : boolean, optional (default=False)\n",
      "            Whether to normalize the output matrix to make the leading diagonal\n",
      "            elements all 1\n",
      "        \n",
      "        smallest_coef : float between 0 and 1, optional (default=0.1)\n",
      "            The value of the smallest coefficient.\n",
      "        \n",
      "        largest_coef : float between 0 and 1, optional (default=0.9)\n",
      "            The value of the largest coefficient.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        prec : sparse matrix of shape (dim, dim)\n",
      "            The generated matrix.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The sparsity is actually imposed on the cholesky factor of the matrix.\n",
      "        Thus alpha does not translate directly into the filling fraction of\n",
      "        the matrix itself.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_spd_matrix\n",
      "    \n",
      "    make_sparse_uncorrelated(n_samples=100, n_features=10, random_state=None)\n",
      "        Generate a random regression problem with sparse uncorrelated design\n",
      "        \n",
      "        This dataset is described in Celeux et al [1]. as::\n",
      "        \n",
      "            X ~ N(0, 1)\n",
      "            y(X) = X[:, 0] + 2 * X[:, 1] - 2 * X[:, 2] - 1.5 * X[:, 3]\n",
      "        \n",
      "        Only the first 4 features are informative. The remaining features are\n",
      "        useless.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, optional (default=10)\n",
      "            The number of features.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The input samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. Celeux, M. El Anbari, J.-M. Marin, C. P. Robert,\n",
      "               \"Regularization in regression: comparing Bayesian and frequentist\n",
      "               methods in a poorly informative situation\", 2009.\n",
      "    \n",
      "    make_spd_matrix(n_dim, random_state=None)\n",
      "        Generate a random symmetric, positive-definite matrix.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_dim : int\n",
      "            The matrix dimension.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_dim, n_dim]\n",
      "            The random symmetric, positive-definite matrix.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_sparse_spd_matrix\n",
      "    \n",
      "    make_swiss_roll(n_samples=100, noise=0.0, random_state=None)\n",
      "        Generate a swiss roll dataset.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of sample points on the S curve.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 3]\n",
      "            The points.\n",
      "        \n",
      "        t : array of shape [n_samples]\n",
      "            The univariate position of the sample according to the main dimension\n",
      "            of the points in the manifold.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The algorithm is from Marsland [1].\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] S. Marsland, \"Machine Learning: An Algorithmic Perspective\",\n",
      "               Chapter 10, 2009.\n",
      "               http://seat.massey.ac.nz/personal/s.r.marsland/Code/10/lle.py\n",
      "\n",
      "DATA\n",
      "    __all__ = ['clear_data_home', 'dump_svmlight_file', 'fetch_20newsgroup...\n",
      "\n",
      "FILE\n",
      "    /usr/local/lib/python3.7/site-packages/sklearn/datasets/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "print(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(digits.data[:-1], digits.target[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(digits.data[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "s = pickle.dumps(clf)\n",
    "clf2 = pickle.loads(s)\n",
    "clf2.predict(X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#导入数据集\n",
    "#这里将全部数据用于训练，并没有对数据进行划分，上例中\n",
    "#将数据划分为训练和测试数据，后面会讲到交叉验证\n",
    "loaded_data = datasets.load_boston()\n",
    "data_X = loaded_data.data\n",
    "data_y = loaded_data.target\n",
    "\n",
    "#设置线性回归模块\n",
    "model = LinearRegression()\n",
    "#训练数据，得出参数\n",
    "model.fit(data_X, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.  21.6 34.7 33.4]\n"
     ]
    }
   ],
   "source": [
    "print(data_y[:4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.00384338 25.02556238 30.56759672 28.60703649]\n",
      "[24.  21.6 34.7 33.4]\n"
     ]
    }
   ],
   "source": [
    "#利用模型，对新数据，进行预测，与原标签进行比较\n",
    "print(model.predict(data_X[:4,:]))\n",
    "print(data_y[:4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "myboston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myboston.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(myboston.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.00632,\n",
       "  18.0,\n",
       "  2.31,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  6.575,\n",
       "  65.2,\n",
       "  4.09,\n",
       "  1.0,\n",
       "  296.0,\n",
       "  15.3,\n",
       "  396.9,\n",
       "  4.98],\n",
       " [0.02731,\n",
       "  0.0,\n",
       "  7.07,\n",
       "  0.0,\n",
       "  0.469,\n",
       "  6.421,\n",
       "  78.9,\n",
       "  4.9671,\n",
       "  2.0,\n",
       "  242.0,\n",
       "  17.8,\n",
       "  396.9,\n",
       "  9.14],\n",
       " [0.02729,\n",
       "  0.0,\n",
       "  7.07,\n",
       "  0.0,\n",
       "  0.469,\n",
       "  7.185,\n",
       "  61.1,\n",
       "  4.9671,\n",
       "  2.0,\n",
       "  242.0,\n",
       "  17.8,\n",
       "  392.83,\n",
       "  4.03],\n",
       " [0.03237,\n",
       "  0.0,\n",
       "  2.18,\n",
       "  0.0,\n",
       "  0.458,\n",
       "  6.998,\n",
       "  45.8,\n",
       "  6.0622,\n",
       "  3.0,\n",
       "  222.0,\n",
       "  18.7,\n",
       "  394.63,\n",
       "  2.94],\n",
       " [0.06905,\n",
       "  0.0,\n",
       "  2.18,\n",
       "  0.0,\n",
       "  0.458,\n",
       "  7.147,\n",
       "  54.2,\n",
       "  6.0622,\n",
       "  3.0,\n",
       "  222.0,\n",
       "  18.7,\n",
       "  396.9,\n",
       "  5.33],\n",
       " [0.02985,\n",
       "  0.0,\n",
       "  2.18,\n",
       "  0.0,\n",
       "  0.458,\n",
       "  6.43,\n",
       "  58.7,\n",
       "  6.0622,\n",
       "  3.0,\n",
       "  222.0,\n",
       "  18.7,\n",
       "  394.12,\n",
       "  5.21],\n",
       " [0.08829,\n",
       "  12.5,\n",
       "  7.87,\n",
       "  0.0,\n",
       "  0.524,\n",
       "  6.012,\n",
       "  66.6,\n",
       "  5.5605,\n",
       "  5.0,\n",
       "  311.0,\n",
       "  15.2,\n",
       "  395.6,\n",
       "  12.43],\n",
       " [0.14455,\n",
       "  12.5,\n",
       "  7.87,\n",
       "  0.0,\n",
       "  0.524,\n",
       "  6.172,\n",
       "  96.1,\n",
       "  5.9505,\n",
       "  5.0,\n",
       "  311.0,\n",
       "  15.2,\n",
       "  396.9,\n",
       "  19.15],\n",
       " [0.21124,\n",
       "  12.5,\n",
       "  7.87,\n",
       "  0.0,\n",
       "  0.524,\n",
       "  5.631,\n",
       "  100.0,\n",
       "  6.0821,\n",
       "  5.0,\n",
       "  311.0,\n",
       "  15.2,\n",
       "  386.63,\n",
       "  29.93],\n",
       " [0.17004,\n",
       "  12.5,\n",
       "  7.87,\n",
       "  0.0,\n",
       "  0.524,\n",
       "  6.004,\n",
       "  85.9,\n",
       "  6.5921,\n",
       "  5.0,\n",
       "  311.0,\n",
       "  15.2,\n",
       "  386.71,\n",
       "  17.1],\n",
       " [0.22489,\n",
       "  12.5,\n",
       "  7.87,\n",
       "  0.0,\n",
       "  0.524,\n",
       "  6.377,\n",
       "  94.3,\n",
       "  6.3467,\n",
       "  5.0,\n",
       "  311.0,\n",
       "  15.2,\n",
       "  392.52,\n",
       "  20.45],\n",
       " [0.11747,\n",
       "  12.5,\n",
       "  7.87,\n",
       "  0.0,\n",
       "  0.524,\n",
       "  6.009,\n",
       "  82.9,\n",
       "  6.2267,\n",
       "  5.0,\n",
       "  311.0,\n",
       "  15.2,\n",
       "  396.9,\n",
       "  13.27],\n",
       " [0.09378,\n",
       "  12.5,\n",
       "  7.87,\n",
       "  0.0,\n",
       "  0.524,\n",
       "  5.889,\n",
       "  39.0,\n",
       "  5.4509,\n",
       "  5.0,\n",
       "  311.0,\n",
       "  15.2,\n",
       "  390.5,\n",
       "  15.71],\n",
       " [0.62976,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.949,\n",
       "  61.8,\n",
       "  4.7075,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  396.9,\n",
       "  8.26],\n",
       " [0.63796,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  6.096,\n",
       "  84.5,\n",
       "  4.4619,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  380.02,\n",
       "  10.26],\n",
       " [0.62739,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.834,\n",
       "  56.5,\n",
       "  4.4986,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  395.62,\n",
       "  8.47],\n",
       " [1.05393,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.935,\n",
       "  29.3,\n",
       "  4.4986,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  386.85,\n",
       "  6.58],\n",
       " [0.7842,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.99,\n",
       "  81.7,\n",
       "  4.2579,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  386.75,\n",
       "  14.67],\n",
       " [0.80271,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.456,\n",
       "  36.6,\n",
       "  3.7965,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  288.99,\n",
       "  11.69],\n",
       " [0.7258,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.727,\n",
       "  69.5,\n",
       "  3.7965,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  390.95,\n",
       "  11.28],\n",
       " [1.25179,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.57,\n",
       "  98.1,\n",
       "  3.7979,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  376.57,\n",
       "  21.02],\n",
       " [0.85204,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.965,\n",
       "  89.2,\n",
       "  4.0123,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  392.53,\n",
       "  13.83],\n",
       " [1.23247,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  6.142,\n",
       "  91.7,\n",
       "  3.9769,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  396.9,\n",
       "  18.72],\n",
       " [0.98843,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.813,\n",
       "  100.0,\n",
       "  4.0952,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  394.54,\n",
       "  19.88],\n",
       " [0.75026,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.924,\n",
       "  94.1,\n",
       "  4.3996,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  394.33,\n",
       "  16.3],\n",
       " [0.84054,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.599,\n",
       "  85.7,\n",
       "  4.4546,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  303.42,\n",
       "  16.51],\n",
       " [0.67191,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.813,\n",
       "  90.3,\n",
       "  4.682,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  376.88,\n",
       "  14.81],\n",
       " [0.95577,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  6.047,\n",
       "  88.8,\n",
       "  4.4534,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  306.38,\n",
       "  17.28],\n",
       " [0.77299,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  6.495,\n",
       "  94.4,\n",
       "  4.4547,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  387.94,\n",
       "  12.8],\n",
       " [1.00245,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  6.674,\n",
       "  87.3,\n",
       "  4.239,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  380.23,\n",
       "  11.98],\n",
       " [1.13081,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.713,\n",
       "  94.1,\n",
       "  4.233,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  360.17,\n",
       "  22.6],\n",
       " [1.35472,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  6.072,\n",
       "  100.0,\n",
       "  4.175,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  376.73,\n",
       "  13.04],\n",
       " [1.38799,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.95,\n",
       "  82.0,\n",
       "  3.99,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  232.6,\n",
       "  27.71],\n",
       " [1.15172,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  5.701,\n",
       "  95.0,\n",
       "  3.7872,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  358.77,\n",
       "  18.35],\n",
       " [1.61282,\n",
       "  0.0,\n",
       "  8.14,\n",
       "  0.0,\n",
       "  0.538,\n",
       "  6.096,\n",
       "  96.9,\n",
       "  3.7598,\n",
       "  4.0,\n",
       "  307.0,\n",
       "  21.0,\n",
       "  248.31,\n",
       "  20.34],\n",
       " [0.06417,\n",
       "  0.0,\n",
       "  5.96,\n",
       "  0.0,\n",
       "  0.499,\n",
       "  5.933,\n",
       "  68.2,\n",
       "  3.3603,\n",
       "  5.0,\n",
       "  279.0,\n",
       "  19.2,\n",
       "  396.9,\n",
       "  9.68],\n",
       " [0.09744,\n",
       "  0.0,\n",
       "  5.96,\n",
       "  0.0,\n",
       "  0.499,\n",
       "  5.841,\n",
       "  61.4,\n",
       "  3.3779,\n",
       "  5.0,\n",
       "  279.0,\n",
       "  19.2,\n",
       "  377.56,\n",
       "  11.41],\n",
       " [0.08014,\n",
       "  0.0,\n",
       "  5.96,\n",
       "  0.0,\n",
       "  0.499,\n",
       "  5.85,\n",
       "  41.5,\n",
       "  3.9342,\n",
       "  5.0,\n",
       "  279.0,\n",
       "  19.2,\n",
       "  396.9,\n",
       "  8.77],\n",
       " [0.17505,\n",
       "  0.0,\n",
       "  5.96,\n",
       "  0.0,\n",
       "  0.499,\n",
       "  5.966,\n",
       "  30.2,\n",
       "  3.8473,\n",
       "  5.0,\n",
       "  279.0,\n",
       "  19.2,\n",
       "  393.43,\n",
       "  10.13],\n",
       " [0.02763,\n",
       "  75.0,\n",
       "  2.95,\n",
       "  0.0,\n",
       "  0.428,\n",
       "  6.595,\n",
       "  21.8,\n",
       "  5.4011,\n",
       "  3.0,\n",
       "  252.0,\n",
       "  18.3,\n",
       "  395.63,\n",
       "  4.32],\n",
       " [0.03359,\n",
       "  75.0,\n",
       "  2.95,\n",
       "  0.0,\n",
       "  0.428,\n",
       "  7.024,\n",
       "  15.8,\n",
       "  5.4011,\n",
       "  3.0,\n",
       "  252.0,\n",
       "  18.3,\n",
       "  395.62,\n",
       "  1.98],\n",
       " [0.12744,\n",
       "  0.0,\n",
       "  6.91,\n",
       "  0.0,\n",
       "  0.448,\n",
       "  6.77,\n",
       "  2.9,\n",
       "  5.7209,\n",
       "  3.0,\n",
       "  233.0,\n",
       "  17.9,\n",
       "  385.41,\n",
       "  4.84],\n",
       " [0.1415,\n",
       "  0.0,\n",
       "  6.91,\n",
       "  0.0,\n",
       "  0.448,\n",
       "  6.169,\n",
       "  6.6,\n",
       "  5.7209,\n",
       "  3.0,\n",
       "  233.0,\n",
       "  17.9,\n",
       "  383.37,\n",
       "  5.81],\n",
       " [0.15936,\n",
       "  0.0,\n",
       "  6.91,\n",
       "  0.0,\n",
       "  0.448,\n",
       "  6.211,\n",
       "  6.5,\n",
       "  5.7209,\n",
       "  3.0,\n",
       "  233.0,\n",
       "  17.9,\n",
       "  394.46,\n",
       "  7.44],\n",
       " [0.12269,\n",
       "  0.0,\n",
       "  6.91,\n",
       "  0.0,\n",
       "  0.448,\n",
       "  6.069,\n",
       "  40.0,\n",
       "  5.7209,\n",
       "  3.0,\n",
       "  233.0,\n",
       "  17.9,\n",
       "  389.39,\n",
       "  9.55],\n",
       " [0.17142,\n",
       "  0.0,\n",
       "  6.91,\n",
       "  0.0,\n",
       "  0.448,\n",
       "  5.682,\n",
       "  33.8,\n",
       "  5.1004,\n",
       "  3.0,\n",
       "  233.0,\n",
       "  17.9,\n",
       "  396.9,\n",
       "  10.21],\n",
       " [0.18836,\n",
       "  0.0,\n",
       "  6.91,\n",
       "  0.0,\n",
       "  0.448,\n",
       "  5.786,\n",
       "  33.3,\n",
       "  5.1004,\n",
       "  3.0,\n",
       "  233.0,\n",
       "  17.9,\n",
       "  396.9,\n",
       "  14.15],\n",
       " [0.22927,\n",
       "  0.0,\n",
       "  6.91,\n",
       "  0.0,\n",
       "  0.448,\n",
       "  6.03,\n",
       "  85.5,\n",
       "  5.6894,\n",
       "  3.0,\n",
       "  233.0,\n",
       "  17.9,\n",
       "  392.74,\n",
       "  18.8],\n",
       " [0.25387,\n",
       "  0.0,\n",
       "  6.91,\n",
       "  0.0,\n",
       "  0.448,\n",
       "  5.399,\n",
       "  95.3,\n",
       "  5.87,\n",
       "  3.0,\n",
       "  233.0,\n",
       "  17.9,\n",
       "  396.9,\n",
       "  30.81],\n",
       " [0.21977,\n",
       "  0.0,\n",
       "  6.91,\n",
       "  0.0,\n",
       "  0.448,\n",
       "  5.602,\n",
       "  62.0,\n",
       "  6.0877,\n",
       "  3.0,\n",
       "  233.0,\n",
       "  17.9,\n",
       "  396.9,\n",
       "  16.2],\n",
       " [0.08873,\n",
       "  21.0,\n",
       "  5.64,\n",
       "  0.0,\n",
       "  0.439,\n",
       "  5.963,\n",
       "  45.7,\n",
       "  6.8147,\n",
       "  4.0,\n",
       "  243.0,\n",
       "  16.8,\n",
       "  395.56,\n",
       "  13.45],\n",
       " [0.04337,\n",
       "  21.0,\n",
       "  5.64,\n",
       "  0.0,\n",
       "  0.439,\n",
       "  6.115,\n",
       "  63.0,\n",
       "  6.8147,\n",
       "  4.0,\n",
       "  243.0,\n",
       "  16.8,\n",
       "  393.97,\n",
       "  9.43],\n",
       " [0.0536,\n",
       "  21.0,\n",
       "  5.64,\n",
       "  0.0,\n",
       "  0.439,\n",
       "  6.511,\n",
       "  21.1,\n",
       "  6.8147,\n",
       "  4.0,\n",
       "  243.0,\n",
       "  16.8,\n",
       "  396.9,\n",
       "  5.28],\n",
       " [0.04981,\n",
       "  21.0,\n",
       "  5.64,\n",
       "  0.0,\n",
       "  0.439,\n",
       "  5.998,\n",
       "  21.4,\n",
       "  6.8147,\n",
       "  4.0,\n",
       "  243.0,\n",
       "  16.8,\n",
       "  396.9,\n",
       "  8.43],\n",
       " [0.0136,\n",
       "  75.0,\n",
       "  4.0,\n",
       "  0.0,\n",
       "  0.41,\n",
       "  5.888,\n",
       "  47.6,\n",
       "  7.3197,\n",
       "  3.0,\n",
       "  469.0,\n",
       "  21.1,\n",
       "  396.9,\n",
       "  14.8],\n",
       " [0.01311,\n",
       "  90.0,\n",
       "  1.22,\n",
       "  0.0,\n",
       "  0.403,\n",
       "  7.249,\n",
       "  21.9,\n",
       "  8.6966,\n",
       "  5.0,\n",
       "  226.0,\n",
       "  17.9,\n",
       "  395.93,\n",
       "  4.81],\n",
       " [0.02055,\n",
       "  85.0,\n",
       "  0.74,\n",
       "  0.0,\n",
       "  0.41,\n",
       "  6.383,\n",
       "  35.7,\n",
       "  9.1876,\n",
       "  2.0,\n",
       "  313.0,\n",
       "  17.3,\n",
       "  396.9,\n",
       "  5.77],\n",
       " [0.01432,\n",
       "  100.0,\n",
       "  1.32,\n",
       "  0.0,\n",
       "  0.411,\n",
       "  6.816,\n",
       "  40.5,\n",
       "  8.3248,\n",
       "  5.0,\n",
       "  256.0,\n",
       "  15.1,\n",
       "  392.9,\n",
       "  3.95],\n",
       " [0.15445,\n",
       "  25.0,\n",
       "  5.13,\n",
       "  0.0,\n",
       "  0.453,\n",
       "  6.145,\n",
       "  29.2,\n",
       "  7.8148,\n",
       "  8.0,\n",
       "  284.0,\n",
       "  19.7,\n",
       "  390.68,\n",
       "  6.86],\n",
       " [0.10328,\n",
       "  25.0,\n",
       "  5.13,\n",
       "  0.0,\n",
       "  0.453,\n",
       "  5.927,\n",
       "  47.2,\n",
       "  6.932,\n",
       "  8.0,\n",
       "  284.0,\n",
       "  19.7,\n",
       "  396.9,\n",
       "  9.22],\n",
       " [0.14932,\n",
       "  25.0,\n",
       "  5.13,\n",
       "  0.0,\n",
       "  0.453,\n",
       "  5.741,\n",
       "  66.2,\n",
       "  7.2254,\n",
       "  8.0,\n",
       "  284.0,\n",
       "  19.7,\n",
       "  395.11,\n",
       "  13.15],\n",
       " [0.17171,\n",
       "  25.0,\n",
       "  5.13,\n",
       "  0.0,\n",
       "  0.453,\n",
       "  5.966,\n",
       "  93.4,\n",
       "  6.8185,\n",
       "  8.0,\n",
       "  284.0,\n",
       "  19.7,\n",
       "  378.08,\n",
       "  14.44],\n",
       " [0.11027,\n",
       "  25.0,\n",
       "  5.13,\n",
       "  0.0,\n",
       "  0.453,\n",
       "  6.456,\n",
       "  67.8,\n",
       "  7.2255,\n",
       "  8.0,\n",
       "  284.0,\n",
       "  19.7,\n",
       "  396.9,\n",
       "  6.73],\n",
       " [0.1265,\n",
       "  25.0,\n",
       "  5.13,\n",
       "  0.0,\n",
       "  0.453,\n",
       "  6.762,\n",
       "  43.4,\n",
       "  7.9809,\n",
       "  8.0,\n",
       "  284.0,\n",
       "  19.7,\n",
       "  395.58,\n",
       "  9.5],\n",
       " [0.01951,\n",
       "  17.5,\n",
       "  1.38,\n",
       "  0.0,\n",
       "  0.4161,\n",
       "  7.104,\n",
       "  59.5,\n",
       "  9.2229,\n",
       "  3.0,\n",
       "  216.0,\n",
       "  18.6,\n",
       "  393.24,\n",
       "  8.05],\n",
       " [0.03584,\n",
       "  80.0,\n",
       "  3.37,\n",
       "  0.0,\n",
       "  0.398,\n",
       "  6.29,\n",
       "  17.8,\n",
       "  6.6115,\n",
       "  4.0,\n",
       "  337.0,\n",
       "  16.1,\n",
       "  396.9,\n",
       "  4.67],\n",
       " [0.04379,\n",
       "  80.0,\n",
       "  3.37,\n",
       "  0.0,\n",
       "  0.398,\n",
       "  5.787,\n",
       "  31.1,\n",
       "  6.6115,\n",
       "  4.0,\n",
       "  337.0,\n",
       "  16.1,\n",
       "  396.9,\n",
       "  10.24],\n",
       " [0.05789,\n",
       "  12.5,\n",
       "  6.07,\n",
       "  0.0,\n",
       "  0.409,\n",
       "  5.878,\n",
       "  21.4,\n",
       "  6.498,\n",
       "  4.0,\n",
       "  345.0,\n",
       "  18.9,\n",
       "  396.21,\n",
       "  8.1],\n",
       " [0.13554,\n",
       "  12.5,\n",
       "  6.07,\n",
       "  0.0,\n",
       "  0.409,\n",
       "  5.594,\n",
       "  36.8,\n",
       "  6.498,\n",
       "  4.0,\n",
       "  345.0,\n",
       "  18.9,\n",
       "  396.9,\n",
       "  13.09],\n",
       " [0.12816,\n",
       "  12.5,\n",
       "  6.07,\n",
       "  0.0,\n",
       "  0.409,\n",
       "  5.885,\n",
       "  33.0,\n",
       "  6.498,\n",
       "  4.0,\n",
       "  345.0,\n",
       "  18.9,\n",
       "  396.9,\n",
       "  8.79],\n",
       " [0.08826,\n",
       "  0.0,\n",
       "  10.81,\n",
       "  0.0,\n",
       "  0.413,\n",
       "  6.417,\n",
       "  6.6,\n",
       "  5.2873,\n",
       "  4.0,\n",
       "  305.0,\n",
       "  19.2,\n",
       "  383.73,\n",
       "  6.72],\n",
       " [0.15876,\n",
       "  0.0,\n",
       "  10.81,\n",
       "  0.0,\n",
       "  0.413,\n",
       "  5.961,\n",
       "  17.5,\n",
       "  5.2873,\n",
       "  4.0,\n",
       "  305.0,\n",
       "  19.2,\n",
       "  376.94,\n",
       "  9.88],\n",
       " [0.09164,\n",
       "  0.0,\n",
       "  10.81,\n",
       "  0.0,\n",
       "  0.413,\n",
       "  6.065,\n",
       "  7.8,\n",
       "  5.2873,\n",
       "  4.0,\n",
       "  305.0,\n",
       "  19.2,\n",
       "  390.91,\n",
       "  5.52],\n",
       " [0.19539,\n",
       "  0.0,\n",
       "  10.81,\n",
       "  0.0,\n",
       "  0.413,\n",
       "  6.245,\n",
       "  6.2,\n",
       "  5.2873,\n",
       "  4.0,\n",
       "  305.0,\n",
       "  19.2,\n",
       "  377.17,\n",
       "  7.54],\n",
       " [0.07896,\n",
       "  0.0,\n",
       "  12.83,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  6.273,\n",
       "  6.0,\n",
       "  4.2515,\n",
       "  5.0,\n",
       "  398.0,\n",
       "  18.7,\n",
       "  394.92,\n",
       "  6.78],\n",
       " [0.09512,\n",
       "  0.0,\n",
       "  12.83,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  6.286,\n",
       "  45.0,\n",
       "  4.5026,\n",
       "  5.0,\n",
       "  398.0,\n",
       "  18.7,\n",
       "  383.23,\n",
       "  8.94],\n",
       " [0.10153,\n",
       "  0.0,\n",
       "  12.83,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  6.279,\n",
       "  74.5,\n",
       "  4.0522,\n",
       "  5.0,\n",
       "  398.0,\n",
       "  18.7,\n",
       "  373.66,\n",
       "  11.97],\n",
       " [0.08707,\n",
       "  0.0,\n",
       "  12.83,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  6.14,\n",
       "  45.8,\n",
       "  4.0905,\n",
       "  5.0,\n",
       "  398.0,\n",
       "  18.7,\n",
       "  386.96,\n",
       "  10.27],\n",
       " [0.05646,\n",
       "  0.0,\n",
       "  12.83,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  6.232,\n",
       "  53.7,\n",
       "  5.0141,\n",
       "  5.0,\n",
       "  398.0,\n",
       "  18.7,\n",
       "  386.4,\n",
       "  12.34],\n",
       " [0.08387,\n",
       "  0.0,\n",
       "  12.83,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  5.874,\n",
       "  36.6,\n",
       "  4.5026,\n",
       "  5.0,\n",
       "  398.0,\n",
       "  18.7,\n",
       "  396.06,\n",
       "  9.1],\n",
       " [0.04113,\n",
       "  25.0,\n",
       "  4.86,\n",
       "  0.0,\n",
       "  0.426,\n",
       "  6.727,\n",
       "  33.5,\n",
       "  5.4007,\n",
       "  4.0,\n",
       "  281.0,\n",
       "  19.0,\n",
       "  396.9,\n",
       "  5.29],\n",
       " [0.04462,\n",
       "  25.0,\n",
       "  4.86,\n",
       "  0.0,\n",
       "  0.426,\n",
       "  6.619,\n",
       "  70.4,\n",
       "  5.4007,\n",
       "  4.0,\n",
       "  281.0,\n",
       "  19.0,\n",
       "  395.63,\n",
       "  7.22],\n",
       " [0.03659,\n",
       "  25.0,\n",
       "  4.86,\n",
       "  0.0,\n",
       "  0.426,\n",
       "  6.302,\n",
       "  32.2,\n",
       "  5.4007,\n",
       "  4.0,\n",
       "  281.0,\n",
       "  19.0,\n",
       "  396.9,\n",
       "  6.72],\n",
       " [0.03551,\n",
       "  25.0,\n",
       "  4.86,\n",
       "  0.0,\n",
       "  0.426,\n",
       "  6.167,\n",
       "  46.7,\n",
       "  5.4007,\n",
       "  4.0,\n",
       "  281.0,\n",
       "  19.0,\n",
       "  390.64,\n",
       "  7.51],\n",
       " [0.05059,\n",
       "  0.0,\n",
       "  4.49,\n",
       "  0.0,\n",
       "  0.449,\n",
       "  6.389,\n",
       "  48.0,\n",
       "  4.7794,\n",
       "  3.0,\n",
       "  247.0,\n",
       "  18.5,\n",
       "  396.9,\n",
       "  9.62],\n",
       " [0.05735,\n",
       "  0.0,\n",
       "  4.49,\n",
       "  0.0,\n",
       "  0.449,\n",
       "  6.63,\n",
       "  56.1,\n",
       "  4.4377,\n",
       "  3.0,\n",
       "  247.0,\n",
       "  18.5,\n",
       "  392.3,\n",
       "  6.53],\n",
       " [0.05188,\n",
       "  0.0,\n",
       "  4.49,\n",
       "  0.0,\n",
       "  0.449,\n",
       "  6.015,\n",
       "  45.1,\n",
       "  4.4272,\n",
       "  3.0,\n",
       "  247.0,\n",
       "  18.5,\n",
       "  395.99,\n",
       "  12.86],\n",
       " [0.07151,\n",
       "  0.0,\n",
       "  4.49,\n",
       "  0.0,\n",
       "  0.449,\n",
       "  6.121,\n",
       "  56.8,\n",
       "  3.7476,\n",
       "  3.0,\n",
       "  247.0,\n",
       "  18.5,\n",
       "  395.15,\n",
       "  8.44],\n",
       " [0.0566,\n",
       "  0.0,\n",
       "  3.41,\n",
       "  0.0,\n",
       "  0.489,\n",
       "  7.007,\n",
       "  86.3,\n",
       "  3.4217,\n",
       "  2.0,\n",
       "  270.0,\n",
       "  17.8,\n",
       "  396.9,\n",
       "  5.5],\n",
       " [0.05302,\n",
       "  0.0,\n",
       "  3.41,\n",
       "  0.0,\n",
       "  0.489,\n",
       "  7.079,\n",
       "  63.1,\n",
       "  3.4145,\n",
       "  2.0,\n",
       "  270.0,\n",
       "  17.8,\n",
       "  396.06,\n",
       "  5.7],\n",
       " [0.04684,\n",
       "  0.0,\n",
       "  3.41,\n",
       "  0.0,\n",
       "  0.489,\n",
       "  6.417,\n",
       "  66.1,\n",
       "  3.0923,\n",
       "  2.0,\n",
       "  270.0,\n",
       "  17.8,\n",
       "  392.18,\n",
       "  8.81],\n",
       " [0.03932,\n",
       "  0.0,\n",
       "  3.41,\n",
       "  0.0,\n",
       "  0.489,\n",
       "  6.405,\n",
       "  73.9,\n",
       "  3.0921,\n",
       "  2.0,\n",
       "  270.0,\n",
       "  17.8,\n",
       "  393.55,\n",
       "  8.2],\n",
       " [0.04203,\n",
       "  28.0,\n",
       "  15.04,\n",
       "  0.0,\n",
       "  0.464,\n",
       "  6.442,\n",
       "  53.6,\n",
       "  3.6659,\n",
       "  4.0,\n",
       "  270.0,\n",
       "  18.2,\n",
       "  395.01,\n",
       "  8.16],\n",
       " [0.02875,\n",
       "  28.0,\n",
       "  15.04,\n",
       "  0.0,\n",
       "  0.464,\n",
       "  6.211,\n",
       "  28.9,\n",
       "  3.6659,\n",
       "  4.0,\n",
       "  270.0,\n",
       "  18.2,\n",
       "  396.33,\n",
       "  6.21],\n",
       " [0.04294,\n",
       "  28.0,\n",
       "  15.04,\n",
       "  0.0,\n",
       "  0.464,\n",
       "  6.249,\n",
       "  77.3,\n",
       "  3.615,\n",
       "  4.0,\n",
       "  270.0,\n",
       "  18.2,\n",
       "  396.9,\n",
       "  10.59],\n",
       " [0.12204,\n",
       "  0.0,\n",
       "  2.89,\n",
       "  0.0,\n",
       "  0.445,\n",
       "  6.625,\n",
       "  57.8,\n",
       "  3.4952,\n",
       "  2.0,\n",
       "  276.0,\n",
       "  18.0,\n",
       "  357.98,\n",
       "  6.65],\n",
       " [0.11504,\n",
       "  0.0,\n",
       "  2.89,\n",
       "  0.0,\n",
       "  0.445,\n",
       "  6.163,\n",
       "  69.6,\n",
       "  3.4952,\n",
       "  2.0,\n",
       "  276.0,\n",
       "  18.0,\n",
       "  391.83,\n",
       "  11.34],\n",
       " [0.12083,\n",
       "  0.0,\n",
       "  2.89,\n",
       "  0.0,\n",
       "  0.445,\n",
       "  8.069,\n",
       "  76.0,\n",
       "  3.4952,\n",
       "  2.0,\n",
       "  276.0,\n",
       "  18.0,\n",
       "  396.9,\n",
       "  4.21],\n",
       " [0.08187,\n",
       "  0.0,\n",
       "  2.89,\n",
       "  0.0,\n",
       "  0.445,\n",
       "  7.82,\n",
       "  36.9,\n",
       "  3.4952,\n",
       "  2.0,\n",
       "  276.0,\n",
       "  18.0,\n",
       "  393.53,\n",
       "  3.57],\n",
       " [0.0686,\n",
       "  0.0,\n",
       "  2.89,\n",
       "  0.0,\n",
       "  0.445,\n",
       "  7.416,\n",
       "  62.5,\n",
       "  3.4952,\n",
       "  2.0,\n",
       "  276.0,\n",
       "  18.0,\n",
       "  396.9,\n",
       "  6.19],\n",
       " [0.14866,\n",
       "  0.0,\n",
       "  8.56,\n",
       "  0.0,\n",
       "  0.52,\n",
       "  6.727,\n",
       "  79.9,\n",
       "  2.7778,\n",
       "  5.0,\n",
       "  384.0,\n",
       "  20.9,\n",
       "  394.76,\n",
       "  9.42],\n",
       " [0.11432,\n",
       "  0.0,\n",
       "  8.56,\n",
       "  0.0,\n",
       "  0.52,\n",
       "  6.781,\n",
       "  71.3,\n",
       "  2.8561,\n",
       "  5.0,\n",
       "  384.0,\n",
       "  20.9,\n",
       "  395.58,\n",
       "  7.67],\n",
       " [0.22876,\n",
       "  0.0,\n",
       "  8.56,\n",
       "  0.0,\n",
       "  0.52,\n",
       "  6.405,\n",
       "  85.4,\n",
       "  2.7147,\n",
       "  5.0,\n",
       "  384.0,\n",
       "  20.9,\n",
       "  70.8,\n",
       "  10.63],\n",
       " [0.21161,\n",
       "  0.0,\n",
       "  8.56,\n",
       "  0.0,\n",
       "  0.52,\n",
       "  6.137,\n",
       "  87.4,\n",
       "  2.7147,\n",
       "  5.0,\n",
       "  384.0,\n",
       "  20.9,\n",
       "  394.47,\n",
       "  13.44],\n",
       " [0.1396,\n",
       "  0.0,\n",
       "  8.56,\n",
       "  0.0,\n",
       "  0.52,\n",
       "  6.167,\n",
       "  90.0,\n",
       "  2.421,\n",
       "  5.0,\n",
       "  384.0,\n",
       "  20.9,\n",
       "  392.69,\n",
       "  12.33],\n",
       " [0.13262,\n",
       "  0.0,\n",
       "  8.56,\n",
       "  0.0,\n",
       "  0.52,\n",
       "  5.851,\n",
       "  96.7,\n",
       "  2.1069,\n",
       "  5.0,\n",
       "  384.0,\n",
       "  20.9,\n",
       "  394.05,\n",
       "  16.47],\n",
       " [0.1712,\n",
       "  0.0,\n",
       "  8.56,\n",
       "  0.0,\n",
       "  0.52,\n",
       "  5.836,\n",
       "  91.9,\n",
       "  2.211,\n",
       "  5.0,\n",
       "  384.0,\n",
       "  20.9,\n",
       "  395.67,\n",
       "  18.66],\n",
       " [0.13117,\n",
       "  0.0,\n",
       "  8.56,\n",
       "  0.0,\n",
       "  0.52,\n",
       "  6.127,\n",
       "  85.2,\n",
       "  2.1224,\n",
       "  5.0,\n",
       "  384.0,\n",
       "  20.9,\n",
       "  387.69,\n",
       "  14.09],\n",
       " [0.12802,\n",
       "  0.0,\n",
       "  8.56,\n",
       "  0.0,\n",
       "  0.52,\n",
       "  6.474,\n",
       "  97.1,\n",
       "  2.4329,\n",
       "  5.0,\n",
       "  384.0,\n",
       "  20.9,\n",
       "  395.24,\n",
       "  12.27],\n",
       " [0.26363,\n",
       "  0.0,\n",
       "  8.56,\n",
       "  0.0,\n",
       "  0.52,\n",
       "  6.229,\n",
       "  91.2,\n",
       "  2.5451,\n",
       "  5.0,\n",
       "  384.0,\n",
       "  20.9,\n",
       "  391.23,\n",
       "  15.55],\n",
       " [0.10793,\n",
       "  0.0,\n",
       "  8.56,\n",
       "  0.0,\n",
       "  0.52,\n",
       "  6.195,\n",
       "  54.4,\n",
       "  2.7778,\n",
       "  5.0,\n",
       "  384.0,\n",
       "  20.9,\n",
       "  393.49,\n",
       "  13.0],\n",
       " [0.10084,\n",
       "  0.0,\n",
       "  10.01,\n",
       "  0.0,\n",
       "  0.547,\n",
       "  6.715,\n",
       "  81.6,\n",
       "  2.6775,\n",
       "  6.0,\n",
       "  432.0,\n",
       "  17.8,\n",
       "  395.59,\n",
       "  10.16],\n",
       " [0.12329,\n",
       "  0.0,\n",
       "  10.01,\n",
       "  0.0,\n",
       "  0.547,\n",
       "  5.913,\n",
       "  92.9,\n",
       "  2.3534,\n",
       "  6.0,\n",
       "  432.0,\n",
       "  17.8,\n",
       "  394.95,\n",
       "  16.21],\n",
       " [0.22212,\n",
       "  0.0,\n",
       "  10.01,\n",
       "  0.0,\n",
       "  0.547,\n",
       "  6.092,\n",
       "  95.4,\n",
       "  2.548,\n",
       "  6.0,\n",
       "  432.0,\n",
       "  17.8,\n",
       "  396.9,\n",
       "  17.09],\n",
       " [0.14231,\n",
       "  0.0,\n",
       "  10.01,\n",
       "  0.0,\n",
       "  0.547,\n",
       "  6.254,\n",
       "  84.2,\n",
       "  2.2565,\n",
       "  6.0,\n",
       "  432.0,\n",
       "  17.8,\n",
       "  388.74,\n",
       "  10.45],\n",
       " [0.17134,\n",
       "  0.0,\n",
       "  10.01,\n",
       "  0.0,\n",
       "  0.547,\n",
       "  5.928,\n",
       "  88.2,\n",
       "  2.4631,\n",
       "  6.0,\n",
       "  432.0,\n",
       "  17.8,\n",
       "  344.91,\n",
       "  15.76],\n",
       " [0.13158,\n",
       "  0.0,\n",
       "  10.01,\n",
       "  0.0,\n",
       "  0.547,\n",
       "  6.176,\n",
       "  72.5,\n",
       "  2.7301,\n",
       "  6.0,\n",
       "  432.0,\n",
       "  17.8,\n",
       "  393.3,\n",
       "  12.04],\n",
       " [0.15098,\n",
       "  0.0,\n",
       "  10.01,\n",
       "  0.0,\n",
       "  0.547,\n",
       "  6.021,\n",
       "  82.6,\n",
       "  2.7474,\n",
       "  6.0,\n",
       "  432.0,\n",
       "  17.8,\n",
       "  394.51,\n",
       "  10.3],\n",
       " [0.13058,\n",
       "  0.0,\n",
       "  10.01,\n",
       "  0.0,\n",
       "  0.547,\n",
       "  5.872,\n",
       "  73.1,\n",
       "  2.4775,\n",
       "  6.0,\n",
       "  432.0,\n",
       "  17.8,\n",
       "  338.63,\n",
       "  15.37],\n",
       " [0.14476,\n",
       "  0.0,\n",
       "  10.01,\n",
       "  0.0,\n",
       "  0.547,\n",
       "  5.731,\n",
       "  65.2,\n",
       "  2.7592,\n",
       "  6.0,\n",
       "  432.0,\n",
       "  17.8,\n",
       "  391.5,\n",
       "  13.61],\n",
       " [0.06899,\n",
       "  0.0,\n",
       "  25.65,\n",
       "  0.0,\n",
       "  0.581,\n",
       "  5.87,\n",
       "  69.7,\n",
       "  2.2577,\n",
       "  2.0,\n",
       "  188.0,\n",
       "  19.1,\n",
       "  389.15,\n",
       "  14.37],\n",
       " [0.07165,\n",
       "  0.0,\n",
       "  25.65,\n",
       "  0.0,\n",
       "  0.581,\n",
       "  6.004,\n",
       "  84.1,\n",
       "  2.1974,\n",
       "  2.0,\n",
       "  188.0,\n",
       "  19.1,\n",
       "  377.67,\n",
       "  14.27],\n",
       " [0.09299,\n",
       "  0.0,\n",
       "  25.65,\n",
       "  0.0,\n",
       "  0.581,\n",
       "  5.961,\n",
       "  92.9,\n",
       "  2.0869,\n",
       "  2.0,\n",
       "  188.0,\n",
       "  19.1,\n",
       "  378.09,\n",
       "  17.93],\n",
       " [0.15038,\n",
       "  0.0,\n",
       "  25.65,\n",
       "  0.0,\n",
       "  0.581,\n",
       "  5.856,\n",
       "  97.0,\n",
       "  1.9444,\n",
       "  2.0,\n",
       "  188.0,\n",
       "  19.1,\n",
       "  370.31,\n",
       "  25.41],\n",
       " [0.09849,\n",
       "  0.0,\n",
       "  25.65,\n",
       "  0.0,\n",
       "  0.581,\n",
       "  5.879,\n",
       "  95.8,\n",
       "  2.0063,\n",
       "  2.0,\n",
       "  188.0,\n",
       "  19.1,\n",
       "  379.38,\n",
       "  17.58],\n",
       " [0.16902,\n",
       "  0.0,\n",
       "  25.65,\n",
       "  0.0,\n",
       "  0.581,\n",
       "  5.986,\n",
       "  88.4,\n",
       "  1.9929,\n",
       "  2.0,\n",
       "  188.0,\n",
       "  19.1,\n",
       "  385.02,\n",
       "  14.81],\n",
       " [0.38735,\n",
       "  0.0,\n",
       "  25.65,\n",
       "  0.0,\n",
       "  0.581,\n",
       "  5.613,\n",
       "  95.6,\n",
       "  1.7572,\n",
       "  2.0,\n",
       "  188.0,\n",
       "  19.1,\n",
       "  359.29,\n",
       "  27.26],\n",
       " [0.25915,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  5.693,\n",
       "  96.0,\n",
       "  1.7883,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  392.11,\n",
       "  17.19],\n",
       " [0.32543,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  6.431,\n",
       "  98.8,\n",
       "  1.8125,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  396.9,\n",
       "  15.39],\n",
       " [0.88125,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  5.637,\n",
       "  94.7,\n",
       "  1.9799,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  396.9,\n",
       "  18.34],\n",
       " [0.34006,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  6.458,\n",
       "  98.9,\n",
       "  2.1185,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  395.04,\n",
       "  12.6],\n",
       " [1.19294,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  6.326,\n",
       "  97.7,\n",
       "  2.271,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  396.9,\n",
       "  12.26],\n",
       " [0.59005,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  6.372,\n",
       "  97.9,\n",
       "  2.3274,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  385.76,\n",
       "  11.12],\n",
       " [0.32982,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  5.822,\n",
       "  95.4,\n",
       "  2.4699,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  388.69,\n",
       "  15.03],\n",
       " [0.97617,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  5.757,\n",
       "  98.4,\n",
       "  2.346,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  262.76,\n",
       "  17.31],\n",
       " [0.55778,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  6.335,\n",
       "  98.2,\n",
       "  2.1107,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  394.67,\n",
       "  16.96],\n",
       " [0.32264,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  5.942,\n",
       "  93.5,\n",
       "  1.9669,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  378.25,\n",
       "  16.9],\n",
       " [0.35233,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  6.454,\n",
       "  98.4,\n",
       "  1.8498,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  394.08,\n",
       "  14.59],\n",
       " [0.2498,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  5.857,\n",
       "  98.2,\n",
       "  1.6686,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  392.04,\n",
       "  21.32],\n",
       " [0.54452,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  6.151,\n",
       "  97.9,\n",
       "  1.6687,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  396.9,\n",
       "  18.46],\n",
       " [0.2909,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  6.174,\n",
       "  93.6,\n",
       "  1.6119,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  388.08,\n",
       "  24.16],\n",
       " [1.62864,\n",
       "  0.0,\n",
       "  21.89,\n",
       "  0.0,\n",
       "  0.624,\n",
       "  5.019,\n",
       "  100.0,\n",
       "  1.4394,\n",
       "  4.0,\n",
       "  437.0,\n",
       "  21.2,\n",
       "  396.9,\n",
       "  34.41],\n",
       " [3.32105,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  1.0,\n",
       "  0.871,\n",
       "  5.403,\n",
       "  100.0,\n",
       "  1.3216,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  396.9,\n",
       "  26.82],\n",
       " [4.0974,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.871,\n",
       "  5.468,\n",
       "  100.0,\n",
       "  1.4118,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  396.9,\n",
       "  26.42],\n",
       " [2.77974,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.871,\n",
       "  4.903,\n",
       "  97.8,\n",
       "  1.3459,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  396.9,\n",
       "  29.29],\n",
       " [2.37934,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.871,\n",
       "  6.13,\n",
       "  100.0,\n",
       "  1.4191,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  172.91,\n",
       "  27.8],\n",
       " [2.15505,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.871,\n",
       "  5.628,\n",
       "  100.0,\n",
       "  1.5166,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  169.27,\n",
       "  16.65],\n",
       " [2.36862,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.871,\n",
       "  4.926,\n",
       "  95.7,\n",
       "  1.4608,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  391.71,\n",
       "  29.53],\n",
       " [2.33099,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.871,\n",
       "  5.186,\n",
       "  93.8,\n",
       "  1.5296,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  356.99,\n",
       "  28.32],\n",
       " [2.73397,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.871,\n",
       "  5.597,\n",
       "  94.9,\n",
       "  1.5257,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  351.85,\n",
       "  21.45],\n",
       " [1.6566,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.871,\n",
       "  6.122,\n",
       "  97.3,\n",
       "  1.618,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  372.8,\n",
       "  14.1],\n",
       " [1.49632,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.871,\n",
       "  5.404,\n",
       "  100.0,\n",
       "  1.5916,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  341.6,\n",
       "  13.28],\n",
       " [1.12658,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  1.0,\n",
       "  0.871,\n",
       "  5.012,\n",
       "  88.0,\n",
       "  1.6102,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  343.28,\n",
       "  12.12],\n",
       " [2.14918,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.871,\n",
       "  5.709,\n",
       "  98.5,\n",
       "  1.6232,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  261.95,\n",
       "  15.79],\n",
       " [1.41385,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  1.0,\n",
       "  0.871,\n",
       "  6.129,\n",
       "  96.0,\n",
       "  1.7494,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  321.02,\n",
       "  15.12],\n",
       " [3.53501,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  1.0,\n",
       "  0.871,\n",
       "  6.152,\n",
       "  82.6,\n",
       "  1.7455,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  88.01,\n",
       "  15.02],\n",
       " [2.44668,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.871,\n",
       "  5.272,\n",
       "  94.0,\n",
       "  1.7364,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  88.63,\n",
       "  16.14],\n",
       " [1.22358,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.605,\n",
       "  6.943,\n",
       "  97.4,\n",
       "  1.8773,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  363.43,\n",
       "  4.59],\n",
       " [1.34284,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.605,\n",
       "  6.066,\n",
       "  100.0,\n",
       "  1.7573,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  353.89,\n",
       "  6.43],\n",
       " [1.42502,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.871,\n",
       "  6.51,\n",
       "  100.0,\n",
       "  1.7659,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  364.31,\n",
       "  7.39],\n",
       " [1.27346,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  1.0,\n",
       "  0.605,\n",
       "  6.25,\n",
       "  92.6,\n",
       "  1.7984,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  338.92,\n",
       "  5.5],\n",
       " [1.46336,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.605,\n",
       "  7.489,\n",
       "  90.8,\n",
       "  1.9709,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  374.43,\n",
       "  1.73],\n",
       " [1.83377,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  1.0,\n",
       "  0.605,\n",
       "  7.802,\n",
       "  98.2,\n",
       "  2.0407,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  389.61,\n",
       "  1.92],\n",
       " [1.51902,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  1.0,\n",
       "  0.605,\n",
       "  8.375,\n",
       "  93.9,\n",
       "  2.162,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  388.45,\n",
       "  3.32],\n",
       " [2.24236,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.605,\n",
       "  5.854,\n",
       "  91.8,\n",
       "  2.422,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  395.11,\n",
       "  11.64],\n",
       " [2.924,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.605,\n",
       "  6.101,\n",
       "  93.0,\n",
       "  2.2834,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  240.16,\n",
       "  9.81],\n",
       " [2.01019,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.605,\n",
       "  7.929,\n",
       "  96.2,\n",
       "  2.0459,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  369.3,\n",
       "  3.7],\n",
       " [1.80028,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.605,\n",
       "  5.877,\n",
       "  79.2,\n",
       "  2.4259,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  227.61,\n",
       "  12.14],\n",
       " [2.3004,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.605,\n",
       "  6.319,\n",
       "  96.1,\n",
       "  2.1,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  297.09,\n",
       "  11.1],\n",
       " [2.44953,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.605,\n",
       "  6.402,\n",
       "  95.2,\n",
       "  2.2625,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  330.04,\n",
       "  11.32],\n",
       " [1.20742,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.605,\n",
       "  5.875,\n",
       "  94.6,\n",
       "  2.4259,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  292.29,\n",
       "  14.43],\n",
       " [2.3139,\n",
       "  0.0,\n",
       "  19.58,\n",
       "  0.0,\n",
       "  0.605,\n",
       "  5.88,\n",
       "  97.3,\n",
       "  2.3887,\n",
       "  5.0,\n",
       "  403.0,\n",
       "  14.7,\n",
       "  348.13,\n",
       "  12.03],\n",
       " [0.13914,\n",
       "  0.0,\n",
       "  4.05,\n",
       "  0.0,\n",
       "  0.51,\n",
       "  5.572,\n",
       "  88.5,\n",
       "  2.5961,\n",
       "  5.0,\n",
       "  296.0,\n",
       "  16.6,\n",
       "  396.9,\n",
       "  14.69],\n",
       " [0.09178,\n",
       "  0.0,\n",
       "  4.05,\n",
       "  0.0,\n",
       "  0.51,\n",
       "  6.416,\n",
       "  84.1,\n",
       "  2.6463,\n",
       "  5.0,\n",
       "  296.0,\n",
       "  16.6,\n",
       "  395.5,\n",
       "  9.04],\n",
       " [0.08447,\n",
       "  0.0,\n",
       "  4.05,\n",
       "  0.0,\n",
       "  0.51,\n",
       "  5.859,\n",
       "  68.7,\n",
       "  2.7019,\n",
       "  5.0,\n",
       "  296.0,\n",
       "  16.6,\n",
       "  393.23,\n",
       "  9.64],\n",
       " [0.06664,\n",
       "  0.0,\n",
       "  4.05,\n",
       "  0.0,\n",
       "  0.51,\n",
       "  6.546,\n",
       "  33.1,\n",
       "  3.1323,\n",
       "  5.0,\n",
       "  296.0,\n",
       "  16.6,\n",
       "  390.96,\n",
       "  5.33],\n",
       " [0.07022,\n",
       "  0.0,\n",
       "  4.05,\n",
       "  0.0,\n",
       "  0.51,\n",
       "  6.02,\n",
       "  47.2,\n",
       "  3.5549,\n",
       "  5.0,\n",
       "  296.0,\n",
       "  16.6,\n",
       "  393.23,\n",
       "  10.11],\n",
       " [0.05425,\n",
       "  0.0,\n",
       "  4.05,\n",
       "  0.0,\n",
       "  0.51,\n",
       "  6.315,\n",
       "  73.4,\n",
       "  3.3175,\n",
       "  5.0,\n",
       "  296.0,\n",
       "  16.6,\n",
       "  395.6,\n",
       "  6.29],\n",
       " [0.06642,\n",
       "  0.0,\n",
       "  4.05,\n",
       "  0.0,\n",
       "  0.51,\n",
       "  6.86,\n",
       "  74.4,\n",
       "  2.9153,\n",
       "  5.0,\n",
       "  296.0,\n",
       "  16.6,\n",
       "  391.27,\n",
       "  6.92],\n",
       " [0.0578,\n",
       "  0.0,\n",
       "  2.46,\n",
       "  0.0,\n",
       "  0.488,\n",
       "  6.98,\n",
       "  58.4,\n",
       "  2.829,\n",
       "  3.0,\n",
       "  193.0,\n",
       "  17.8,\n",
       "  396.9,\n",
       "  5.04],\n",
       " [0.06588,\n",
       "  0.0,\n",
       "  2.46,\n",
       "  0.0,\n",
       "  0.488,\n",
       "  7.765,\n",
       "  83.3,\n",
       "  2.741,\n",
       "  3.0,\n",
       "  193.0,\n",
       "  17.8,\n",
       "  395.56,\n",
       "  7.56],\n",
       " [0.06888,\n",
       "  0.0,\n",
       "  2.46,\n",
       "  0.0,\n",
       "  0.488,\n",
       "  6.144,\n",
       "  62.2,\n",
       "  2.5979,\n",
       "  3.0,\n",
       "  193.0,\n",
       "  17.8,\n",
       "  396.9,\n",
       "  9.45],\n",
       " [0.09103,\n",
       "  0.0,\n",
       "  2.46,\n",
       "  0.0,\n",
       "  0.488,\n",
       "  7.155,\n",
       "  92.2,\n",
       "  2.7006,\n",
       "  3.0,\n",
       "  193.0,\n",
       "  17.8,\n",
       "  394.12,\n",
       "  4.82],\n",
       " [0.10008,\n",
       "  0.0,\n",
       "  2.46,\n",
       "  0.0,\n",
       "  0.488,\n",
       "  6.563,\n",
       "  95.6,\n",
       "  2.847,\n",
       "  3.0,\n",
       "  193.0,\n",
       "  17.8,\n",
       "  396.9,\n",
       "  5.68],\n",
       " [0.08308,\n",
       "  0.0,\n",
       "  2.46,\n",
       "  0.0,\n",
       "  0.488,\n",
       "  5.604,\n",
       "  89.8,\n",
       "  2.9879,\n",
       "  3.0,\n",
       "  193.0,\n",
       "  17.8,\n",
       "  391.0,\n",
       "  13.98],\n",
       " [0.06047,\n",
       "  0.0,\n",
       "  2.46,\n",
       "  0.0,\n",
       "  0.488,\n",
       "  6.153,\n",
       "  68.8,\n",
       "  3.2797,\n",
       "  3.0,\n",
       "  193.0,\n",
       "  17.8,\n",
       "  387.11,\n",
       "  13.15],\n",
       " [0.05602,\n",
       "  0.0,\n",
       "  2.46,\n",
       "  0.0,\n",
       "  0.488,\n",
       "  7.831,\n",
       "  53.6,\n",
       "  3.1992,\n",
       "  3.0,\n",
       "  193.0,\n",
       "  17.8,\n",
       "  392.63,\n",
       "  4.45],\n",
       " [0.07875,\n",
       "  45.0,\n",
       "  3.44,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  6.782,\n",
       "  41.1,\n",
       "  3.7886,\n",
       "  5.0,\n",
       "  398.0,\n",
       "  15.2,\n",
       "  393.87,\n",
       "  6.68],\n",
       " [0.12579,\n",
       "  45.0,\n",
       "  3.44,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  6.556,\n",
       "  29.1,\n",
       "  4.5667,\n",
       "  5.0,\n",
       "  398.0,\n",
       "  15.2,\n",
       "  382.84,\n",
       "  4.56],\n",
       " [0.0837,\n",
       "  45.0,\n",
       "  3.44,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  7.185,\n",
       "  38.9,\n",
       "  4.5667,\n",
       "  5.0,\n",
       "  398.0,\n",
       "  15.2,\n",
       "  396.9,\n",
       "  5.39],\n",
       " [0.09068,\n",
       "  45.0,\n",
       "  3.44,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  6.951,\n",
       "  21.5,\n",
       "  6.4798,\n",
       "  5.0,\n",
       "  398.0,\n",
       "  15.2,\n",
       "  377.68,\n",
       "  5.1],\n",
       " [0.06911,\n",
       "  45.0,\n",
       "  3.44,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  6.739,\n",
       "  30.8,\n",
       "  6.4798,\n",
       "  5.0,\n",
       "  398.0,\n",
       "  15.2,\n",
       "  389.71,\n",
       "  4.69],\n",
       " [0.08664,\n",
       "  45.0,\n",
       "  3.44,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  7.178,\n",
       "  26.3,\n",
       "  6.4798,\n",
       "  5.0,\n",
       "  398.0,\n",
       "  15.2,\n",
       "  390.49,\n",
       "  2.87],\n",
       " [0.02187,\n",
       "  60.0,\n",
       "  2.93,\n",
       "  0.0,\n",
       "  0.401,\n",
       "  6.8,\n",
       "  9.9,\n",
       "  6.2196,\n",
       "  1.0,\n",
       "  265.0,\n",
       "  15.6,\n",
       "  393.37,\n",
       "  5.03],\n",
       " [0.01439,\n",
       "  60.0,\n",
       "  2.93,\n",
       "  0.0,\n",
       "  0.401,\n",
       "  6.604,\n",
       "  18.8,\n",
       "  6.2196,\n",
       "  1.0,\n",
       "  265.0,\n",
       "  15.6,\n",
       "  376.7,\n",
       "  4.38],\n",
       " [0.01381,\n",
       "  80.0,\n",
       "  0.46,\n",
       "  0.0,\n",
       "  0.422,\n",
       "  7.875,\n",
       "  32.0,\n",
       "  5.6484,\n",
       "  4.0,\n",
       "  255.0,\n",
       "  14.4,\n",
       "  394.23,\n",
       "  2.97],\n",
       " [0.04011,\n",
       "  80.0,\n",
       "  1.52,\n",
       "  0.0,\n",
       "  0.404,\n",
       "  7.287,\n",
       "  34.1,\n",
       "  7.309,\n",
       "  2.0,\n",
       "  329.0,\n",
       "  12.6,\n",
       "  396.9,\n",
       "  4.08],\n",
       " [0.04666,\n",
       "  80.0,\n",
       "  1.52,\n",
       "  0.0,\n",
       "  0.404,\n",
       "  7.107,\n",
       "  36.6,\n",
       "  7.309,\n",
       "  2.0,\n",
       "  329.0,\n",
       "  12.6,\n",
       "  354.31,\n",
       "  8.61],\n",
       " [0.03768,\n",
       "  80.0,\n",
       "  1.52,\n",
       "  0.0,\n",
       "  0.404,\n",
       "  7.274,\n",
       "  38.3,\n",
       "  7.309,\n",
       "  2.0,\n",
       "  329.0,\n",
       "  12.6,\n",
       "  392.2,\n",
       "  6.62],\n",
       " [0.0315,\n",
       "  95.0,\n",
       "  1.47,\n",
       "  0.0,\n",
       "  0.403,\n",
       "  6.975,\n",
       "  15.3,\n",
       "  7.6534,\n",
       "  3.0,\n",
       "  402.0,\n",
       "  17.0,\n",
       "  396.9,\n",
       "  4.56],\n",
       " [0.01778,\n",
       "  95.0,\n",
       "  1.47,\n",
       "  0.0,\n",
       "  0.403,\n",
       "  7.135,\n",
       "  13.9,\n",
       "  7.6534,\n",
       "  3.0,\n",
       "  402.0,\n",
       "  17.0,\n",
       "  384.3,\n",
       "  4.45],\n",
       " [0.03445,\n",
       "  82.5,\n",
       "  2.03,\n",
       "  0.0,\n",
       "  0.415,\n",
       "  6.162,\n",
       "  38.4,\n",
       "  6.27,\n",
       "  2.0,\n",
       "  348.0,\n",
       "  14.7,\n",
       "  393.77,\n",
       "  7.43],\n",
       " [0.02177,\n",
       "  82.5,\n",
       "  2.03,\n",
       "  0.0,\n",
       "  0.415,\n",
       "  7.61,\n",
       "  15.7,\n",
       "  6.27,\n",
       "  2.0,\n",
       "  348.0,\n",
       "  14.7,\n",
       "  395.38,\n",
       "  3.11],\n",
       " [0.0351,\n",
       "  95.0,\n",
       "  2.68,\n",
       "  0.0,\n",
       "  0.4161,\n",
       "  7.853,\n",
       "  33.2,\n",
       "  5.118,\n",
       "  4.0,\n",
       "  224.0,\n",
       "  14.7,\n",
       "  392.78,\n",
       "  3.81],\n",
       " [0.02009,\n",
       "  95.0,\n",
       "  2.68,\n",
       "  0.0,\n",
       "  0.4161,\n",
       "  8.034,\n",
       "  31.9,\n",
       "  5.118,\n",
       "  4.0,\n",
       "  224.0,\n",
       "  14.7,\n",
       "  390.55,\n",
       "  2.88],\n",
       " [0.13642,\n",
       "  0.0,\n",
       "  10.59,\n",
       "  0.0,\n",
       "  0.489,\n",
       "  5.891,\n",
       "  22.3,\n",
       "  3.9454,\n",
       "  4.0,\n",
       "  277.0,\n",
       "  18.6,\n",
       "  396.9,\n",
       "  10.87],\n",
       " [0.22969,\n",
       "  0.0,\n",
       "  10.59,\n",
       "  0.0,\n",
       "  0.489,\n",
       "  6.326,\n",
       "  52.5,\n",
       "  4.3549,\n",
       "  4.0,\n",
       "  277.0,\n",
       "  18.6,\n",
       "  394.87,\n",
       "  10.97],\n",
       " [0.25199,\n",
       "  0.0,\n",
       "  10.59,\n",
       "  0.0,\n",
       "  0.489,\n",
       "  5.783,\n",
       "  72.7,\n",
       "  4.3549,\n",
       "  4.0,\n",
       "  277.0,\n",
       "  18.6,\n",
       "  389.43,\n",
       "  18.06],\n",
       " [0.13587,\n",
       "  0.0,\n",
       "  10.59,\n",
       "  1.0,\n",
       "  0.489,\n",
       "  6.064,\n",
       "  59.1,\n",
       "  4.2392,\n",
       "  4.0,\n",
       "  277.0,\n",
       "  18.6,\n",
       "  381.32,\n",
       "  14.66],\n",
       " [0.43571,\n",
       "  0.0,\n",
       "  10.59,\n",
       "  1.0,\n",
       "  0.489,\n",
       "  5.344,\n",
       "  100.0,\n",
       "  3.875,\n",
       "  4.0,\n",
       "  277.0,\n",
       "  18.6,\n",
       "  396.9,\n",
       "  23.09],\n",
       " [0.17446,\n",
       "  0.0,\n",
       "  10.59,\n",
       "  1.0,\n",
       "  0.489,\n",
       "  5.96,\n",
       "  92.1,\n",
       "  3.8771,\n",
       "  4.0,\n",
       "  277.0,\n",
       "  18.6,\n",
       "  393.25,\n",
       "  17.27],\n",
       " [0.37578,\n",
       "  0.0,\n",
       "  10.59,\n",
       "  1.0,\n",
       "  0.489,\n",
       "  5.404,\n",
       "  88.6,\n",
       "  3.665,\n",
       "  4.0,\n",
       "  277.0,\n",
       "  18.6,\n",
       "  395.24,\n",
       "  23.98],\n",
       " [0.21719,\n",
       "  0.0,\n",
       "  10.59,\n",
       "  1.0,\n",
       "  0.489,\n",
       "  5.807,\n",
       "  53.8,\n",
       "  3.6526,\n",
       "  4.0,\n",
       "  277.0,\n",
       "  18.6,\n",
       "  390.94,\n",
       "  16.03],\n",
       " [0.14052,\n",
       "  0.0,\n",
       "  10.59,\n",
       "  0.0,\n",
       "  0.489,\n",
       "  6.375,\n",
       "  32.3,\n",
       "  3.9454,\n",
       "  4.0,\n",
       "  277.0,\n",
       "  18.6,\n",
       "  385.81,\n",
       "  9.38],\n",
       " [0.28955,\n",
       "  0.0,\n",
       "  10.59,\n",
       "  0.0,\n",
       "  0.489,\n",
       "  5.412,\n",
       "  9.8,\n",
       "  3.5875,\n",
       "  4.0,\n",
       "  277.0,\n",
       "  18.6,\n",
       "  348.93,\n",
       "  29.55],\n",
       " [0.19802,\n",
       "  0.0,\n",
       "  10.59,\n",
       "  0.0,\n",
       "  0.489,\n",
       "  6.182,\n",
       "  42.4,\n",
       "  3.9454,\n",
       "  4.0,\n",
       "  277.0,\n",
       "  18.6,\n",
       "  393.63,\n",
       "  9.47],\n",
       " [0.0456,\n",
       "  0.0,\n",
       "  13.89,\n",
       "  1.0,\n",
       "  0.55,\n",
       "  5.888,\n",
       "  56.0,\n",
       "  3.1121,\n",
       "  5.0,\n",
       "  276.0,\n",
       "  16.4,\n",
       "  392.8,\n",
       "  13.51],\n",
       " [0.07013,\n",
       "  0.0,\n",
       "  13.89,\n",
       "  0.0,\n",
       "  0.55,\n",
       "  6.642,\n",
       "  85.1,\n",
       "  3.4211,\n",
       "  5.0,\n",
       "  276.0,\n",
       "  16.4,\n",
       "  392.78,\n",
       "  9.69],\n",
       " [0.11069,\n",
       "  0.0,\n",
       "  13.89,\n",
       "  1.0,\n",
       "  0.55,\n",
       "  5.951,\n",
       "  93.8,\n",
       "  2.8893,\n",
       "  5.0,\n",
       "  276.0,\n",
       "  16.4,\n",
       "  396.9,\n",
       "  17.92],\n",
       " [0.11425,\n",
       "  0.0,\n",
       "  13.89,\n",
       "  1.0,\n",
       "  0.55,\n",
       "  6.373,\n",
       "  92.4,\n",
       "  3.3633,\n",
       "  5.0,\n",
       "  276.0,\n",
       "  16.4,\n",
       "  393.74,\n",
       "  10.5],\n",
       " [0.35809,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  1.0,\n",
       "  0.507,\n",
       "  6.951,\n",
       "  88.5,\n",
       "  2.8617,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  391.7,\n",
       "  9.71],\n",
       " [0.40771,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  1.0,\n",
       "  0.507,\n",
       "  6.164,\n",
       "  91.3,\n",
       "  3.048,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  395.24,\n",
       "  21.46],\n",
       " [0.62356,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  1.0,\n",
       "  0.507,\n",
       "  6.879,\n",
       "  77.7,\n",
       "  3.2721,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  390.39,\n",
       "  9.93],\n",
       " [0.6147,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  0.0,\n",
       "  0.507,\n",
       "  6.618,\n",
       "  80.8,\n",
       "  3.2721,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  396.9,\n",
       "  7.6],\n",
       " [0.31533,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  0.0,\n",
       "  0.504,\n",
       "  8.266,\n",
       "  78.3,\n",
       "  2.8944,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  385.05,\n",
       "  4.14],\n",
       " [0.52693,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  0.0,\n",
       "  0.504,\n",
       "  8.725,\n",
       "  83.0,\n",
       "  2.8944,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  382.0,\n",
       "  4.63],\n",
       " [0.38214,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  0.0,\n",
       "  0.504,\n",
       "  8.04,\n",
       "  86.5,\n",
       "  3.2157,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  387.38,\n",
       "  3.13],\n",
       " [0.41238,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  0.0,\n",
       "  0.504,\n",
       "  7.163,\n",
       "  79.9,\n",
       "  3.2157,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  372.08,\n",
       "  6.36],\n",
       " [0.29819,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  0.0,\n",
       "  0.504,\n",
       "  7.686,\n",
       "  17.0,\n",
       "  3.3751,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  377.51,\n",
       "  3.92],\n",
       " [0.44178,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  0.0,\n",
       "  0.504,\n",
       "  6.552,\n",
       "  21.4,\n",
       "  3.3751,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  380.34,\n",
       "  3.76],\n",
       " [0.537,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  0.0,\n",
       "  0.504,\n",
       "  5.981,\n",
       "  68.1,\n",
       "  3.6715,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  378.35,\n",
       "  11.65],\n",
       " [0.46296,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  0.0,\n",
       "  0.504,\n",
       "  7.412,\n",
       "  76.9,\n",
       "  3.6715,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  376.14,\n",
       "  5.25],\n",
       " [0.57529,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  0.0,\n",
       "  0.507,\n",
       "  8.337,\n",
       "  73.3,\n",
       "  3.8384,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  385.91,\n",
       "  2.47],\n",
       " [0.33147,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  0.0,\n",
       "  0.507,\n",
       "  8.247,\n",
       "  70.4,\n",
       "  3.6519,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  378.95,\n",
       "  3.95],\n",
       " [0.44791,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  1.0,\n",
       "  0.507,\n",
       "  6.726,\n",
       "  66.5,\n",
       "  3.6519,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  360.2,\n",
       "  8.05],\n",
       " [0.33045,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  0.0,\n",
       "  0.507,\n",
       "  6.086,\n",
       "  61.5,\n",
       "  3.6519,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  376.75,\n",
       "  10.88],\n",
       " [0.52058,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  1.0,\n",
       "  0.507,\n",
       "  6.631,\n",
       "  76.5,\n",
       "  4.148,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  388.45,\n",
       "  9.54],\n",
       " [0.51183,\n",
       "  0.0,\n",
       "  6.2,\n",
       "  0.0,\n",
       "  0.507,\n",
       "  7.358,\n",
       "  71.6,\n",
       "  4.148,\n",
       "  8.0,\n",
       "  307.0,\n",
       "  17.4,\n",
       "  390.07,\n",
       "  4.73],\n",
       " [0.08244,\n",
       "  30.0,\n",
       "  4.93,\n",
       "  0.0,\n",
       "  0.428,\n",
       "  6.481,\n",
       "  18.5,\n",
       "  6.1899,\n",
       "  6.0,\n",
       "  300.0,\n",
       "  16.6,\n",
       "  379.41,\n",
       "  6.36],\n",
       " [0.09252,\n",
       "  30.0,\n",
       "  4.93,\n",
       "  0.0,\n",
       "  0.428,\n",
       "  6.606,\n",
       "  42.2,\n",
       "  6.1899,\n",
       "  6.0,\n",
       "  300.0,\n",
       "  16.6,\n",
       "  383.78,\n",
       "  7.37],\n",
       " [0.11329,\n",
       "  30.0,\n",
       "  4.93,\n",
       "  0.0,\n",
       "  0.428,\n",
       "  6.897,\n",
       "  54.3,\n",
       "  6.3361,\n",
       "  6.0,\n",
       "  300.0,\n",
       "  16.6,\n",
       "  391.25,\n",
       "  11.38],\n",
       " [0.10612,\n",
       "  30.0,\n",
       "  4.93,\n",
       "  0.0,\n",
       "  0.428,\n",
       "  6.095,\n",
       "  65.1,\n",
       "  6.3361,\n",
       "  6.0,\n",
       "  300.0,\n",
       "  16.6,\n",
       "  394.62,\n",
       "  12.4],\n",
       " [0.1029,\n",
       "  30.0,\n",
       "  4.93,\n",
       "  0.0,\n",
       "  0.428,\n",
       "  6.358,\n",
       "  52.9,\n",
       "  7.0355,\n",
       "  6.0,\n",
       "  300.0,\n",
       "  16.6,\n",
       "  372.75,\n",
       "  11.22],\n",
       " [0.12757,\n",
       "  30.0,\n",
       "  4.93,\n",
       "  0.0,\n",
       "  0.428,\n",
       "  6.393,\n",
       "  7.8,\n",
       "  7.0355,\n",
       "  6.0,\n",
       "  300.0,\n",
       "  16.6,\n",
       "  374.71,\n",
       "  5.19],\n",
       " [0.20608,\n",
       "  22.0,\n",
       "  5.86,\n",
       "  0.0,\n",
       "  0.431,\n",
       "  5.593,\n",
       "  76.5,\n",
       "  7.9549,\n",
       "  7.0,\n",
       "  330.0,\n",
       "  19.1,\n",
       "  372.49,\n",
       "  12.5],\n",
       " [0.19133,\n",
       "  22.0,\n",
       "  5.86,\n",
       "  0.0,\n",
       "  0.431,\n",
       "  5.605,\n",
       "  70.2,\n",
       "  7.9549,\n",
       "  7.0,\n",
       "  330.0,\n",
       "  19.1,\n",
       "  389.13,\n",
       "  18.46],\n",
       " [0.33983,\n",
       "  22.0,\n",
       "  5.86,\n",
       "  0.0,\n",
       "  0.431,\n",
       "  6.108,\n",
       "  34.9,\n",
       "  8.0555,\n",
       "  7.0,\n",
       "  330.0,\n",
       "  19.1,\n",
       "  390.18,\n",
       "  9.16],\n",
       " [0.19657,\n",
       "  22.0,\n",
       "  5.86,\n",
       "  0.0,\n",
       "  0.431,\n",
       "  6.226,\n",
       "  79.2,\n",
       "  8.0555,\n",
       "  7.0,\n",
       "  330.0,\n",
       "  19.1,\n",
       "  376.14,\n",
       "  10.15],\n",
       " [0.16439,\n",
       "  22.0,\n",
       "  5.86,\n",
       "  0.0,\n",
       "  0.431,\n",
       "  6.433,\n",
       "  49.1,\n",
       "  7.8265,\n",
       "  7.0,\n",
       "  330.0,\n",
       "  19.1,\n",
       "  374.71,\n",
       "  9.52],\n",
       " [0.19073,\n",
       "  22.0,\n",
       "  5.86,\n",
       "  0.0,\n",
       "  0.431,\n",
       "  6.718,\n",
       "  17.5,\n",
       "  7.8265,\n",
       "  7.0,\n",
       "  330.0,\n",
       "  19.1,\n",
       "  393.74,\n",
       "  6.56],\n",
       " [0.1403,\n",
       "  22.0,\n",
       "  5.86,\n",
       "  0.0,\n",
       "  0.431,\n",
       "  6.487,\n",
       "  13.0,\n",
       "  7.3967,\n",
       "  7.0,\n",
       "  330.0,\n",
       "  19.1,\n",
       "  396.28,\n",
       "  5.9],\n",
       " [0.21409,\n",
       "  22.0,\n",
       "  5.86,\n",
       "  0.0,\n",
       "  0.431,\n",
       "  6.438,\n",
       "  8.9,\n",
       "  7.3967,\n",
       "  7.0,\n",
       "  330.0,\n",
       "  19.1,\n",
       "  377.07,\n",
       "  3.59],\n",
       " [0.08221,\n",
       "  22.0,\n",
       "  5.86,\n",
       "  0.0,\n",
       "  0.431,\n",
       "  6.957,\n",
       "  6.8,\n",
       "  8.9067,\n",
       "  7.0,\n",
       "  330.0,\n",
       "  19.1,\n",
       "  386.09,\n",
       "  3.53],\n",
       " [0.36894,\n",
       "  22.0,\n",
       "  5.86,\n",
       "  0.0,\n",
       "  0.431,\n",
       "  8.259,\n",
       "  8.4,\n",
       "  8.9067,\n",
       "  7.0,\n",
       "  330.0,\n",
       "  19.1,\n",
       "  396.9,\n",
       "  3.54],\n",
       " [0.04819,\n",
       "  80.0,\n",
       "  3.64,\n",
       "  0.0,\n",
       "  0.392,\n",
       "  6.108,\n",
       "  32.0,\n",
       "  9.2203,\n",
       "  1.0,\n",
       "  315.0,\n",
       "  16.4,\n",
       "  392.89,\n",
       "  6.57],\n",
       " [0.03548,\n",
       "  80.0,\n",
       "  3.64,\n",
       "  0.0,\n",
       "  0.392,\n",
       "  5.876,\n",
       "  19.1,\n",
       "  9.2203,\n",
       "  1.0,\n",
       "  315.0,\n",
       "  16.4,\n",
       "  395.18,\n",
       "  9.25],\n",
       " [0.01538,\n",
       "  90.0,\n",
       "  3.75,\n",
       "  0.0,\n",
       "  0.394,\n",
       "  7.454,\n",
       "  34.2,\n",
       "  6.3361,\n",
       "  3.0,\n",
       "  244.0,\n",
       "  15.9,\n",
       "  386.34,\n",
       "  3.11],\n",
       " [0.61154,\n",
       "  20.0,\n",
       "  3.97,\n",
       "  0.0,\n",
       "  0.647,\n",
       "  8.704,\n",
       "  86.9,\n",
       "  1.801,\n",
       "  5.0,\n",
       "  264.0,\n",
       "  13.0,\n",
       "  389.7,\n",
       "  5.12],\n",
       " [0.66351,\n",
       "  20.0,\n",
       "  3.97,\n",
       "  0.0,\n",
       "  0.647,\n",
       "  7.333,\n",
       "  100.0,\n",
       "  1.8946,\n",
       "  5.0,\n",
       "  264.0,\n",
       "  13.0,\n",
       "  383.29,\n",
       "  7.79],\n",
       " [0.65665,\n",
       "  20.0,\n",
       "  3.97,\n",
       "  0.0,\n",
       "  0.647,\n",
       "  6.842,\n",
       "  100.0,\n",
       "  2.0107,\n",
       "  5.0,\n",
       "  264.0,\n",
       "  13.0,\n",
       "  391.93,\n",
       "  6.9],\n",
       " [0.54011,\n",
       "  20.0,\n",
       "  3.97,\n",
       "  0.0,\n",
       "  0.647,\n",
       "  7.203,\n",
       "  81.8,\n",
       "  2.1121,\n",
       "  5.0,\n",
       "  264.0,\n",
       "  13.0,\n",
       "  392.8,\n",
       "  9.59],\n",
       " [0.53412,\n",
       "  20.0,\n",
       "  3.97,\n",
       "  0.0,\n",
       "  0.647,\n",
       "  7.52,\n",
       "  89.4,\n",
       "  2.1398,\n",
       "  5.0,\n",
       "  264.0,\n",
       "  13.0,\n",
       "  388.37,\n",
       "  7.26],\n",
       " [0.52014,\n",
       "  20.0,\n",
       "  3.97,\n",
       "  0.0,\n",
       "  0.647,\n",
       "  8.398,\n",
       "  91.5,\n",
       "  2.2885,\n",
       "  5.0,\n",
       "  264.0,\n",
       "  13.0,\n",
       "  386.86,\n",
       "  5.91],\n",
       " [0.82526,\n",
       "  20.0,\n",
       "  3.97,\n",
       "  0.0,\n",
       "  0.647,\n",
       "  7.327,\n",
       "  94.5,\n",
       "  2.0788,\n",
       "  5.0,\n",
       "  264.0,\n",
       "  13.0,\n",
       "  393.42,\n",
       "  11.25],\n",
       " [0.55007,\n",
       "  20.0,\n",
       "  3.97,\n",
       "  0.0,\n",
       "  0.647,\n",
       "  7.206,\n",
       "  91.6,\n",
       "  1.9301,\n",
       "  5.0,\n",
       "  264.0,\n",
       "  13.0,\n",
       "  387.89,\n",
       "  8.1],\n",
       " [0.76162,\n",
       "  20.0,\n",
       "  3.97,\n",
       "  0.0,\n",
       "  0.647,\n",
       "  5.56,\n",
       "  62.8,\n",
       "  1.9865,\n",
       "  5.0,\n",
       "  264.0,\n",
       "  13.0,\n",
       "  392.4,\n",
       "  10.45],\n",
       " [0.7857,\n",
       "  20.0,\n",
       "  3.97,\n",
       "  0.0,\n",
       "  0.647,\n",
       "  7.014,\n",
       "  84.6,\n",
       "  2.1329,\n",
       "  5.0,\n",
       "  264.0,\n",
       "  13.0,\n",
       "  384.07,\n",
       "  14.79],\n",
       " [0.57834,\n",
       "  20.0,\n",
       "  3.97,\n",
       "  0.0,\n",
       "  0.575,\n",
       "  8.297,\n",
       "  67.0,\n",
       "  2.4216,\n",
       "  5.0,\n",
       "  264.0,\n",
       "  13.0,\n",
       "  384.54,\n",
       "  7.44],\n",
       " [0.5405,\n",
       "  20.0,\n",
       "  3.97,\n",
       "  0.0,\n",
       "  0.575,\n",
       "  7.47,\n",
       "  52.6,\n",
       "  2.872,\n",
       "  5.0,\n",
       "  264.0,\n",
       "  13.0,\n",
       "  390.3,\n",
       "  3.16],\n",
       " [0.09065,\n",
       "  20.0,\n",
       "  6.96,\n",
       "  1.0,\n",
       "  0.464,\n",
       "  5.92,\n",
       "  61.5,\n",
       "  3.9175,\n",
       "  3.0,\n",
       "  223.0,\n",
       "  18.6,\n",
       "  391.34,\n",
       "  13.65],\n",
       " [0.29916,\n",
       "  20.0,\n",
       "  6.96,\n",
       "  0.0,\n",
       "  0.464,\n",
       "  5.856,\n",
       "  42.1,\n",
       "  4.429,\n",
       "  3.0,\n",
       "  223.0,\n",
       "  18.6,\n",
       "  388.65,\n",
       "  13.0],\n",
       " [0.16211,\n",
       "  20.0,\n",
       "  6.96,\n",
       "  0.0,\n",
       "  0.464,\n",
       "  6.24,\n",
       "  16.3,\n",
       "  4.429,\n",
       "  3.0,\n",
       "  223.0,\n",
       "  18.6,\n",
       "  396.9,\n",
       "  6.59],\n",
       " [0.1146,\n",
       "  20.0,\n",
       "  6.96,\n",
       "  0.0,\n",
       "  0.464,\n",
       "  6.538,\n",
       "  58.7,\n",
       "  3.9175,\n",
       "  3.0,\n",
       "  223.0,\n",
       "  18.6,\n",
       "  394.96,\n",
       "  7.73],\n",
       " [0.22188,\n",
       "  20.0,\n",
       "  6.96,\n",
       "  1.0,\n",
       "  0.464,\n",
       "  7.691,\n",
       "  51.8,\n",
       "  4.3665,\n",
       "  3.0,\n",
       "  223.0,\n",
       "  18.6,\n",
       "  390.77,\n",
       "  6.58],\n",
       " [0.05644,\n",
       "  40.0,\n",
       "  6.41,\n",
       "  1.0,\n",
       "  0.447,\n",
       "  6.758,\n",
       "  32.9,\n",
       "  4.0776,\n",
       "  4.0,\n",
       "  254.0,\n",
       "  17.6,\n",
       "  396.9,\n",
       "  3.53],\n",
       " [0.09604,\n",
       "  40.0,\n",
       "  6.41,\n",
       "  0.0,\n",
       "  0.447,\n",
       "  6.854,\n",
       "  42.8,\n",
       "  4.2673,\n",
       "  4.0,\n",
       "  254.0,\n",
       "  17.6,\n",
       "  396.9,\n",
       "  2.98],\n",
       " [0.10469,\n",
       "  40.0,\n",
       "  6.41,\n",
       "  1.0,\n",
       "  0.447,\n",
       "  7.267,\n",
       "  49.0,\n",
       "  4.7872,\n",
       "  4.0,\n",
       "  254.0,\n",
       "  17.6,\n",
       "  389.25,\n",
       "  6.05],\n",
       " [0.06127,\n",
       "  40.0,\n",
       "  6.41,\n",
       "  1.0,\n",
       "  0.447,\n",
       "  6.826,\n",
       "  27.6,\n",
       "  4.8628,\n",
       "  4.0,\n",
       "  254.0,\n",
       "  17.6,\n",
       "  393.45,\n",
       "  4.16],\n",
       " [0.07978,\n",
       "  40.0,\n",
       "  6.41,\n",
       "  0.0,\n",
       "  0.447,\n",
       "  6.482,\n",
       "  32.1,\n",
       "  4.1403,\n",
       "  4.0,\n",
       "  254.0,\n",
       "  17.6,\n",
       "  396.9,\n",
       "  7.19],\n",
       " [0.21038,\n",
       "  20.0,\n",
       "  3.33,\n",
       "  0.0,\n",
       "  0.4429,\n",
       "  6.812,\n",
       "  32.2,\n",
       "  4.1007,\n",
       "  5.0,\n",
       "  216.0,\n",
       "  14.9,\n",
       "  396.9,\n",
       "  4.85],\n",
       " [0.03578,\n",
       "  20.0,\n",
       "  3.33,\n",
       "  0.0,\n",
       "  0.4429,\n",
       "  7.82,\n",
       "  64.5,\n",
       "  4.6947,\n",
       "  5.0,\n",
       "  216.0,\n",
       "  14.9,\n",
       "  387.31,\n",
       "  3.76],\n",
       " [0.03705,\n",
       "  20.0,\n",
       "  3.33,\n",
       "  0.0,\n",
       "  0.4429,\n",
       "  6.968,\n",
       "  37.2,\n",
       "  5.2447,\n",
       "  5.0,\n",
       "  216.0,\n",
       "  14.9,\n",
       "  392.23,\n",
       "  4.59],\n",
       " [0.06129,\n",
       "  20.0,\n",
       "  3.33,\n",
       "  1.0,\n",
       "  0.4429,\n",
       "  7.645,\n",
       "  49.7,\n",
       "  5.2119,\n",
       "  5.0,\n",
       "  216.0,\n",
       "  14.9,\n",
       "  377.07,\n",
       "  3.01],\n",
       " [0.01501,\n",
       "  90.0,\n",
       "  1.21,\n",
       "  1.0,\n",
       "  0.401,\n",
       "  7.923,\n",
       "  24.8,\n",
       "  5.885,\n",
       "  1.0,\n",
       "  198.0,\n",
       "  13.6,\n",
       "  395.52,\n",
       "  3.16],\n",
       " [0.00906,\n",
       "  90.0,\n",
       "  2.97,\n",
       "  0.0,\n",
       "  0.4,\n",
       "  7.088,\n",
       "  20.8,\n",
       "  7.3073,\n",
       "  1.0,\n",
       "  285.0,\n",
       "  15.3,\n",
       "  394.72,\n",
       "  7.85],\n",
       " [0.01096,\n",
       "  55.0,\n",
       "  2.25,\n",
       "  0.0,\n",
       "  0.389,\n",
       "  6.453,\n",
       "  31.9,\n",
       "  7.3073,\n",
       "  1.0,\n",
       "  300.0,\n",
       "  15.3,\n",
       "  394.72,\n",
       "  8.23],\n",
       " [0.01965,\n",
       "  80.0,\n",
       "  1.76,\n",
       "  0.0,\n",
       "  0.385,\n",
       "  6.23,\n",
       "  31.5,\n",
       "  9.0892,\n",
       "  1.0,\n",
       "  241.0,\n",
       "  18.2,\n",
       "  341.6,\n",
       "  12.93],\n",
       " [0.03871,\n",
       "  52.5,\n",
       "  5.32,\n",
       "  0.0,\n",
       "  0.405,\n",
       "  6.209,\n",
       "  31.3,\n",
       "  7.3172,\n",
       "  6.0,\n",
       "  293.0,\n",
       "  16.6,\n",
       "  396.9,\n",
       "  7.14],\n",
       " [0.0459,\n",
       "  52.5,\n",
       "  5.32,\n",
       "  0.0,\n",
       "  0.405,\n",
       "  6.315,\n",
       "  45.6,\n",
       "  7.3172,\n",
       "  6.0,\n",
       "  293.0,\n",
       "  16.6,\n",
       "  396.9,\n",
       "  7.6],\n",
       " [0.04297,\n",
       "  52.5,\n",
       "  5.32,\n",
       "  0.0,\n",
       "  0.405,\n",
       "  6.565,\n",
       "  22.9,\n",
       "  7.3172,\n",
       "  6.0,\n",
       "  293.0,\n",
       "  16.6,\n",
       "  371.72,\n",
       "  9.51],\n",
       " [0.03502,\n",
       "  80.0,\n",
       "  4.95,\n",
       "  0.0,\n",
       "  0.411,\n",
       "  6.861,\n",
       "  27.9,\n",
       "  5.1167,\n",
       "  4.0,\n",
       "  245.0,\n",
       "  19.2,\n",
       "  396.9,\n",
       "  3.33],\n",
       " [0.07886,\n",
       "  80.0,\n",
       "  4.95,\n",
       "  0.0,\n",
       "  0.411,\n",
       "  7.148,\n",
       "  27.7,\n",
       "  5.1167,\n",
       "  4.0,\n",
       "  245.0,\n",
       "  19.2,\n",
       "  396.9,\n",
       "  3.56],\n",
       " [0.03615,\n",
       "  80.0,\n",
       "  4.95,\n",
       "  0.0,\n",
       "  0.411,\n",
       "  6.63,\n",
       "  23.4,\n",
       "  5.1167,\n",
       "  4.0,\n",
       "  245.0,\n",
       "  19.2,\n",
       "  396.9,\n",
       "  4.7],\n",
       " [0.08265,\n",
       "  0.0,\n",
       "  13.92,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  6.127,\n",
       "  18.4,\n",
       "  5.5027,\n",
       "  4.0,\n",
       "  289.0,\n",
       "  16.0,\n",
       "  396.9,\n",
       "  8.58],\n",
       " [0.08199,\n",
       "  0.0,\n",
       "  13.92,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  6.009,\n",
       "  42.3,\n",
       "  5.5027,\n",
       "  4.0,\n",
       "  289.0,\n",
       "  16.0,\n",
       "  396.9,\n",
       "  10.4],\n",
       " [0.12932,\n",
       "  0.0,\n",
       "  13.92,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  6.678,\n",
       "  31.1,\n",
       "  5.9604,\n",
       "  4.0,\n",
       "  289.0,\n",
       "  16.0,\n",
       "  396.9,\n",
       "  6.27],\n",
       " [0.05372,\n",
       "  0.0,\n",
       "  13.92,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  6.549,\n",
       "  51.0,\n",
       "  5.9604,\n",
       "  4.0,\n",
       "  289.0,\n",
       "  16.0,\n",
       "  392.85,\n",
       "  7.39],\n",
       " [0.14103,\n",
       "  0.0,\n",
       "  13.92,\n",
       "  0.0,\n",
       "  0.437,\n",
       "  5.79,\n",
       "  58.0,\n",
       "  6.32,\n",
       "  4.0,\n",
       "  289.0,\n",
       "  16.0,\n",
       "  396.9,\n",
       "  15.84],\n",
       " [0.06466,\n",
       "  70.0,\n",
       "  2.24,\n",
       "  0.0,\n",
       "  0.4,\n",
       "  6.345,\n",
       "  20.1,\n",
       "  7.8278,\n",
       "  5.0,\n",
       "  358.0,\n",
       "  14.8,\n",
       "  368.24,\n",
       "  4.97],\n",
       " [0.05561,\n",
       "  70.0,\n",
       "  2.24,\n",
       "  0.0,\n",
       "  0.4,\n",
       "  7.041,\n",
       "  10.0,\n",
       "  7.8278,\n",
       "  5.0,\n",
       "  358.0,\n",
       "  14.8,\n",
       "  371.58,\n",
       "  4.74],\n",
       " [0.04417,\n",
       "  70.0,\n",
       "  2.24,\n",
       "  0.0,\n",
       "  0.4,\n",
       "  6.871,\n",
       "  47.4,\n",
       "  7.8278,\n",
       "  5.0,\n",
       "  358.0,\n",
       "  14.8,\n",
       "  390.86,\n",
       "  6.07],\n",
       " [0.03537,\n",
       "  34.0,\n",
       "  6.09,\n",
       "  0.0,\n",
       "  0.433,\n",
       "  6.59,\n",
       "  40.4,\n",
       "  5.4917,\n",
       "  7.0,\n",
       "  329.0,\n",
       "  16.1,\n",
       "  395.75,\n",
       "  9.5],\n",
       " [0.09266,\n",
       "  34.0,\n",
       "  6.09,\n",
       "  0.0,\n",
       "  0.433,\n",
       "  6.495,\n",
       "  18.4,\n",
       "  5.4917,\n",
       "  7.0,\n",
       "  329.0,\n",
       "  16.1,\n",
       "  383.61,\n",
       "  8.67],\n",
       " [0.1,\n",
       "  34.0,\n",
       "  6.09,\n",
       "  0.0,\n",
       "  0.433,\n",
       "  6.982,\n",
       "  17.7,\n",
       "  5.4917,\n",
       "  7.0,\n",
       "  329.0,\n",
       "  16.1,\n",
       "  390.43,\n",
       "  4.86],\n",
       " [0.05515,\n",
       "  33.0,\n",
       "  2.18,\n",
       "  0.0,\n",
       "  0.472,\n",
       "  7.236,\n",
       "  41.1,\n",
       "  4.022,\n",
       "  7.0,\n",
       "  222.0,\n",
       "  18.4,\n",
       "  393.68,\n",
       "  6.93],\n",
       " [0.05479,\n",
       "  33.0,\n",
       "  2.18,\n",
       "  0.0,\n",
       "  0.472,\n",
       "  6.616,\n",
       "  58.1,\n",
       "  3.37,\n",
       "  7.0,\n",
       "  222.0,\n",
       "  18.4,\n",
       "  393.36,\n",
       "  8.93],\n",
       " [0.07503,\n",
       "  33.0,\n",
       "  2.18,\n",
       "  0.0,\n",
       "  0.472,\n",
       "  7.42,\n",
       "  71.9,\n",
       "  3.0992,\n",
       "  7.0,\n",
       "  222.0,\n",
       "  18.4,\n",
       "  396.9,\n",
       "  6.47],\n",
       " [0.04932,\n",
       "  33.0,\n",
       "  2.18,\n",
       "  0.0,\n",
       "  0.472,\n",
       "  6.849,\n",
       "  70.3,\n",
       "  3.1827,\n",
       "  7.0,\n",
       "  222.0,\n",
       "  18.4,\n",
       "  396.9,\n",
       "  7.53],\n",
       " [0.49298,\n",
       "  0.0,\n",
       "  9.9,\n",
       "  0.0,\n",
       "  0.544,\n",
       "  6.635,\n",
       "  82.5,\n",
       "  3.3175,\n",
       "  4.0,\n",
       "  304.0,\n",
       "  18.4,\n",
       "  396.9,\n",
       "  4.54],\n",
       " [0.3494,\n",
       "  0.0,\n",
       "  9.9,\n",
       "  0.0,\n",
       "  0.544,\n",
       "  5.972,\n",
       "  76.7,\n",
       "  3.1025,\n",
       "  4.0,\n",
       "  304.0,\n",
       "  18.4,\n",
       "  396.24,\n",
       "  9.97],\n",
       " [2.63548,\n",
       "  0.0,\n",
       "  9.9,\n",
       "  0.0,\n",
       "  0.544,\n",
       "  4.973,\n",
       "  37.8,\n",
       "  2.5194,\n",
       "  4.0,\n",
       "  304.0,\n",
       "  18.4,\n",
       "  350.45,\n",
       "  12.64],\n",
       " [0.79041,\n",
       "  0.0,\n",
       "  9.9,\n",
       "  0.0,\n",
       "  0.544,\n",
       "  6.122,\n",
       "  52.8,\n",
       "  2.6403,\n",
       "  4.0,\n",
       "  304.0,\n",
       "  18.4,\n",
       "  396.9,\n",
       "  5.98],\n",
       " [0.26169,\n",
       "  0.0,\n",
       "  9.9,\n",
       "  0.0,\n",
       "  0.544,\n",
       "  6.023,\n",
       "  90.4,\n",
       "  2.834,\n",
       "  4.0,\n",
       "  304.0,\n",
       "  18.4,\n",
       "  396.3,\n",
       "  11.72],\n",
       " [0.26938,\n",
       "  0.0,\n",
       "  9.9,\n",
       "  0.0,\n",
       "  0.544,\n",
       "  6.266,\n",
       "  82.8,\n",
       "  3.2628,\n",
       "  4.0,\n",
       "  304.0,\n",
       "  18.4,\n",
       "  393.39,\n",
       "  7.9],\n",
       " [0.3692,\n",
       "  0.0,\n",
       "  9.9,\n",
       "  0.0,\n",
       "  0.544,\n",
       "  6.567,\n",
       "  87.3,\n",
       "  3.6023,\n",
       "  4.0,\n",
       "  304.0,\n",
       "  18.4,\n",
       "  395.69,\n",
       "  9.28],\n",
       " [0.25356,\n",
       "  0.0,\n",
       "  9.9,\n",
       "  0.0,\n",
       "  0.544,\n",
       "  5.705,\n",
       "  77.7,\n",
       "  3.945,\n",
       "  4.0,\n",
       "  304.0,\n",
       "  18.4,\n",
       "  396.42,\n",
       "  11.5],\n",
       " [0.31827,\n",
       "  0.0,\n",
       "  9.9,\n",
       "  0.0,\n",
       "  0.544,\n",
       "  5.914,\n",
       "  83.2,\n",
       "  3.9986,\n",
       "  4.0,\n",
       "  304.0,\n",
       "  18.4,\n",
       "  390.7,\n",
       "  18.33],\n",
       " [0.24522,\n",
       "  0.0,\n",
       "  9.9,\n",
       "  0.0,\n",
       "  0.544,\n",
       "  5.782,\n",
       "  71.7,\n",
       "  4.0317,\n",
       "  4.0,\n",
       "  304.0,\n",
       "  18.4,\n",
       "  396.9,\n",
       "  15.94],\n",
       " [0.40202,\n",
       "  0.0,\n",
       "  9.9,\n",
       "  0.0,\n",
       "  0.544,\n",
       "  6.382,\n",
       "  67.2,\n",
       "  3.5325,\n",
       "  4.0,\n",
       "  304.0,\n",
       "  18.4,\n",
       "  395.21,\n",
       "  10.36],\n",
       " [0.47547,\n",
       "  0.0,\n",
       "  9.9,\n",
       "  0.0,\n",
       "  0.544,\n",
       "  6.113,\n",
       "  58.8,\n",
       "  4.0019,\n",
       "  4.0,\n",
       "  304.0,\n",
       "  18.4,\n",
       "  396.23,\n",
       "  12.73],\n",
       " [0.1676,\n",
       "  0.0,\n",
       "  7.38,\n",
       "  0.0,\n",
       "  0.493,\n",
       "  6.426,\n",
       "  52.3,\n",
       "  4.5404,\n",
       "  5.0,\n",
       "  287.0,\n",
       "  19.6,\n",
       "  396.9,\n",
       "  7.2],\n",
       " [0.18159,\n",
       "  0.0,\n",
       "  7.38,\n",
       "  0.0,\n",
       "  0.493,\n",
       "  6.376,\n",
       "  54.3,\n",
       "  4.5404,\n",
       "  5.0,\n",
       "  287.0,\n",
       "  19.6,\n",
       "  396.9,\n",
       "  6.87],\n",
       " [0.35114,\n",
       "  0.0,\n",
       "  7.38,\n",
       "  0.0,\n",
       "  0.493,\n",
       "  6.041,\n",
       "  49.9,\n",
       "  4.7211,\n",
       "  5.0,\n",
       "  287.0,\n",
       "  19.6,\n",
       "  396.9,\n",
       "  7.7],\n",
       " [0.28392,\n",
       "  0.0,\n",
       "  7.38,\n",
       "  0.0,\n",
       "  0.493,\n",
       "  5.708,\n",
       "  74.3,\n",
       "  4.7211,\n",
       "  5.0,\n",
       "  287.0,\n",
       "  19.6,\n",
       "  391.13,\n",
       "  11.74],\n",
       " [0.34109,\n",
       "  0.0,\n",
       "  7.38,\n",
       "  0.0,\n",
       "  0.493,\n",
       "  6.415,\n",
       "  40.1,\n",
       "  4.7211,\n",
       "  5.0,\n",
       "  287.0,\n",
       "  19.6,\n",
       "  396.9,\n",
       "  6.12],\n",
       " [0.19186,\n",
       "  0.0,\n",
       "  7.38,\n",
       "  0.0,\n",
       "  0.493,\n",
       "  6.431,\n",
       "  14.7,\n",
       "  5.4159,\n",
       "  5.0,\n",
       "  287.0,\n",
       "  19.6,\n",
       "  393.68,\n",
       "  5.08],\n",
       " [0.30347,\n",
       "  0.0,\n",
       "  7.38,\n",
       "  0.0,\n",
       "  0.493,\n",
       "  6.312,\n",
       "  28.9,\n",
       "  5.4159,\n",
       "  5.0,\n",
       "  287.0,\n",
       "  19.6,\n",
       "  396.9,\n",
       "  6.15],\n",
       " [0.24103,\n",
       "  0.0,\n",
       "  7.38,\n",
       "  0.0,\n",
       "  0.493,\n",
       "  6.083,\n",
       "  43.7,\n",
       "  5.4159,\n",
       "  5.0,\n",
       "  287.0,\n",
       "  19.6,\n",
       "  396.9,\n",
       "  12.79],\n",
       " [0.06617,\n",
       "  0.0,\n",
       "  3.24,\n",
       "  0.0,\n",
       "  0.46,\n",
       "  5.868,\n",
       "  25.8,\n",
       "  5.2146,\n",
       "  4.0,\n",
       "  430.0,\n",
       "  16.9,\n",
       "  382.44,\n",
       "  9.97],\n",
       " [0.06724,\n",
       "  0.0,\n",
       "  3.24,\n",
       "  0.0,\n",
       "  0.46,\n",
       "  6.333,\n",
       "  17.2,\n",
       "  5.2146,\n",
       "  4.0,\n",
       "  430.0,\n",
       "  16.9,\n",
       "  375.21,\n",
       "  7.34],\n",
       " [0.04544,\n",
       "  0.0,\n",
       "  3.24,\n",
       "  0.0,\n",
       "  0.46,\n",
       "  6.144,\n",
       "  32.2,\n",
       "  5.8736,\n",
       "  4.0,\n",
       "  430.0,\n",
       "  16.9,\n",
       "  368.57,\n",
       "  9.09],\n",
       " [0.05023,\n",
       "  35.0,\n",
       "  6.06,\n",
       "  0.0,\n",
       "  0.4379,\n",
       "  5.706,\n",
       "  28.4,\n",
       "  6.6407,\n",
       "  1.0,\n",
       "  304.0,\n",
       "  16.9,\n",
       "  394.02,\n",
       "  12.43],\n",
       " [0.03466,\n",
       "  35.0,\n",
       "  6.06,\n",
       "  0.0,\n",
       "  0.4379,\n",
       "  6.031,\n",
       "  23.3,\n",
       "  6.6407,\n",
       "  1.0,\n",
       "  304.0,\n",
       "  16.9,\n",
       "  362.25,\n",
       "  7.83],\n",
       " [0.05083,\n",
       "  0.0,\n",
       "  5.19,\n",
       "  0.0,\n",
       "  0.515,\n",
       "  6.316,\n",
       "  38.1,\n",
       "  6.4584,\n",
       "  5.0,\n",
       "  224.0,\n",
       "  20.2,\n",
       "  389.71,\n",
       "  5.68],\n",
       " [0.03738,\n",
       "  0.0,\n",
       "  5.19,\n",
       "  0.0,\n",
       "  0.515,\n",
       "  6.31,\n",
       "  38.5,\n",
       "  6.4584,\n",
       "  5.0,\n",
       "  224.0,\n",
       "  20.2,\n",
       "  389.4,\n",
       "  6.75],\n",
       " [0.03961,\n",
       "  0.0,\n",
       "  5.19,\n",
       "  0.0,\n",
       "  0.515,\n",
       "  6.037,\n",
       "  34.5,\n",
       "  5.9853,\n",
       "  5.0,\n",
       "  224.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  8.01],\n",
       " [0.03427,\n",
       "  0.0,\n",
       "  5.19,\n",
       "  0.0,\n",
       "  0.515,\n",
       "  5.869,\n",
       "  46.3,\n",
       "  5.2311,\n",
       "  5.0,\n",
       "  224.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  9.8],\n",
       " [0.03041,\n",
       "  0.0,\n",
       "  5.19,\n",
       "  0.0,\n",
       "  0.515,\n",
       "  5.895,\n",
       "  59.6,\n",
       "  5.615,\n",
       "  5.0,\n",
       "  224.0,\n",
       "  20.2,\n",
       "  394.81,\n",
       "  10.56],\n",
       " [0.03306,\n",
       "  0.0,\n",
       "  5.19,\n",
       "  0.0,\n",
       "  0.515,\n",
       "  6.059,\n",
       "  37.3,\n",
       "  4.8122,\n",
       "  5.0,\n",
       "  224.0,\n",
       "  20.2,\n",
       "  396.14,\n",
       "  8.51],\n",
       " [0.05497,\n",
       "  0.0,\n",
       "  5.19,\n",
       "  0.0,\n",
       "  0.515,\n",
       "  5.985,\n",
       "  45.4,\n",
       "  4.8122,\n",
       "  5.0,\n",
       "  224.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  9.74],\n",
       " [0.06151,\n",
       "  0.0,\n",
       "  5.19,\n",
       "  0.0,\n",
       "  0.515,\n",
       "  5.968,\n",
       "  58.5,\n",
       "  4.8122,\n",
       "  5.0,\n",
       "  224.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  9.29],\n",
       " [0.01301,\n",
       "  35.0,\n",
       "  1.52,\n",
       "  0.0,\n",
       "  0.442,\n",
       "  7.241,\n",
       "  49.3,\n",
       "  7.0379,\n",
       "  1.0,\n",
       "  284.0,\n",
       "  15.5,\n",
       "  394.74,\n",
       "  5.49],\n",
       " [0.02498,\n",
       "  0.0,\n",
       "  1.89,\n",
       "  0.0,\n",
       "  0.518,\n",
       "  6.54,\n",
       "  59.7,\n",
       "  6.2669,\n",
       "  1.0,\n",
       "  422.0,\n",
       "  15.9,\n",
       "  389.96,\n",
       "  8.65],\n",
       " [0.02543,\n",
       "  55.0,\n",
       "  3.78,\n",
       "  0.0,\n",
       "  0.484,\n",
       "  6.696,\n",
       "  56.4,\n",
       "  5.7321,\n",
       "  5.0,\n",
       "  370.0,\n",
       "  17.6,\n",
       "  396.9,\n",
       "  7.18],\n",
       " [0.03049,\n",
       "  55.0,\n",
       "  3.78,\n",
       "  0.0,\n",
       "  0.484,\n",
       "  6.874,\n",
       "  28.1,\n",
       "  6.4654,\n",
       "  5.0,\n",
       "  370.0,\n",
       "  17.6,\n",
       "  387.97,\n",
       "  4.61],\n",
       " [0.03113,\n",
       "  0.0,\n",
       "  4.39,\n",
       "  0.0,\n",
       "  0.442,\n",
       "  6.014,\n",
       "  48.5,\n",
       "  8.0136,\n",
       "  3.0,\n",
       "  352.0,\n",
       "  18.8,\n",
       "  385.64,\n",
       "  10.53],\n",
       " [0.06162,\n",
       "  0.0,\n",
       "  4.39,\n",
       "  0.0,\n",
       "  0.442,\n",
       "  5.898,\n",
       "  52.3,\n",
       "  8.0136,\n",
       "  3.0,\n",
       "  352.0,\n",
       "  18.8,\n",
       "  364.61,\n",
       "  12.67],\n",
       " [0.0187,\n",
       "  85.0,\n",
       "  4.15,\n",
       "  0.0,\n",
       "  0.429,\n",
       "  6.516,\n",
       "  27.7,\n",
       "  8.5353,\n",
       "  4.0,\n",
       "  351.0,\n",
       "  17.9,\n",
       "  392.43,\n",
       "  6.36],\n",
       " [0.01501,\n",
       "  80.0,\n",
       "  2.01,\n",
       "  0.0,\n",
       "  0.435,\n",
       "  6.635,\n",
       "  29.7,\n",
       "  8.344,\n",
       "  4.0,\n",
       "  280.0,\n",
       "  17.0,\n",
       "  390.94,\n",
       "  5.99],\n",
       " [0.02899,\n",
       "  40.0,\n",
       "  1.25,\n",
       "  0.0,\n",
       "  0.429,\n",
       "  6.939,\n",
       "  34.5,\n",
       "  8.7921,\n",
       "  1.0,\n",
       "  335.0,\n",
       "  19.7,\n",
       "  389.85,\n",
       "  5.89],\n",
       " [0.06211,\n",
       "  40.0,\n",
       "  1.25,\n",
       "  0.0,\n",
       "  0.429,\n",
       "  6.49,\n",
       "  44.4,\n",
       "  8.7921,\n",
       "  1.0,\n",
       "  335.0,\n",
       "  19.7,\n",
       "  396.9,\n",
       "  5.98],\n",
       " [0.0795,\n",
       "  60.0,\n",
       "  1.69,\n",
       "  0.0,\n",
       "  0.411,\n",
       "  6.579,\n",
       "  35.9,\n",
       "  10.7103,\n",
       "  4.0,\n",
       "  411.0,\n",
       "  18.3,\n",
       "  370.78,\n",
       "  5.49],\n",
       " [0.07244,\n",
       "  60.0,\n",
       "  1.69,\n",
       "  0.0,\n",
       "  0.411,\n",
       "  5.884,\n",
       "  18.5,\n",
       "  10.7103,\n",
       "  4.0,\n",
       "  411.0,\n",
       "  18.3,\n",
       "  392.33,\n",
       "  7.79],\n",
       " [0.01709,\n",
       "  90.0,\n",
       "  2.02,\n",
       "  0.0,\n",
       "  0.41,\n",
       "  6.728,\n",
       "  36.1,\n",
       "  12.1265,\n",
       "  5.0,\n",
       "  187.0,\n",
       "  17.0,\n",
       "  384.46,\n",
       "  4.5],\n",
       " [0.04301,\n",
       "  80.0,\n",
       "  1.91,\n",
       "  0.0,\n",
       "  0.413,\n",
       "  5.663,\n",
       "  21.9,\n",
       "  10.5857,\n",
       "  4.0,\n",
       "  334.0,\n",
       "  22.0,\n",
       "  382.8,\n",
       "  8.05],\n",
       " [0.10659,\n",
       "  80.0,\n",
       "  1.91,\n",
       "  0.0,\n",
       "  0.413,\n",
       "  5.936,\n",
       "  19.5,\n",
       "  10.5857,\n",
       "  4.0,\n",
       "  334.0,\n",
       "  22.0,\n",
       "  376.04,\n",
       "  5.57],\n",
       " [8.98296,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  1.0,\n",
       "  0.77,\n",
       "  6.212,\n",
       "  97.4,\n",
       "  2.1222,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  377.73,\n",
       "  17.6],\n",
       " [3.8497,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  1.0,\n",
       "  0.77,\n",
       "  6.395,\n",
       "  91.0,\n",
       "  2.5052,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  391.34,\n",
       "  13.27],\n",
       " [5.20177,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  1.0,\n",
       "  0.77,\n",
       "  6.127,\n",
       "  83.4,\n",
       "  2.7227,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  395.43,\n",
       "  11.48],\n",
       " [4.26131,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.77,\n",
       "  6.112,\n",
       "  81.3,\n",
       "  2.5091,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  390.74,\n",
       "  12.67],\n",
       " [4.54192,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.77,\n",
       "  6.398,\n",
       "  88.0,\n",
       "  2.5182,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  374.56,\n",
       "  7.79],\n",
       " [3.83684,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.77,\n",
       "  6.251,\n",
       "  91.1,\n",
       "  2.2955,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  350.65,\n",
       "  14.19],\n",
       " [3.67822,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.77,\n",
       "  5.362,\n",
       "  96.2,\n",
       "  2.1036,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  380.79,\n",
       "  10.19],\n",
       " [4.22239,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  1.0,\n",
       "  0.77,\n",
       "  5.803,\n",
       "  89.0,\n",
       "  1.9047,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  353.04,\n",
       "  14.64],\n",
       " [3.47428,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  1.0,\n",
       "  0.718,\n",
       "  8.78,\n",
       "  82.9,\n",
       "  1.9047,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  354.55,\n",
       "  5.29],\n",
       " [4.55587,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.718,\n",
       "  3.561,\n",
       "  87.9,\n",
       "  1.6132,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  354.7,\n",
       "  7.12],\n",
       " [3.69695,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.718,\n",
       "  4.963,\n",
       "  91.4,\n",
       "  1.7523,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  316.03,\n",
       "  14.0],\n",
       " [13.5222,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.631,\n",
       "  3.863,\n",
       "  100.0,\n",
       "  1.5106,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  131.42,\n",
       "  13.33],\n",
       " [4.89822,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.631,\n",
       "  4.97,\n",
       "  100.0,\n",
       "  1.3325,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  375.52,\n",
       "  3.26],\n",
       " [5.66998,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  1.0,\n",
       "  0.631,\n",
       "  6.683,\n",
       "  96.8,\n",
       "  1.3567,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  375.33,\n",
       "  3.73],\n",
       " [6.53876,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  1.0,\n",
       "  0.631,\n",
       "  7.016,\n",
       "  97.5,\n",
       "  1.2024,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  392.05,\n",
       "  2.96],\n",
       " [9.2323,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.631,\n",
       "  6.216,\n",
       "  100.0,\n",
       "  1.1691,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  366.15,\n",
       "  9.53],\n",
       " [8.26725,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  1.0,\n",
       "  0.668,\n",
       "  5.875,\n",
       "  89.6,\n",
       "  1.1296,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  347.88,\n",
       "  8.88],\n",
       " [11.1081,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.668,\n",
       "  4.906,\n",
       "  100.0,\n",
       "  1.1742,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  34.77],\n",
       " [18.4982,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.668,\n",
       "  4.138,\n",
       "  100.0,\n",
       "  1.137,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  37.97],\n",
       " [19.6091,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.671,\n",
       "  7.313,\n",
       "  97.9,\n",
       "  1.3163,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  13.44],\n",
       " [15.288,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.671,\n",
       "  6.649,\n",
       "  93.3,\n",
       "  1.3449,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  363.02,\n",
       "  23.24],\n",
       " [9.82349,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.671,\n",
       "  6.794,\n",
       "  98.8,\n",
       "  1.358,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  21.24],\n",
       " [23.6482,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.671,\n",
       "  6.38,\n",
       "  96.2,\n",
       "  1.3861,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  23.69],\n",
       " [17.8667,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.671,\n",
       "  6.223,\n",
       "  100.0,\n",
       "  1.3861,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  393.74,\n",
       "  21.78],\n",
       " [88.9762,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.671,\n",
       "  6.968,\n",
       "  91.9,\n",
       "  1.4165,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  17.21],\n",
       " [15.8744,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.671,\n",
       "  6.545,\n",
       "  99.1,\n",
       "  1.5192,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  21.08],\n",
       " [9.18702,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.7,\n",
       "  5.536,\n",
       "  100.0,\n",
       "  1.5804,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  23.6],\n",
       " [7.99248,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.7,\n",
       "  5.52,\n",
       "  100.0,\n",
       "  1.5331,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  24.56],\n",
       " [20.0849,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.7,\n",
       "  4.368,\n",
       "  91.2,\n",
       "  1.4395,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  285.83,\n",
       "  30.63],\n",
       " [16.8118,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.7,\n",
       "  5.277,\n",
       "  98.1,\n",
       "  1.4261,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  30.81],\n",
       " [24.3938,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.7,\n",
       "  4.652,\n",
       "  100.0,\n",
       "  1.4672,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  28.28],\n",
       " [22.5971,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.7,\n",
       "  5.0,\n",
       "  89.5,\n",
       "  1.5184,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  31.99],\n",
       " [14.3337,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.7,\n",
       "  4.88,\n",
       "  100.0,\n",
       "  1.5895,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  372.92,\n",
       "  30.62],\n",
       " [8.15174,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.7,\n",
       "  5.39,\n",
       "  98.9,\n",
       "  1.7281,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  20.85],\n",
       " [6.96215,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.7,\n",
       "  5.713,\n",
       "  97.0,\n",
       "  1.9265,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  394.43,\n",
       "  17.11],\n",
       " [5.29305,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.7,\n",
       "  6.051,\n",
       "  82.5,\n",
       "  2.1678,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  378.38,\n",
       "  18.76],\n",
       " [11.5779,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.7,\n",
       "  5.036,\n",
       "  97.0,\n",
       "  1.77,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  25.68],\n",
       " [8.64476,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  6.193,\n",
       "  92.6,\n",
       "  1.7912,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  15.17],\n",
       " [13.3598,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  5.887,\n",
       "  94.7,\n",
       "  1.7821,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  16.35],\n",
       " [8.71675,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  6.471,\n",
       "  98.8,\n",
       "  1.7257,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  391.98,\n",
       "  17.12],\n",
       " [5.87205,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  6.405,\n",
       "  96.0,\n",
       "  1.6768,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  19.37],\n",
       " [7.67202,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  5.747,\n",
       "  98.9,\n",
       "  1.6334,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  393.1,\n",
       "  19.92],\n",
       " [38.3518,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  5.453,\n",
       "  100.0,\n",
       "  1.4896,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  30.59],\n",
       " [9.91655,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  5.852,\n",
       "  77.8,\n",
       "  1.5004,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  338.16,\n",
       "  29.97],\n",
       " [25.0461,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  5.987,\n",
       "  100.0,\n",
       "  1.5888,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  26.77],\n",
       " [14.2362,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  6.343,\n",
       "  100.0,\n",
       "  1.5741,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  20.32],\n",
       " [9.59571,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  6.404,\n",
       "  100.0,\n",
       "  1.639,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  376.11,\n",
       "  20.31],\n",
       " [24.8017,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  5.349,\n",
       "  96.0,\n",
       "  1.7028,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  19.77],\n",
       " [41.5292,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  5.531,\n",
       "  85.4,\n",
       "  1.6074,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  329.46,\n",
       "  27.38],\n",
       " [67.9208,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  5.683,\n",
       "  100.0,\n",
       "  1.4254,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  384.97,\n",
       "  22.98],\n",
       " [20.7162,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.659,\n",
       "  4.138,\n",
       "  100.0,\n",
       "  1.1781,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  370.22,\n",
       "  23.34],\n",
       " [11.9511,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.659,\n",
       "  5.608,\n",
       "  100.0,\n",
       "  1.2852,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  332.09,\n",
       "  12.13],\n",
       " [7.40389,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.597,\n",
       "  5.617,\n",
       "  97.9,\n",
       "  1.4547,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  314.64,\n",
       "  26.4],\n",
       " [14.4383,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.597,\n",
       "  6.852,\n",
       "  100.0,\n",
       "  1.4655,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  179.36,\n",
       "  19.78],\n",
       " [51.1358,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.597,\n",
       "  5.757,\n",
       "  100.0,\n",
       "  1.413,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  2.6,\n",
       "  10.11],\n",
       " [14.0507,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.597,\n",
       "  6.657,\n",
       "  100.0,\n",
       "  1.5275,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  35.05,\n",
       "  21.22],\n",
       " [18.811,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.597,\n",
       "  4.628,\n",
       "  100.0,\n",
       "  1.5539,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  28.79,\n",
       "  34.37],\n",
       " [28.6558,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.597,\n",
       "  5.155,\n",
       "  100.0,\n",
       "  1.5894,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  210.97,\n",
       "  20.08],\n",
       " [45.7461,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.693,\n",
       "  4.519,\n",
       "  100.0,\n",
       "  1.6582,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  88.27,\n",
       "  36.98],\n",
       " [18.0846,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.679,\n",
       "  6.434,\n",
       "  100.0,\n",
       "  1.8347,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  27.25,\n",
       "  29.05],\n",
       " [10.8342,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.679,\n",
       "  6.782,\n",
       "  90.8,\n",
       "  1.8195,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  21.57,\n",
       "  25.79],\n",
       " [25.9406,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.679,\n",
       "  5.304,\n",
       "  89.1,\n",
       "  1.6475,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  127.36,\n",
       "  26.64],\n",
       " [73.5341,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.679,\n",
       "  5.957,\n",
       "  100.0,\n",
       "  1.8026,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  16.45,\n",
       "  20.62],\n",
       " [11.8123,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.718,\n",
       "  6.824,\n",
       "  76.5,\n",
       "  1.794,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  48.45,\n",
       "  22.74],\n",
       " [11.0874,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.718,\n",
       "  6.411,\n",
       "  100.0,\n",
       "  1.8589,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  318.75,\n",
       "  15.02],\n",
       " [7.02259,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.718,\n",
       "  6.006,\n",
       "  95.3,\n",
       "  1.8746,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  319.98,\n",
       "  15.7],\n",
       " [12.0482,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.614,\n",
       "  5.648,\n",
       "  87.6,\n",
       "  1.9512,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  291.55,\n",
       "  14.1],\n",
       " [7.05042,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.614,\n",
       "  6.103,\n",
       "  85.1,\n",
       "  2.0218,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  2.52,\n",
       "  23.29],\n",
       " [8.79212,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.584,\n",
       "  5.565,\n",
       "  70.6,\n",
       "  2.0635,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  3.65,\n",
       "  17.16],\n",
       " [15.8603,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.679,\n",
       "  5.896,\n",
       "  95.4,\n",
       "  1.9096,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  7.68,\n",
       "  24.39],\n",
       " [12.2472,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.584,\n",
       "  5.837,\n",
       "  59.7,\n",
       "  1.9976,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  24.65,\n",
       "  15.69],\n",
       " [37.6619,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.679,\n",
       "  6.202,\n",
       "  78.7,\n",
       "  1.8629,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  18.82,\n",
       "  14.52],\n",
       " [7.36711,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.679,\n",
       "  6.193,\n",
       "  78.1,\n",
       "  1.9356,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  96.73,\n",
       "  21.52],\n",
       " [9.33889,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.679,\n",
       "  6.38,\n",
       "  95.6,\n",
       "  1.9682,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  60.72,\n",
       "  24.08],\n",
       " [8.49213,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.584,\n",
       "  6.348,\n",
       "  86.1,\n",
       "  2.0527,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  83.45,\n",
       "  17.64],\n",
       " [10.0623,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.584,\n",
       "  6.833,\n",
       "  94.3,\n",
       "  2.0882,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  81.33,\n",
       "  19.69],\n",
       " [6.44405,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.584,\n",
       "  6.425,\n",
       "  74.8,\n",
       "  2.2004,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  97.95,\n",
       "  12.03],\n",
       " [5.58107,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.436,\n",
       "  87.9,\n",
       "  2.3158,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  100.19,\n",
       "  16.22],\n",
       " [13.9134,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.208,\n",
       "  95.0,\n",
       "  2.2222,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  100.63,\n",
       "  15.17],\n",
       " [11.1604,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.74,\n",
       "  6.629,\n",
       "  94.6,\n",
       "  2.1247,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  109.85,\n",
       "  23.27],\n",
       " [14.4208,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.74,\n",
       "  6.461,\n",
       "  93.3,\n",
       "  2.0026,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  27.49,\n",
       "  18.05],\n",
       " [15.1772,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.74,\n",
       "  6.152,\n",
       "  100.0,\n",
       "  1.9142,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  9.32,\n",
       "  26.45],\n",
       " [13.6781,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.74,\n",
       "  5.935,\n",
       "  87.9,\n",
       "  1.8206,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  68.95,\n",
       "  34.02],\n",
       " [9.39063,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.74,\n",
       "  5.627,\n",
       "  93.9,\n",
       "  1.8172,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  22.88],\n",
       " [22.0511,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.74,\n",
       "  5.818,\n",
       "  92.4,\n",
       "  1.8662,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  391.45,\n",
       "  22.11],\n",
       " [9.72418,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.74,\n",
       "  6.406,\n",
       "  97.2,\n",
       "  2.0651,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  385.96,\n",
       "  19.52],\n",
       " [5.66637,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.74,\n",
       "  6.219,\n",
       "  100.0,\n",
       "  2.0048,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  395.69,\n",
       "  16.59],\n",
       " [9.96654,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.74,\n",
       "  6.485,\n",
       "  100.0,\n",
       "  1.9784,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  386.73,\n",
       "  18.85],\n",
       " [12.8023,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.74,\n",
       "  5.854,\n",
       "  96.6,\n",
       "  1.8956,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  240.52,\n",
       "  23.79],\n",
       " [10.6718,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.74,\n",
       "  6.459,\n",
       "  94.8,\n",
       "  1.9879,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  43.06,\n",
       "  23.98],\n",
       " [6.28807,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.74,\n",
       "  6.341,\n",
       "  96.4,\n",
       "  2.072,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  318.01,\n",
       "  17.79],\n",
       " [9.92485,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.74,\n",
       "  6.251,\n",
       "  96.6,\n",
       "  2.198,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  388.52,\n",
       "  16.44],\n",
       " [9.32909,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.185,\n",
       "  98.7,\n",
       "  2.2616,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  18.13],\n",
       " [7.52601,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.417,\n",
       "  98.3,\n",
       "  2.185,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  304.21,\n",
       "  19.31],\n",
       " [6.71772,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.749,\n",
       "  92.6,\n",
       "  2.3236,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  0.32,\n",
       "  17.44],\n",
       " [5.44114,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.655,\n",
       "  98.2,\n",
       "  2.3552,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  355.29,\n",
       "  17.73],\n",
       " [5.09017,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.297,\n",
       "  91.8,\n",
       "  2.3682,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  385.09,\n",
       "  17.27],\n",
       " [8.24809,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  7.393,\n",
       "  99.3,\n",
       "  2.4527,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  375.87,\n",
       "  16.74],\n",
       " [9.51363,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.728,\n",
       "  94.1,\n",
       "  2.4961,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  6.68,\n",
       "  18.71],\n",
       " [4.75237,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.525,\n",
       "  86.5,\n",
       "  2.4358,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  50.92,\n",
       "  18.13],\n",
       " [4.66883,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  5.976,\n",
       "  87.9,\n",
       "  2.5806,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  10.48,\n",
       "  19.01],\n",
       " [8.20058,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  5.936,\n",
       "  80.3,\n",
       "  2.7792,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  3.5,\n",
       "  16.94],\n",
       " [7.75223,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.301,\n",
       "  83.7,\n",
       "  2.7831,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  272.21,\n",
       "  16.23],\n",
       " [6.80117,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.081,\n",
       "  84.4,\n",
       "  2.7175,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  14.7],\n",
       " [4.81213,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.701,\n",
       "  90.0,\n",
       "  2.5975,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  255.23,\n",
       "  16.42],\n",
       " [3.69311,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.376,\n",
       "  88.4,\n",
       "  2.5671,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  391.43,\n",
       "  14.65],\n",
       " [6.65492,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.317,\n",
       "  83.0,\n",
       "  2.7344,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  13.99],\n",
       " [5.82115,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.713,\n",
       "  6.513,\n",
       "  89.9,\n",
       "  2.8016,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  393.82,\n",
       "  10.29],\n",
       " [7.83932,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.655,\n",
       "  6.209,\n",
       "  65.4,\n",
       "  2.9634,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  13.22],\n",
       " [3.1636,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.655,\n",
       "  5.759,\n",
       "  48.2,\n",
       "  3.0665,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  334.4,\n",
       "  14.13],\n",
       " [3.77498,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.655,\n",
       "  5.952,\n",
       "  84.7,\n",
       "  2.8715,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  22.01,\n",
       "  17.15],\n",
       " [4.42228,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.584,\n",
       "  6.003,\n",
       "  94.5,\n",
       "  2.5403,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  331.29,\n",
       "  21.32],\n",
       " [15.5757,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.58,\n",
       "  5.926,\n",
       "  71.0,\n",
       "  2.9084,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  368.74,\n",
       "  18.13],\n",
       " [13.0751,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.58,\n",
       "  5.713,\n",
       "  56.7,\n",
       "  2.8237,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  14.76],\n",
       " [4.34879,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.58,\n",
       "  6.167,\n",
       "  84.0,\n",
       "  3.0334,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  16.29],\n",
       " [4.03841,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.532,\n",
       "  6.229,\n",
       "  90.7,\n",
       "  3.0993,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  395.33,\n",
       "  12.87],\n",
       " [3.56868,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.58,\n",
       "  6.437,\n",
       "  75.0,\n",
       "  2.8965,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  393.37,\n",
       "  14.36],\n",
       " [4.64689,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.614,\n",
       "  6.98,\n",
       "  67.6,\n",
       "  2.5329,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  374.68,\n",
       "  11.66],\n",
       " [8.05579,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.584,\n",
       "  5.427,\n",
       "  95.4,\n",
       "  2.4298,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  352.58,\n",
       "  18.14],\n",
       " [6.39312,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.584,\n",
       "  6.162,\n",
       "  97.4,\n",
       "  2.206,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  302.76,\n",
       "  24.1],\n",
       " [4.87141,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.614,\n",
       "  6.484,\n",
       "  93.6,\n",
       "  2.3053,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.21,\n",
       "  18.68],\n",
       " [15.0234,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.614,\n",
       "  5.304,\n",
       "  97.3,\n",
       "  2.1007,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  349.48,\n",
       "  24.91],\n",
       " [10.233,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.614,\n",
       "  6.185,\n",
       "  96.7,\n",
       "  2.1705,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  379.7,\n",
       "  18.03],\n",
       " [14.3337,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.614,\n",
       "  6.229,\n",
       "  88.0,\n",
       "  1.9512,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  383.32,\n",
       "  13.11],\n",
       " [5.82401,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.532,\n",
       "  6.242,\n",
       "  64.7,\n",
       "  3.4242,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  396.9,\n",
       "  10.74],\n",
       " [5.70818,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.532,\n",
       "  6.75,\n",
       "  74.9,\n",
       "  3.3317,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  393.07,\n",
       "  7.74],\n",
       " [5.73116,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.532,\n",
       "  7.061,\n",
       "  77.0,\n",
       "  3.4106,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  395.28,\n",
       "  7.01],\n",
       " [2.81838,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.532,\n",
       "  5.762,\n",
       "  40.3,\n",
       "  4.0983,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  392.92,\n",
       "  10.42],\n",
       " [2.37857,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.583,\n",
       "  5.871,\n",
       "  41.9,\n",
       "  3.724,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  370.73,\n",
       "  13.34],\n",
       " [3.67367,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.583,\n",
       "  6.312,\n",
       "  51.9,\n",
       "  3.9917,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  388.62,\n",
       "  10.58],\n",
       " [5.69175,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.583,\n",
       "  6.114,\n",
       "  79.8,\n",
       "  3.5459,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  392.68,\n",
       "  14.98],\n",
       " [4.83567,\n",
       "  0.0,\n",
       "  18.1,\n",
       "  0.0,\n",
       "  0.583,\n",
       "  5.905,\n",
       "  53.2,\n",
       "  3.1523,\n",
       "  24.0,\n",
       "  666.0,\n",
       "  20.2,\n",
       "  388.22,\n",
       "  11.45],\n",
       " [0.15086,\n",
       "  0.0,\n",
       "  27.74,\n",
       "  0.0,\n",
       "  0.609,\n",
       "  5.454,\n",
       "  92.7,\n",
       "  1.8209,\n",
       "  4.0,\n",
       "  711.0,\n",
       "  20.1,\n",
       "  395.09,\n",
       "  18.06],\n",
       " [0.18337,\n",
       "  0.0,\n",
       "  27.74,\n",
       "  0.0,\n",
       "  0.609,\n",
       "  5.414,\n",
       "  98.3,\n",
       "  1.7554,\n",
       "  4.0,\n",
       "  711.0,\n",
       "  20.1,\n",
       "  344.05,\n",
       "  23.97],\n",
       " [0.20746,\n",
       "  0.0,\n",
       "  27.74,\n",
       "  0.0,\n",
       "  0.609,\n",
       "  5.093,\n",
       "  98.0,\n",
       "  1.8226,\n",
       "  4.0,\n",
       "  711.0,\n",
       "  20.1,\n",
       "  318.43,\n",
       "  29.68],\n",
       " [0.10574,\n",
       "  0.0,\n",
       "  27.74,\n",
       "  0.0,\n",
       "  0.609,\n",
       "  5.983,\n",
       "  98.8,\n",
       "  1.8681,\n",
       "  4.0,\n",
       "  711.0,\n",
       "  20.1,\n",
       "  390.11,\n",
       "  18.07],\n",
       " [0.11132,\n",
       "  0.0,\n",
       "  27.74,\n",
       "  0.0,\n",
       "  0.609,\n",
       "  5.983,\n",
       "  83.5,\n",
       "  2.1099,\n",
       "  4.0,\n",
       "  711.0,\n",
       "  20.1,\n",
       "  396.9,\n",
       "  13.35],\n",
       " [0.17331,\n",
       "  0.0,\n",
       "  9.69,\n",
       "  0.0,\n",
       "  0.585,\n",
       "  5.707,\n",
       "  54.0,\n",
       "  2.3817,\n",
       "  6.0,\n",
       "  391.0,\n",
       "  19.2,\n",
       "  396.9,\n",
       "  12.01],\n",
       " [0.27957,\n",
       "  0.0,\n",
       "  9.69,\n",
       "  0.0,\n",
       "  0.585,\n",
       "  5.926,\n",
       "  42.6,\n",
       "  2.3817,\n",
       "  6.0,\n",
       "  391.0,\n",
       "  19.2,\n",
       "  396.9,\n",
       "  13.59],\n",
       " [0.17899,\n",
       "  0.0,\n",
       "  9.69,\n",
       "  0.0,\n",
       "  0.585,\n",
       "  5.67,\n",
       "  28.8,\n",
       "  2.7986,\n",
       "  6.0,\n",
       "  391.0,\n",
       "  19.2,\n",
       "  393.29,\n",
       "  17.6],\n",
       " [0.2896,\n",
       "  0.0,\n",
       "  9.69,\n",
       "  0.0,\n",
       "  0.585,\n",
       "  5.39,\n",
       "  72.9,\n",
       "  2.7986,\n",
       "  6.0,\n",
       "  391.0,\n",
       "  19.2,\n",
       "  396.9,\n",
       "  21.14],\n",
       " [0.26838,\n",
       "  0.0,\n",
       "  9.69,\n",
       "  0.0,\n",
       "  0.585,\n",
       "  5.794,\n",
       "  70.6,\n",
       "  2.8927,\n",
       "  6.0,\n",
       "  391.0,\n",
       "  19.2,\n",
       "  396.9,\n",
       "  14.1],\n",
       " [0.23912,\n",
       "  0.0,\n",
       "  9.69,\n",
       "  0.0,\n",
       "  0.585,\n",
       "  6.019,\n",
       "  65.3,\n",
       "  2.4091,\n",
       "  6.0,\n",
       "  391.0,\n",
       "  19.2,\n",
       "  396.9,\n",
       "  12.92],\n",
       " [0.17783,\n",
       "  0.0,\n",
       "  9.69,\n",
       "  0.0,\n",
       "  0.585,\n",
       "  5.569,\n",
       "  73.5,\n",
       "  2.3999,\n",
       "  6.0,\n",
       "  391.0,\n",
       "  19.2,\n",
       "  395.77,\n",
       "  15.1],\n",
       " [0.22438,\n",
       "  0.0,\n",
       "  9.69,\n",
       "  0.0,\n",
       "  0.585,\n",
       "  6.027,\n",
       "  79.7,\n",
       "  2.4982,\n",
       "  6.0,\n",
       "  391.0,\n",
       "  19.2,\n",
       "  396.9,\n",
       "  14.33],\n",
       " [0.06263,\n",
       "  0.0,\n",
       "  11.93,\n",
       "  0.0,\n",
       "  0.573,\n",
       "  6.593,\n",
       "  69.1,\n",
       "  2.4786,\n",
       "  1.0,\n",
       "  273.0,\n",
       "  21.0,\n",
       "  391.99,\n",
       "  9.67],\n",
       " [0.04527,\n",
       "  0.0,\n",
       "  11.93,\n",
       "  0.0,\n",
       "  0.573,\n",
       "  6.12,\n",
       "  76.7,\n",
       "  2.2875,\n",
       "  1.0,\n",
       "  273.0,\n",
       "  21.0,\n",
       "  396.9,\n",
       "  9.08],\n",
       " [0.06076,\n",
       "  0.0,\n",
       "  11.93,\n",
       "  0.0,\n",
       "  0.573,\n",
       "  6.976,\n",
       "  91.0,\n",
       "  2.1675,\n",
       "  1.0,\n",
       "  273.0,\n",
       "  21.0,\n",
       "  396.9,\n",
       "  5.64],\n",
       " [0.10959,\n",
       "  0.0,\n",
       "  11.93,\n",
       "  0.0,\n",
       "  0.573,\n",
       "  6.794,\n",
       "  89.3,\n",
       "  2.3889,\n",
       "  1.0,\n",
       "  273.0,\n",
       "  21.0,\n",
       "  393.45,\n",
       "  6.48],\n",
       " [0.04741,\n",
       "  0.0,\n",
       "  11.93,\n",
       "  0.0,\n",
       "  0.573,\n",
       "  6.03,\n",
       "  80.8,\n",
       "  2.505,\n",
       "  1.0,\n",
       "  273.0,\n",
       "  21.0,\n",
       "  396.9,\n",
       "  7.88]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myboston.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
